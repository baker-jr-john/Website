---
pagetitle: "John Baker – Learning Analytics"
title: "Knowledge Structure Mapping: a Comprehensive Report"
description: "An in-depth exploration of knowledge structure mapping using Factor Analysis, K-Means clustering, and PCA to uncover latent skills in an eight-item test dataset"
date: 2024-11-20
# date-modified: 
author: 
  - name: John Baker
    email: jbaker1@upenn.edu
    affiliation:
      - name: "Penn GSE: University of Pennsylvania Graduate School of Education"
        url: https://www.gse.upenn.edu/
abstract: |
  This study aims to identify the underlying knowledge structure of an eight-item test dataset by applying Factor Analysis, K-Means clustering, and Principal Component Analysis (PCA). Factor Analysis was utilized to uncover latent skills, with results cross-validated using K-Means clustering (simulating Barnes's Q-Matrix method) and PCA. Models with two to four components were compared to determine the optimal skill representation. The findings indicate that a three-component Factor Analysis model best captures the relationships among test items, effectively identifying three distinct skills. The final Q-matrix balances complexity and interpretability, providing a robust mapping of items to latent skills and enhancing the understanding of the dataset's knowledge structure.
keywords:
  - knowledge structure mapping
  - Factor Analysis
  - Q-matrix
  - latent skills
  - PCA
bibliography: bibliography/bibliography.bib
nocite: |
  @*
# image: images/image_fx_.png
format:
  html:
    code-link: false
draft: true
jupyter: python3
ipynb-shell-interactivity: all
execute: 
  freeze: false
---

## Introduction

Imagine if educators could uncover the hidden connections between what students know and what they are tested on. This is the power of knowledge structure mapping. **Knowledge structure mapping** allows educators and researchers to uncover the relationships between test items and the underlying skills or concepts they measure. This understanding is crucial for developing effective educational tools, improving assessment strategies, and tailoring instruction to meet individual student needs. By mapping how different items relate to latent skills, educators can identify areas where students may struggle and provide targeted interventions.

Determining the optimal representation of latent skills within limited test data is challenging, as traditional methods often rely on assumptions that may not generalize across educational contexts or assessment types. Therefore, robust, data-driven approaches are needed to accurately identify and validate the underlying skill structures in assessment data.

This study addresses this gap by investigating the knowledge structure underlying an eight-item test dataset using a comprehensive methodology that balances model complexity and interpretability. By combining advanced statistical and machine learning techniques—specifically, **Factor Analysis** to uncover latent skills, **K-Means clustering** to simulate Barnes's Q-Matrix method for grouping items, and **Principal Component Analysis (PCA)** to validate the identified item-skill relationships—I aim to identify the underlying skill structures robustly. To determine the optimal skill representation, I compare models with varying numbers of components, from two to four, seeking a balance between capturing sufficient detail and maintaining simplicity for educational interpretation and application. The resulting **Q-matrix** derived from this multi-method approach offers a clear, empirically-derived mapping of items to latent skills, enhancing the interpretability and utility of test results for educators and researchers.

My approach contributes to the existing body of research by providing a comprehensive methodology that balances complexity with interpretability. The final **Q-matrix** derived from my analysis offers a robust mapping of items to latent skills, enhancing the interpretability of test results. This study demonstrates the effectiveness of combining multiple analytical methods for knowledge structure mapping. It also provides insights to inform the development of more nuanced educational assessments and personalized learning strategies.

## Background and Related Work

**Knowledge structure mapping** is a fundamental process in educational data mining that involves analyzing and visualizing learners' conceptual understanding and cognitive organization of information [@gordon2003learning]. It enables educators and researchers to represent relationships between different pieces of knowledge, facilitating the development of personalized learning experiences and more effective educational tools.

### Methods for Knowledge Structure Mapping

Several methods have been developed to map knowledge structures, each with its own advantages and limitations. **Learning Factors Analysis (LFA)** is one such method used to evaluate and refine cognitive models [@cen2006learning]. LFA leverages student performance data to improve the accuracy of these models, thereby enhancing personalized learning by tailoring instruction to individual student needs.

**Partial-Order Knowledge Spaces (POKS)** provide another powerful framework for representing knowledge structures [@desmarais2006learned]. POKS uses partially ordered sets of skills to model how knowledge builds upon itself. For example, mastering addition might be a prerequisite for learning multiplication, reflecting the hierarchical nature of certain learning processes.

Another widely used method for knowledge structure mapping is **Factor Analysis**, a statistical technique used to uncover hidden relationships between observed variables—such as test items—and underlying latent variables—such as skills [@beavers2019practical]. By analyzing correlations among test items, Factor Analysis can reveal clusters of items that measure the same underlying skill. This data-driven approach helps in identifying latent skills without requiring prior knowledge of the skill structure.

While Factor Analysis and PCA rely on statistical techniques, **Barnes's Q-matrix method** takes a different approach. It uses a binary matrix to represent the relationship between items and skills [@barnes2005q]. In this matrix, rows represent test items, columns represent skills and entries indicate whether a skill is required for a particular item. The Q-matrix provides a visual and analytical tool for understanding which skills are assessed by each item, and it is widely used in cognitive modeling and educational data mining.

**K-Means Clustering** can simulate the Q-matrix method by grouping items based on response patterns without prior knowledge of the skill structure. By clustering items that have similar response profiles, researchers can infer potential underlying skills that explain these patterns. This unsupervised learning approach allows for the exploration of latent skill groupings in the absence of predefined skill mappings.

**Principal Component Analysis (PCA)** is another statistical method employed in knowledge structure mapping to reduce the dimensionality of data while preserving as much variance as possible. PCA identifies principal components, which are linear combinations of the original variables (test items). These components can be interpreted as underlying skills or factors influencing student performance. PCA helps validate the item-skill relationships identified through other methods like Factor Analysis by providing an alternative perspective on the data structure [@kargupta2001distributed].

These methods collectively provide a toolbox for researchers to uncover the underlying structure of knowledge in educational data.

### Applications in Educational Data Mining

The knowledge structure mapping methods discussed above have found wide application in educational data mining, including:

- **Intelligent Tutoring Systems (ITSs):** Knowledge structure mapping is crucial for ITSs to personalize instruction and provide tailored feedback based on individual student performance and identified skill gaps [@de2008educational].

- **Predicting Student Performance:** Understanding knowledge structures enables the prediction of student performance on assessments and helps in identifying students who are at risk of falling behind, allowing for timely interventions [@de2008educational].

- **Analyzing Student Behavior:** Knowledge structure mapping can be used to analyze student behavior patterns, such as help-seeking actions, providing insights into how students approach learning tasks and where they may encounter difficulties [@cukurova2022learning].

The importance of using data-driven approaches, such as Factor Analysis, K-Means clustering, and PCA, lies in their ability to uncover patterns and relationships that might not be apparent through traditional methods [@chen2018knowedu]. These techniques allow researchers to identify latent skills and understand how knowledge is organized within a dataset, which can be applied to improve educational practices and assessment designs.

### Limitations and Challenges

Despite their utility, each knowledge structure mapping method has its limitations. Factor Analysis and PCA typically assume that the data are continuous and normally distributed, which may not always be the case with binary test item responses. K-Means clustering requires the specification of the number of clusters in advance and may not capture complex, hierarchical relationships between items and skills. Despite these limitations, when used in combination, these methods can provide a robust analysis of knowledge structures by cross-validating findings and offering complementary insights.

## Methods Used

### Overview

This study employs statistical and machine learning techniques—**Factor Analysis**, **K-Means Clustering**, and **Principal Component Analysis (PCA)**—to uncover the latent skills underlying an eight-item test dataset. Each method offers unique insights into the data, and their combined use allows for a comprehensive analysis of the knowledge structure. Each technique complements and validates the findings of the others, contributing to a robust understanding of the underlying skill structure.

### Factor Analysis

**Factor Analysis** was chosen as the primary method to discover the underlying latent skills measured by the test items. This statistical technique identifies factors (latent variables) that explain the patterns of correlations among observed variables (test items). By reducing the dimensionality of the data, Factor Analysis helps reveal the structure of the latent skills that influence student performance.

**Rationale**:

- **Data-Driven Identification and Correlation Structure**: Given the exploratory nature of this study and its aim to uncover latent skills, Factor Analysis is an appropriate choice. It does not require prior knowledge of the skill structure and can effectively capture the underlying correlation patterns among test items.

**Assumptions and Justifications**:

- **Binary Data Consideration and Sample Size Adequacy**: Although Factor Analysis traditionally assumes continuous and normally distributed data, its application to binary data is acceptable in exploratory contexts, particularly when the sample size is sufficient, as in this study.
- **Number of Factors**: I initially selected three factors based on the expectation of three underlying skills. To ensure robustness, models with two and four factors were also tested to explore alternative structures.

### Barnes's Q-Matrix Method (Simulated using K-Means Clustering)

**K-Means Clustering** is used to simulate **Barnes's Q-Matrix method**, providing an alternative perspective on item groupings based on response patterns without imposing prior assumptions about the skill structure, allowing for a data-driven validation of the Factor Analysis results.

**Rationale**:

- **Unsupervised Learning**: K-Means Clustering groups items based on similarity in response patterns without prior assumptions about the skill structure, effectively simulating the creation of a Q-matrix.
- **Cross-Validation**: It provides an alternative perspective on item groupings, allowing us to validate the findings from Factor Analysis.

**How K-Means Clustering Simulates the Q-Matrix Method**:

- **Item Clustering**: By clustering items that have similar response patterns across students, K-Means Clustering effectively groups items that may require the same underlying skill.
- **Skill Inference**: Each cluster represents a group of items that are likely associated with an ordinary skill, analogous to columns in the Q-matrix.

**Assumptions and Justifications**:

- **Number of Clusters**: To facilitate comparison, I set the number of clusters to three, consistent with the initial number of factors in Factor Analysis.
- **Distance Metric**: The default Euclidean distance is used, as it is suitable for capturing the similarity of response patterns in binary data.

### Principal Component Analysis (PCA)

**Principal Component Analysis (PCA)** an additional method to validate the item-skill relationships identified through Factor Analysis and K-Means Clustering. PCA helps confirm the significance of the identified latent skills by examining the variance explained by each principal component.

**Rationale**:

- **Alternative Dimensionality Reduction**: PCA offers an alternative method for identifying underlying structures in the data, providing a means to cross-validate findings from Factor Analysis.
- **Variance Explanation**: By examining the amount of variance explained by each principal component, I can infer the significance of the underlying skills.

**Assumptions and Justifications**:

- **Binary Data Consideration**: While PCA assumes continuous data, its application to binary data is acceptable for exploratory purposes, particularly when used with other methods to validate its findings.
- **Number of Components**: Three principal components were extracted to maintain consistency with the other methods and to facilitate direct comparison.

### Model Iteration and Comparison

To determine the optimal skill representation, I iteratively tested models with varying numbers of components—two, three, and four—across all methods.

**Rationale**:

- **Exploring Complexity**: Testing multiple models allows us to explore how the complexity of the model affects the interpretability and explanatory power of the latent skills.
- **Avoiding Overfitting and Oversimplification**: By comparing models with different numbers of components, I aim to find a balance between capturing sufficient detail and maintaining simplicity.

**Assumptions and Justifications**:

- **Consistency Across Methods**: Maintaining the same number of components or clusters across different methods helps compare and validate the results.
- **Interpretability Priority**: The selection of the optimal model is guided by the interpretability of the results, ensuring that the identified skills make practical sense in the context of educational assessment.

### Data Preparation and Preprocessing

Before applying the methods, the data are prepared and preprocessed to ensure accurate analysis.

**Steps**:

- **Data Loading**: The dataset is loaded using pandas. It contains binary responses (correct or incorrect) for eight test items across multiple students.
- **Item Data Extraction**: The 'student' identifier column is excluded to focus on item responses.
- **Data Transformation**: For K-Means Clustering, the item data were transposed to cluster items rather than students.

**Assumptions and Justifications**:

- **Data Quality**: The data are assumed to be accurate and free from errors or missing values, which is critical for the validity of the analyses.
- **Binary Nature of Responses**: The binary nature of the item responses is considered when selecting and applying of methods, acknowledging potential limitations.

### Summary of Methodological Approach

This study employs a multi-method approach that mitigates the limitations of individual techniques by leveraging the strengths of Factor Analysis, K-Means Clustering, and PCA.

- **Factor Analysis** identifies latent skills based on correlation structures.
- **K-Means Clustering** groups items based on response pattern similarities without prior assumptions.
- **PCA** validates the findings by identifying principal components that explain the most variance.

This approach enhances the reliability and robustness of the knowledge structure mapping, providing a comprehensive understanding of the latent skills assessed by the test items.

## Implementation Details

### Data Preparation

#### Loading the Data

To begin the analysis, I loaded the dataset containing binary responses (correct or incorrect) for eight test items from multiple students. The `pandas` library is used for data manipulation due to its efficiency and ease of use with tabular data.

```{python}
#| label: tbl-prep
#| tbl-cap: First few rows of the dataset

# Import necessary libraries
import pandas as pd

# Load the dataset
data = pd.read_csv('data/8items.csv')

# Display the first few rows of the dataset
data.head()
```

**Explanation**:

- **Data Loading**: The dataset `8items.csv` is read into a pandas data frame called `data`.
- **Data Inspection**: Using `data.head()`, I display the first few rows to verify that the data has been loaded correctly.

#### Data Exploration

Before proceeding, I explored the data to understand its structure and check for anomalies.

```{python}
# Check the dimensions of the dataset
print(f"Dataset dimensions: {data.shape}")

# Check for missing values
print("Missing values in each column:")
print(data.isnull().sum())
```

**Explanation**:

- **Dataset Dimensions**: I print the shape of the data frame to confirm the number of students (rows) and items (columns).
- **Missing Values**: I check for any missing values that could affect the analysis.

**Findings**:

- The dataset has the expected dimensions with no missing values, indicating that it is ready for analysis.

### Factor Analysis

#### Preparing Data for Factor Analysis

I extracted the item response data, excluding any non-item columns such as 'student' identifiers.

```{python}
# Extract item data (excluding the 'student' column if present)
item_data = data.drop(columns=['student'], errors='ignore')
```

**Explanation**:

- **Data Extraction**: I drop the 'student' column to focus solely on the item responses.
- **Error Handling**: The `errors='ignore'` parameter ensures that the code will not raise an error if the 'student' column is not present.

#### Determining the Number of Factors Using Scree Plot

```{python}
# Import necessary modules
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from factor_analyzer import FactorAnalyzer

# Standardize the data
scaler = StandardScaler()
item_data_scaled = scaler.fit_transform(item_data)

# Perform factor analysis with maximum factors
fa_model = FactorAnalyzer(rotation=None)
fa_model.fit(item_data_scaled)
```
```{python}
# Get eigenvalues and variance explained
ev, v = fa_model.get_eigenvalues()
variance = fa_model.get_factor_variance()

# Extract variance explained and cumulative variance
variance_explained = variance[1]
cumulative_variance_explained = variance[2]

# Total variance explained by the factors
total_variance_explained = cumulative_variance_explained[-1]
print(f"Total Variance Explained by Factors: {total_variance_explained}")
```
```{python}
# Plot the scree plot
plt.figure(figsize=(8, 5))
plt.plot(range(1, len(ev) + 1), ev, 'o-', color='blue')
_ = plt.title('Scree Plot for Factor Analysis')
_ = plt.xlabel('Factor Number')
_ = plt.ylabel('Eigenvalue')
plt.grid(True)
plt.show()
```

**Explanation**:

- The scree plot shows a clear "elbow" after the second factor, where the eigenvalues drop sharply initially and then level off. This "elbow" suggests that the first two factors capture most of the meaningful variance, with subsequent factors contributing relatively little.

#### Performing Factor Analysis

I apply Factor Analysis with three components to identify latent skills in the dataset. The `FactorAnalysis` module from `sklearn.decomposition` is used to perform the analysis.

```{python}
# Retrieve the factor loadings
factor_loadings = fa_model.loadings_

# Dynamically determine the number of factors extracted
n_factors_extracted = factor_loadings.shape[1]

# Create a data frame for the factor loadings
factor_loadings_df = pd.DataFrame(
    factor_loadings,
    index=item_data.columns,
    columns=[f'Skill_{i+1}' for i in range(n_factors_extracted)]
)
```

**Explanation**:

- **Model Initialization**: I initialize the `FactorAnalyzer` model.
- **Model Fitting**: The model is fit to `item_data_scaled`.
- **Factor Loadings**: I obtain the factor loadings representing the correlation coefficients between items and factors (skills).
- **Data frame Creation**: The factor loadings are organized into a data frame for better visualization and interpretation.

```{python}
#| label: tbl-factor
#| tbl-cap: Factor Loadings

# Display the factor loadings
factor_loadings_df
```

The factor loadings suggest that items group together based on their highest loadings, indicating the presence of three distinct latent skills.

### K-Means Clustering

#### Transposing Item Data

I transpose the item data to cluster items based on their response patterns.

```{python}
# Import K-Means module
from sklearn.cluster import KMeans

# Transpose the item data to have items as rows and students as columns
item_data_transposed = item_data_scaled.T

# Specify the number of clusters (skills)
n_clusters = 3

# Initialize the K-Means model
kmeans = KMeans(n_clusters=n_clusters, random_state=42)

# Fit the model to the transposed item data
kmeans.fit(item_data_transposed)
```
```{python}
# Retrieve the cluster labels for each item
cluster_labels = kmeans.labels_

# Create a data frame to display the item-cluster mapping
kmeans_q_matrix_df = pd.DataFrame({
    'Item': item_data.columns,
    'Mapped_Skill': [f'Skill_{label+1}' for label in cluster_labels]
})
```

**Explanation**:

- **Transposition**: Clustering is performed on items, so I transpose the data to have items as the observations.

#### Determining the Number of Clusters Using Elbow Method

```{python}
# Import necessary module
import numpy as np

# Calculate WCSS for different number of clusters
wcss = []
for i in range(1, 7):
    kmeans_elbow = KMeans(n_clusters=i, random_state=42)
    kmeans_elbow.fit(item_data_transposed)
    wcss.append(kmeans_elbow.inertia_)
```
```{python}
# Plot the elbow graph
plt.figure(figsize=(8, 5))
plt.plot(range(1, 7), wcss, 'o-', color='red')
_ = plt.title('Elbow Method for K-Means Clustering')
_ = plt.xlabel('Number of Clusters')
_ = plt.ylabel('Within-Cluster Sum of Squares (WCSS)')
plt.grid(True)
plt.show()
```

**Explanation**:

- The elbow plot indicates that the WCSS significantly decreases up to three clusters, after which the rate of decrease slows down, suggesting that three clusters are optimal.

#### Applying K-Means Clustering

I apply K-Means clustering to group items into clusters representing latent skills.

**Explanation**:

- **Model Initialization**: I initialize the `K-Means` model with `n_clusters=3`.
- **Model Fitting**: The model is fitted to `item_data_transposed`.
- **Cluster Labels**: Each item is assigned a cluster label, indicating its grouping.
- **Mapping Items to Skills**: I map cluster labels to skill identifiers for interpretation.

```{python}
#| label: tbl-kmeans
#| tbl-cap: Item-Cluster Mapping

# Display the item-cluster mapping
kmeans_q_matrix_df
```

The clustering results provide an alternative item-skill mapping that can be compared with the Factor Analysis findings.

### Principal Component Analysis (PCA)

#### Determining the Number of Components Using Scree Plot

```{python}
# Import necessary module
from sklearn.decomposition import PCA

# Initialize PCA to get all components
pca = PCA()
pca.fit(item_data_scaled)

# Calculate explained variance
explained_variance = pca.explained_variance_

# Plot the scree plot
plt.figure(figsize=(8, 5))
plt.plot(range(1, len(explained_variance) + 1), explained_variance, 'o-', color='green')
_ = plt.title('Scree Plot for PCA')
_ = plt.xlabel('Principal Component Number')
_ = plt.ylabel('Eigenvalue')
plt.grid(True)
plt.show()
```

**Explanation**:

- The scree plot for PCA suggests that two components are optimal, as the eigenvalues level off after the second component.

#### Performing PCA

I use PCA to identify principal components that may represent latent skills.

```{python}
# Initialize the PCA model with three components
pca_model = PCA(n_components=3)

# Fit the PCA model to the item data
pca_model.fit(item_data_scaled)
```
```{python}
# Retrieve the PCA loadings
pca_loadings = pca_model.components_.T

# Create a data frame for the PCA loadings
pca_loadings_df = pd.DataFrame(
    pca_loadings,
    index=item_data.columns,
    columns=[f'Skill_{i+1}' for i in range(3)]
)
```

**Explanation**:

- **Model Initialization**: I initialize the `PCA` model with `n_components=3`.
- **Model Fitting**: The model is fitted to `item_data_scaled`.
- **PCA Loadings**: The loadings indicate the contribution of each item to the principal components.

```{python}
#| label: tbl-pca
#| tbl-cap: PCA Loadings

# Display the PCA loadings
pca_loadings_df
```

The PCA results offer additional insights into the item-skill relationships, which can be compared with the results from Factor Analysis and K-Means Clustering.

## Results

### Mapping Items to Skills Using PCA

To understand the item-skill relationships further, I created a Q-matrix based on the **Principal Component Analysis (PCA)** loadings to further understand the item-skill relationships. Each item is assigned to the skill (principal component) with which it has the highest loading.

```{python}
#| label: tbl-qmarix1
#| tbl-cap: PCA Q-Matrix

# Determine the skill with the highest loading for each item from PCA
pca_q_matrix = pca_loadings_df.idxmax(axis=1)

# Create the Q-matrix as a data frame, showing the mapping between items and skills
pca_q_matrix_df = pd.DataFrame({'Item': item_data.columns, 'Mapped_Skill': pca_q_matrix.values})
pca_q_matrix_df
```

### Comparison Across Methods

The mappings obtained from Factor Analysis, K-Means Clustering, and PCA show considerable agreement, suggesting the presence of three distinct latent skills assessed by the test items.

### Testing Alternative Factor Analysis Models

I test **Factor Analysis** models with two, three, and four components to determine the optimal number of latent skills.

#### Factor Analysis with Four Components

```{python}
# Performing Factor Analysis with four components to explore the potential presence of additional latent skills
n_factors_extended = 4
fa_model_extended = FactorAnalyzer(n_factors=n_factors_extended, rotation=None)
fa_model_extended.fit(item_data_scaled)
```
```{python}
#| label: tbl-qmarix2
#| tbl-cap: Factor Analysis with Four Components

# Get the factor loadings for the 4-component model
factor_loadings_extended = fa_model_extended.loadings_

# Create a data frame to visualize the factor loadings for the four-component model
factor_loadings_extended_df = pd.DataFrame(factor_loadings_extended, index=item_data.columns, columns=[f'Skill_{i+1}' for i in range(n_factors_extended)])
factor_loadings_extended_df
```

**Observations from the Four-Component Model**:

- **Complexity and Overfitting**: The four-component model introduces additional complexity without significant gains in explained variance. Some items load significantly on multiple factors, making interpretation challenging.
- **Item Loadings**:
  - **Item2** and **Item4** have substantial loadings on both **Skill_2** and **Skill_4**, indicating overlapping skills.
  - **Item5** loads highly on both **Skill_1** and **Skill_3**, suggesting it may be measuring a combination of skills.
- **Interpretability**: The overlapping loadings reduce the model's interpretability, making it less practical for educational applications.

#### Factor Analysis with Two Components

```{python}
# Performing Factor Analysis with two components to explore if a simpler model might explain the relationships
n_factors_simpler = 2
fa_model_simpler = FactorAnalyzer(n_factors=n_factors_simpler, rotation=None)
fa_model_simpler.fit(item_data_scaled)
```
```{python}
#| label: tbl-qmarix3
#| tbl-cap: Factor Analysis with Two Components
# Get the factor loadings for the two-component model
factor_loadings_simpler = fa_model_simpler.loadings_

# Create a data frame to visualize the factor loadings for the two-component model
factor_loadings_simpler_df = pd.DataFrame(factor_loadings_simpler, index=item_data.columns, columns=[f'Skill_{i+1}' for i in range(n_factors_simpler)])
factor_loadings_simpler_df
```

- **Simplicity vs. Variance Explained**: The two-component model is simpler but explains less variance compared to the three-component model.
- **Item Loadings**:
  - **Item3**, **Item5**, **Item7**, and **Item8** load highly on **Skill_1**.
  - **Item2**, **Item4**, and **Item6** load on **Skill_2**.
  - **Item1** has very low loadings on both factors, suggesting it may not be well-represented in this model.
- **Loss of Detail**: The two-component model may be too simplistic, failing to capture nuances in the data, particularly the unique contribution of **Item1**.

### Visualizations

#### Diagrams

I create some [Mermaid](https://mermaid.js.org/) diagrams to gain further insight.[^1]

[^1]: Refer to [Creative Assignment 3's GitHub repository](https://github.com/baker-jr-john/Website/blob/main/educ_6191_001/creative_assignments/assignment_3/index.qmd) for the code behind the diagrams.

```{mermaid}
graph TB
    subgraph PCA
        PCA_S1[Skill_1] --- PCA_I3[Item 3]
        PCA_S1 --- PCA_I7[Item 7]
        PCA_S1 --- PCA_I8[Item 8]
        
        PCA_S2[Skill_2] --- PCA_I2[Item 2]
        PCA_S2 --- PCA_I4[Item 4]
        PCA_S2 --- PCA_I6[Item 6]
        
        PCA_S3[Skill_3] --- PCA_I1[Item 1]
        PCA_S3 --- PCA_I5[Item 5]
    end
    
    subgraph KMeans
        KM_S1[Skill_1] --- KM_I3[Item 3]
        KM_S1 --- KM_I5[Item 5]
        KM_S1 --- KM_I7[Item 7]
        KM_S1 --- KM_I8[Item 8]
        
        KM_S2[Skill_2] --- KM_I2[Item 2]
        KM_S2 --- KM_I4[Item 4]
        KM_S2 --- KM_I6[Item 6]
        
        KM_S3[Skill_3] --- KM_I1[Item 1]
    end
    
    subgraph Factor_Analysis
        FA_S1[Skill_1] --- FA_I3[Item 3]
        FA_S1 --- FA_I5[Item 5]
        FA_S1 --- FA_I7[Item 7]
        FA_S1 --- FA_I8[Item 8]
        
        FA_S2[Skill_2] --- FA_I2[Item 2]
        FA_S2 --- FA_I4[Item 4]
        FA_S2 --- FA_I6[Item 6]
        
        FA_S3[Skill_3] --- FA_I1[Item 1]
    end

    style PCA fill:#f9f,stroke:#333,stroke-width:2px
    style KMeans fill:#bbf,stroke:#333,stroke-width:2px
    style Factor_Analysis fill:#bfb,stroke:#333,stroke-width:2px
```
<figcaption style="font-size: 0.9em; color: #555555; text-align: left; margin-top: 8px;">
    Diagram 1: Comparison Across the Three Methods
</figcaption>
<br>

##### Diagram 1: Method Comparison (Factor Analysis, K-Means, PCA)
- **Key Observations**:
  1. **Consistency Across Methods**: Many items (e.g., Item 3 and Item 7) align similarly across Factor Analysis, K-Means, and PCA, reinforcing the robustness of these mappings.
  2. **Item Overlap**: The clustering of items (e.g., Items 3, 7, and 8 under Skill_1) consistently suggests a strong latent skill grouping.
  3. **Discrepancies**: While most items map consistently, some differences (e.g., Item 5 under Factor Analysis vs. PCA) suggest subtle differences in how these methods interpret data structures.
  4. **Skill 3 Representation**: This skill emerges consistently across methods but captures fewer items, which might indicate a niche or less represented skill.

The visual comparison highlights overlaps and outliers more effectively than numerical tables, making it easier to identify items that contribute ambiguously to multiple skills or are method-dependent.
```{mermaid}
graph TB
    subgraph Four_Component_Model
        FC_S1[Skill_1] --- FC_I3[Item 3]
        FC_S1 --- FC_I7[Item 7]
        FC_S1 --- FC_I8[Item 8]
        FC_S1 -.-> FC_I5[Item 5]
        
        FC_S2[Skill_2] --- FC_I6[Item 6]
        FC_S2 -.-> FC_I2[Item 2]
        FC_S2 -.-> FC_I4[Item 4]
        
        FC_S3[Skill_3] --- FC_I1[Item 1]
        FC_S3 --- FC_I5
        
        FC_S4[Skill_4] -.-> FC_I2
        FC_S4 -.-> FC_I4
    end
    
    subgraph Three_Component_Model
        TH_S1[Skill_1] --- TH_I3[Item 3]
        TH_S1 --- TH_I7[Item 7]
        TH_S1 --- TH_I8[Item 8]
        TH_S1 --- TH_I5[Item 5]
        
        TH_S2[Skill_2] --- TH_I2[Item 2]
        TH_S2 --- TH_I4[Item 4]
        TH_S2 --- TH_I6[Item 6]
        
        TH_S3[Skill_3] --- TH_I1[Item 1]
        TH_S3 -.-> TH_I5
    end
    
    subgraph Two_Component_Model
        TC_S1[Skill_1] --- TC_I3[Item 3]
        TC_S1 --- TC_I5[Item 5]
        TC_S1 --- TC_I7[Item 7]
        TC_S1 --- TC_I8[Item 8]
        
        TC_S2[Skill_2] --- TC_I2[Item 2]
        TC_S2 --- TC_I4[Item 4]
        TC_S2 --- TC_I6[Item 6]
        
        TC_I1[Item 1<br/>Weak Loadings] -..- TC_S1
        TC_I1 -..- TC_S2
    end

    style Two_Component_Model fill:#bfb,stroke:#333,stroke-width:2px
    style Three_Component_Model fill:#bbf,stroke:#333,stroke-width:2px
    style Four_Component_Model fill:#f9f,stroke:#333,stroke-width:2px
```
<figcaption style="font-size: 0.9em; color: #555555; text-align: left; margin-top: 8px;">
    Diagram 2: Comparison Across the Three Models
</figcaption>
<br>

##### Diagram 2: Model Comparison (Two-, Three-, and Four-Component Models)
- **Key Observations**:
  1. **Two-Component Model**: Simpler but lacks granularity, as evident in fewer distinct mappings and the merging of certain skills.
  2. **Three-Component Model**: Balanced in complexity and interpretability, with clear item-skill relationships (e.g., Items 3, 7, and 8 consistently linked to Skill 1).
  3. **Four-Component Model**: Overcomplicates relationships with multiple cross-loadings (e.g., Item 5 linked to both Skill 1 and Skill 3), making the model harder to interpret.
  4. **Weak Loadings (Item 1)**: Visualizing weak loadings in the two-component model underscores its limited ability to represent all test items adequately.

The diagrams provide a clear visual distinction between the interpretability trade-offs of different models. For instance, they highlight how additional components in the four-component model lead to more overlap, supporting the conclusion that the three-component model is optimal.

##### Broader Insights:
- **Support for Prior Work**: The diagrams reinforce the findings that a three-component model is the most interpretable and aligns well across methods.
- **New Learnings**:
  - **Item-Specific Trends**: Items like Item 5 show variability across methods and models, suggesting they may assess complex or multiple skills.
  - **Skill Coverage**: Skills identified in PCA seem broader, potentially capturing more nuanced relationships, while K-Means provides a stricter clustering.
  - **Cross-Method Validation**: The diagrams visually validate the multi-method approach, showing where methods agree or diverge.

#### Heatmap of Factor Loadings (Three Components)

Using a heatmap, I visualize the factor loadings from the three-component Factor Analysis model.

```{python}
#| label: fig-heatmap
#| fig-cap: "Factor Analysis with Three Components"

import seaborn as sns

# Create a heatmap to visualize item-skill relationships from Factor Analysis
plt.figure(figsize=(10, 6))
sns.heatmap(factor_loadings_df, annot=True, cmap='coolwarm', linewidths=0.5, linecolor='black', cbar=True)
_ = plt.title('Item-Skill Relationships (Factor Analysis with Three Components)')
plt.show()
```

##### Key Observations:
1. **Dominant Item-Skill Relationships**:
   - **Item 1** strongly loads on **Skill 3** (0.99), indicating that it is almost exclusively associated with this latent skill.
   - **Item 3**, **Item 7**, and **Item 8** have high loadings on **Skill 1** (0.81, 0.78, and 0.78, respectively), showing that they are closely related to this skill.
   - **Item 6** is strongly associated with **Skill 2** (1.00), suggesting it is a clear indicator of this skill.

2. **Cross-Skill Contributions**:
   - **Item 5** has moderate loadings on both **Skill 1** (0.48) and **Skill 3** (0.33), indicating that it measures a mix of these skills.
   - **Item 2** has a moderate loading on **Skill 2** (0.30), with negligible contributions to other skills, suggesting it is moderately representative of this skill but not a strong indicator.

3. **Weak Loadings**:
   - **Item 4** shows relatively weak loadings across all skills, with the highest on **Skill 2** (0.33). This suggests that it may not align well with any single skill or may be ambiguously measuring multiple skills.
   - Similarly, **Item 2** and **Item 5** exhibit weak or mixed relationships across skills, warranting further investigation.

4. **Distinct Skills**:
   - **Skill 1**: Clearly defined by **Item 3**, **Item 7**, and **Item 8**.
   - **Skill 2**: Dominated by **Item 6**, with some contributions from **Item 2** and **Item 4**.
   - **Skill 3**: Clearly represented by **Item 1**, with partial contributions from **Item 5**.

##### Insights:
- **Item-Skill Assignment**: The heatmap visually confirms the appropriateness of assigning items to the skills based on their dominant factor loadings.
- **Complex or Ambiguous Items**: Items like **Item 5** and **Item 4** exhibit weaker or mixed relationships, suggesting potential challenges in their interpretation or measurement of a specific skill.
- **Skill Coverage**: Each skill appears to have at least one strongly associated item, ensuring that all skills are represented in the model.

#### Bar Charts for Individual Items

I generate bar charts to illustrate the factor loadings of each item across the three skills.

```{python}
#| label: fig-barcharts
#| fig-cap: "Bar Charts for Individual Items"

# Create bar charts for each item to show its relationship across skills
num_items = len(factor_loadings_df.index)
fig, axes = plt.subplots(num_items, 1, figsize=(9, num_items * 2))

for i, item in enumerate(factor_loadings_df.index):
    axes[i].bar(factor_loadings_df.columns, factor_loadings_df.loc[item], color='skyblue')
    _ = axes[i].set_title(f'Relationship of {item} with Skills')
    _ = axes[i].set_ylabel('Loading Value')
    _ = axes[i].set_ylim(-1, 1)

plt.tight_layout()

plt.show()
```

##### Key Insights:
1. **Dominant Item-Skill Relationships**:
   - **Item 1**: Almost exclusively associated with **Skill 3**, with a very high loading value (~0.99). It does not meaningfully load on **Skill 1** or **Skill 2**.
   - **Item 3**, **Item 7**, and **Item 8**: Strongly associated with **Skill 1**, with high positive loadings (~0.81 and ~0.78). These items clearly represent this latent skill.
   - **Item 6**: Solely aligned with **Skill 2** (loading ~1.00), making it the clearest representative of this skill.

2. **Mixed and Moderate Relationships**:
   - **Item 5**: Shows moderate loadings on both **Skill 1** (~0.48) and **Skill 3** (~0.33), indicating that it may measure a combination of these skills.
   - **Item 2**: Moderately aligned with **Skill 2** (~0.30) but has negligible loadings on the other skills, making it a less prominent representative of any single skill.

3. **Ambiguous or Weak Relationships**:
   - **Item 4**: Has low to moderate loadings across the board, with the highest (~0.33) on **Skill 2**. This indicates that the item may be ambiguous or weakly related to the latent skills in this model.
   - **Item 2**: Although moderately associated with **Skill 2**, its low loadings suggest it does not strongly differentiate itself in measuring this skill.

4. **Distinct Skills**:
   - **Skill 1**: Clearly defined by **Item 3**, **Item 7**, and **Item 8**.
   - **Skill 2**: Primarily represented by **Item 6**, with minor contributions from **Item 2** and **Item 4**.
   - **Skill 3**: Dominated by **Item 1**, with partial contributions from **Item 5**.

##### What We Learn:
1. **Support for Factor Analysis Findings**:
   - The charts confirm that the three-component model successfully captures distinct latent skills, with most items showing strong associations with a single skill.
   - The visualization highlights items that load cleanly on one skill (e.g., Item 6 for Skill 2, Item 1 for Skill 3).

2. **Ambiguous Items**:
   - Items like **Item 4** and **Item 5** demonstrate weaker or mixed relationships, indicating potential issues with their design or alignment with specific skills.
   - These items may require revision or could indicate the need for further exploration of an additional component.

3. **Strength of Representation**:
   - Certain skills (e.g., Skill 1 and Skill 3) have multiple items with high loadings, providing strong representation.
   - Skill 2 is highly dependent on a single dominant item (**Item 6**), which could make it more vulnerable to measurement error.
   
### Creating the Final Q-Matrix

Based on the analyses and visualizations, I create the final **Q-matrix** by assigning each item to the skill with the highest loading from the three-component Factor Analysis model.

```{python}
#| label: tbl-qmarix4
#| tbl-cap: Final Q-Matrix

# Creating the final Q-matrix based on the visualization and analysis findings
# Assigning each item to the skill with the highest loading from the Factor Analysis with three components
final_q_matrix = factor_loadings_df.idxmax(axis=1)

# Create a data frame to visualize the final Q-matrix, showing the mapping between items and skills
final_q_matrix_df = pd.DataFrame({'Item': item_data.columns, 'Mapped_Skill': final_q_matrix.values})
final_q_matrix_df
```

```{mermaid}
graph LR
    subgraph Final_Q_Matrix_Mappings
        S1[Skill_1] --- I3[Item 3]
        S1 --- I5[Item 5]
        S1 --- I7[Item 7]
        S1 --- I8[Item 8]
        
        S2[Skill_2] --- I2[Item 2]
        S2 --- I4[Item 4]
        S2 --- I6[Item 6]
        
        S3[Skill_3] --- I1[Item 1]
    end
    
    style Final_Q_Matrix_Mappings fill:#bfb,stroke:#333,stroke-width:2px
```
<figcaption style="font-size: 0.9em; color: #555555; text-align: left; margin-top: 8px;">
    Diagram 3: Final Q-Matirx
</figcaption>
<br>

### Key Strengths of the Final Q-Matrix and Diagram
1. **Clear Mapping**:
   - Each item is assigned to the skill with the highest loading, ensuring that the relationships are driven by the statistical analysis.
   - The diagram visually highlights these relationships, making it easy to understand and communicate the structure.

2. **Skill Representation**:
   - **Skill 1**: Represented by four items (**Item 3**, **Item 5**, **Item 7**, and **Item 8**), providing robust coverage and reliability for assessing this skill.
   - **Skill 2**: Supported by three items (**Item 2**, **Item 4**, and **Item 6**), with **Item 6** being the strongest indicator.
   - **Skill 3**: Represented by **Item 1**, a highly specific item exclusively aligned with this skill.

3. **Alignment with Analyses**:
   - The Q-matrix directly reflects the findings from the Factor Analysis heatmap and bar charts, ensuring consistency and validation of the mappings.

4. **Balanced Complexity**:
   - By selecting three components, the Q-matrix strikes a balance between interpretability and detail, avoiding the over-complexity of a four-component model while capturing nuances missed in a two-component model.

### Observations and Recommendations
1. **Strength of Item Representation**:
   - **Skill 3** relies on a single item (**Item 1**). While **Item 1** has a strong loading, additional items may be needed to ensure the skill is robustly assessed.
   - **Skill 2** shows moderate contributions from **Item 2** and **Item 4**, which might require review to ensure their alignment with this skill.

2. **Ambiguous Items**:
   - **Item 5** has a mixed loading (moderate on **Skill 1** and **Skill 3**), but its assignment to **Skill 1** aligns well with the overall structure.
   - **Item 4** has weaker loadings but is still included under **Skill 2**, reflecting its statistical alignment while acknowledging its relative ambiguity.

### Utility of the Diagram
The diagram is an excellent tool for:

- Communicating the Q-matrix to stakeholders (e.g., educators, researchers) in a visually intuitive format.
- Supporting discussions about item revisions or further refinements to the skill structure.
- Illustrating the rationale for skill-specific interventions or curriculum changes.

### Model Evaluation Metrics

#### Calculating Proportion of Variance Explained ($R^2$)

**For Factor Analysis**:

```{python}
# Compute the communalities
communalities = fa_model.get_communalities()

# Total variance explained
total_variance_explained = np.sum(communalities)

# Total variance (number of variables)
total_variance = item_data_scaled.shape[1]

# Proportion of variance explained
r_squared_fa = total_variance_explained / total_variance

print(f"Factor Analysis R^2: {r_squared_fa:.2f}")
```

**Interpretation:**

- The $R^2$ value of **0.56** indicates that the three-factor model explains **56%** of the total variance in the data.
- **Implications:**
  - A proportion of variance explained greater than 50% is generally considered acceptable in exploratory Factor Analysis, especially with psychological or educational data where constructs are often complex.
  - However, it also suggests that **44%** of the variance is not explained by the model, which may be due to measurement error, unique variance of items, or additional latent factors not captured by the model.

**For PCA**:

```{python}
# Calculate cumulative variance explained
cumulative_variance = np.cumsum(pca_model.explained_variance_ratio_)
print(f"PCA cumulative variance explained by first 3 components: {cumulative_variance[2]:.2f}")
```

**Interpretation:**

- The first three principal components explain **66%** of the total variance in the data.
- **Implications:**
  - This indicates a slightly better variance explanation than the Factor Analysis model.
  - PCA aims to capture the maximum variance with the fewest components, so a higher cumulative variance explained is desirable.
  - However, PCA components may not be as interpretable as factors from Factor Analysis, since PCA components are linear combinations that maximize variance without considering underlying latent constructs.

**Comparison:**

- The PCA model explains more variance (66%) compared to the Factor Analysis model (56%).
- This difference may be due to the methodological differences between PCA and Factor Analysis:
  - **PCA** focuses on capturing variance and is sensitive to the scale of the data.
  - **Factor Analysis** models the underlying latent constructs and accounts for measurement error.

**Considerations:**

- **Adequacy of Variance Explained:**
  - In social sciences, cumulative variance explained between 50% and 75% is generally acceptable.
  - Both models fall within this range, but there is room for improvement.
- **Unexplained Variance:**
  - The unexplained variance suggests that additional factors or components might exist, or that some items do not fit well within the identified latent skills.

#### Calculating Cohen's Kappa Coefficient

```{python}
from sklearn.metrics import confusion_matrix
from scipy.optimize import linear_sum_assignment

# Map skill labels to numeric codes for Factor Analysis
fa_skill_codes = final_q_matrix_df['Mapped_Skill'].map({'Skill_1': 0, 'Skill_2': 1, 'Skill_3': 2}).values

# K-Means cluster labels
kmeans_labels = kmeans.labels_

# Compute confusion matrix
confusion = confusion_matrix(fa_skill_codes, kmeans_labels)
print("Confusion Matrix:")
print(confusion)

# Align clusters with skills using the Hungarian algorithm
row_ind, col_ind = linear_sum_assignment(-confusion)
mapping = dict(zip(col_ind, row_ind))

# Map K-Means labels to Factor Analysis skill codes
kmeans_labels_mapped = np.array([mapping[label] for label in kmeans_labels])

# Compute Cohen's kappa
from sklearn.metrics import cohen_kappa_score

kappa = cohen_kappa_score(fa_skill_codes, kmeans_labels_mapped)
print(f"Cohen's kappa after alignment: {kappa:.2f}")
```

**Interpretation:**

- **Confusion Matrix:**
  - The confusion matrix shows perfect agreement between the methods after alignment:
    - All items assigned to Skill 1 in Factor Analysis are also assigned to the corresponding cluster in K-Means.
    - The same applies to Skills 2 and 3.
- **Cohen's Kappa Value:**
  - A Kappa value of **1.00** indicates **perfect agreement** between the two methods after alignment.
- **Implications:**
  - This high level of agreement suggests that both methods are consistently identifying the same underlying item-skill structures.
  - It provides strong validation for the robustness of your item-skill mappings.

**Considerations:**

- **Alignment Step:**
  - The necessity of aligning clusters to skills underscores that cluster labels are arbitrary.
  - It's important to perform this alignment to make meaningful comparisons.

- **Cohen's Kappa Interpretation:**
  - Kappa values range from -1 to 1, where:
    - **< 0**: Less than chance agreement.
    - **0–0.20**: Slight agreement.
    - **0.21–0.40**: Fair agreement.
    - **0.41–0.60**: Moderate agreement.
    - **0.61–0.80**: Substantial agreement.
    - **0.81–1.00**: Almost perfect agreement.
  - A value of **1.00** confirms that the two methods are in complete concordance post-alignment.

### **Overall Evaluation**

**Strengths:**

- **Converging Evidence:**
  - The high Cohen's Kappa value indicates that different analytical methods converge on the same item-skill mappings, enhancing confidence in your results.
- **Variance Explained:**
  - Both Factor Analysis and PCA explain a substantial portion of the variance, supporting the validity of the three-component model.
- **Methodological Rigor:**
  - Your approach of using multiple methods and comparing them through quantitative metrics strengthens the robustness of your findings.

**Limitations:**

- **Variance Not Explained:**
  - Approximately 34% to 44% of the variance remains unexplained, which could be due to:
    - Measurement error.
    - Additional latent skills not captured by the model.
    - Unique variances of items.
- **Assumptions of Methods:**
  - Factor Analysis and PCA assumptions may not be fully met with binary data, which could affect the variance explained.

#### Verifying Item-Skill Mappings

```{python}
print("Factor Analysis Mappings:")
print(final_q_matrix_df)
```

**Interpretation:**

- **Item Assignments**: Each item is assigned to the skill with which it has the highest factor loading from your final Q-matrix.
- **Skill Representation**:
  - **Skill_1**: Items 3, 5, 7, 8
  - **Skill_2**: Items 2, 4, 6
  - **Skill_3**: Item 1

**Significance:**

- **Consistent Mapping**: The assignments reflect the conclusions drawn from your Factor Analysis, where items are mapped based on dominant loadings.
- **Foundation for Comparison**: These mappings serve as the reference point for comparing with the K-Means Clustering results.

```{python}
print("\nK-Means Clustering Mappings (before alignment):")
print(kmeans_q_matrix_df)
```

**Interpretation:**

- **Cluster Assignments**: Items are assigned to clusters labeled as Skill_1, Skill_2, or Skill_3, based on the K-Means Clustering algorithm.
- **Arbitrary Labels**: The cluster labels (e.g., Skill_1, Skill_2) are assigned by the algorithm and do not necessarily correspond to the skills identified in Factor Analysis.

**Significance:**

- **Initial Comparison**: At first glance, the mappings appear similar to the Factor Analysis mappings, but due to arbitrary labeling, a direct comparison isn't meaningful yet.
- **Need for Alignment**: To accurately compare the item-skill assignments, cluster labels must be aligned with the skills from Factor Analysis.

```{python}
# Map clusters to skills after alignment
kmeans_skill_names_aligned = ['Skill_' + str(mapping[label] + 1) for label in kmeans_labels]
kmeans_q_matrix_df_aligned = kmeans_q_matrix_df.copy()
kmeans_q_matrix_df_aligned['Mapped_Skill'] = kmeans_skill_names_aligned
```

**Process:**

- **Alignment Using the Hungarian Algorithm**:
  - Since cluster labels are arbitrary, you used the **Hungarian algorithm** (also known as the **linear sum assignment method**) to find the optimal one-to-one mapping between clusters and skills.
  - This algorithm minimizes the total disagreement between the two sets of labels.

- **Mapping Clusters to Skills**:
  - You created a mapping dictionary (`mapping`) that aligns each cluster label with the corresponding skill from Factor Analysis.
  - This ensures that clusters are correctly interpreted in the context of your identified skills.

```{python}
print("\nK-Means Clustering Mappings (after alignment):")
print(kmeans_q_matrix_df_aligned)
```

**Interpretation:**

- **Aligned Assignments**: After alignment, the cluster labels now correspond to the same skills as in the Factor Analysis mappings.
- **Perfect Agreement**: The item-skill assignments from K-Means Clustering now match exactly with those from Factor Analysis.

**Significance:**

- **Validation of Consistency**: The perfect match indicates strong agreement between the two methods.
- **Robustness of Findings**: The consistency across methods reinforces the reliability of your item-skill mappings.

## Discussion

### Overview of Model Comparison and Selection

#### Model Complexity and Interpretability

After comparing models with two, three, and four components, the **three-component Factor Analysis model** emerged as the most suitable representation of the latent skills in the dataset.

**Two-Component Model**

- **Simplicity:** The two-component model is the simplest, reducing the latent skills to two factors.
- **Interpretability:**
  - Some items showed weak loadings or ambiguous associations.
  - **Item 1**, for example, had very low loadings on both factors, suggesting it doesn't fit well within this model.
- **Implications:**
  - The model may be too simplistic, failing to capture important nuances in the data.
  - It potentially merges distinct skills into broader categories, which could obscure meaningful distinctions.

**Three-Component Model**

- **Balance:** Offers a middle ground between simplicity and complexity.
- **Interpretability:**
  - Provides clear and distinct latent skills.
  - Most items load strongly on a single factor, enhancing interpretability.
- **Findings:**
  - The model captures the nuances in the data without unnecessary complexity.
  - **Item 5** shows moderate loadings on two skills, indicating split influences but remains interpretable.

**Four-Component Model**

- **Complexity:** Introduces additional complexity with a fourth factor.
- **Interpretability:**
  - Overlapping loadings make the model harder to interpret.
  - Some items load significantly on multiple factors, causing ambiguity.
- **Implications:**
  - The added complexity doesn't substantially increase explained variance.
  - May overfit the data, capturing noise rather than meaningful structure.

**Summary:**

- **Trade-Offs:**
  - The **two-component model** may underfit, missing key distinctions between skills.
  - The **four-component model** may overfit, adding unnecessary complexity without practical benefits.
- **Optimal Complexity:**
  - The **three-component model** strikes a balance, capturing essential structures while maintaining interpretability.

#### Variance Explained and Model Fit

**Factor Analysis Variance Explained**

- **Two-Component Model:**
  - Lower proportion of variance explained (~ less than 56%).
  - Indicates insufficient capture of the data's variability.
- **Three-Component Model:**
  - Explains approximately **56%** of the total variance.
  - Represents a reasonable fit for exploratory purposes.
- **Four-Component Model:**
  - Slight increase in variance explained.
  - Not significant enough to justify added complexity.

**PCA Variance Explained**

- **Three-Component Model:**
  - Cumulative variance explained is **66%**.
  - Indicates a substantial capture of data variability.
- **Comparison:**
  - PCA generally explains more variance than Factor Analysis in your findings.
  - However, PCA components may not be as interpretable in terms of latent skills.

**Summary:**

- **Thresholds:**
  - In social sciences, explaining around 50-75% variance is acceptable.
- **Diminishing Returns:**
  - The variance explained by adding a fourth component doesn't justify the increased complexity.
- **Model Fit:**
  - The three-component model provides an acceptable fit with reasonable simplicity.

#### Consistency Across Methods

**Agreement Among Methods**

- **Three-Component Model:**
  - High consistency in item-skill mappings across Factor Analysis, K-Means Clustering, and PCA.
  - **Cohen's Kappa Coefficient** of **1.00** after alignment indicates perfect agreement.
- **Two- and Four-Component Models:**
  - Less consistent across methods.
  - Ambiguities in item assignments due to overlapping loadings.

**Summary:**

- **Cross-Validation:**
  - Consistency strengthens the validity of your findings.
- **Reinforcement:**
  - Different methods converging on the same solution supports the robustness of the three-component model.
- **Practical Implications:**
  - A consistent model is more reliable for educational applications, such as test design and interpretation.

#### Model Evaluation Metrics

**Proportion of Variance Explained ($R^2$)**

- **Factor Analysis:**
  - **Three-Component Model $R^2$:** Approximately **0.56**.
  - Indicates that 56% of the variance is captured by the model.
- **PCA:**
  - **Three-Component Model Cumulative Variance:** **66%**.
  - Suggests a better variance capture, but PCA components may be less interpretable.

**Cohen's Kappa Coefficient**

- **Value:** **1.00** after alignment.
- **Interpretation:**
  - Indicates perfect agreement between item-skill mappings from Factor Analysis and K-Means Clustering.
- **Significance:**
  - Validates the consistency and reliability of the three-component model.

**Summary:**

- **Balance of Metrics:**
  - The three-component model provides a good balance between variance explained and interpretability.
- **Limitations:**
  - Acknowledge that a portion of variance remains unexplained.
  - Suggests potential areas for further investigation or alternative modeling approaches.

#### Final Model Selection

**Reasons for Selecting the Three-Component Model**

- **Optimal Balance:**
  - Captures essential structures without overcomplicating the model.
- **High Interpretability:**
  - Clear item-skill relationships make it practical for educational use.
- **Strong Validation:**
  - Consistent findings across multiple methods reinforce its selection.
- **Model Performance:**
  - Satisfactory variance explained and perfect agreement in item assignments.

**Implications for the Q-Matrix**

- **Robust Mapping:**
  - The final Q-matrix derived from the three-component model provides a reliable item-skill mapping.
- **Educational Utility:**
  - Enhances interpretability of test results.
  - Aids in identifying areas for instructional focus and intervention.

### Justification for the Final Q-Matrix

#### Derivation from Multiple Methods

**Integration of Analytical Findings**

- **Factor Analysis**: The Final Q-Matrix is primarily based on the results of your three-component Factor Analysis, where each item is assigned to the skill with the highest factor loading.

- **K-Means Clustering** and **PCA**: The item-skill mappings derived from these methods align closely with the Factor Analysis results, reinforcing the assignments in the Final Q-Matrix.

  - **Consistency in Item Groupings**: Items that cluster together in K-Means and load on the same principal components in PCA correspond to the same skills identified in Factor Analysis.

**Justification**:

- **Converging Evidence**: The consistent findings across multiple methods provide strong evidence that the item-skill assignments in the Final Q-Matrix accurately reflect the underlying knowledge structure.

- **Robustness**: Using different analytical techniques reduces the likelihood that the results are artifacts of a specific method, increasing confidence in the Q-Matrix.

#### Support from Model Evaluation Metrics

**Variance Explained**

- **Factor Analysis $R^2$**: The three-component model explains approximately **56%** of the total variance.

- **PCA Variance**: The first three principal components account for **66%** of the variance.

**Cohen's Kappa Coefficient**

- **Value of 1.00**: Indicates perfect agreement between the item-skill mappings from Factor Analysis and K-Means Clustering after alignment.

**Justification**:

- **Adequate Model Fit**: The proportion of variance explained suggests that the model captures a substantial amount of the data's variability, which is acceptable in exploratory analyses.

- **Validation of Mappings**: The perfect Cohen's Kappa score confirms that different methods agree on the item-skill assignments, supporting the validity of the Final Q-Matrix.

#### Balance of Complexity and Interpretability

**Model Selection**

- **Three-Component Model**: Chosen for providing the best balance between capturing sufficient detail and maintaining simplicity.

**Justification**:

- **Avoiding Overfitting**: The four-component model introduced complexity without significant gains in variance explained, making it less interpretable.

- **Preventing Oversimplification**: The two-component model failed to capture important nuances, with some items not fitting well.

- **Practical Interpretability**: The three-component model allows for clear and distinct item-skill relationships, making the Q-Matrix practical for educational purposes.

#### Consistency Across Analytical Methods

**Alignment of Results**

- **Factor Analysis, K-Means Clustering, and PCA** all indicate similar item-skill groupings.

**Visualizations**

- **Mermaid Diagrams and Heatmaps**: Provide visual confirmation of the consistent item-skill relationships across methods.

**Justification**:

- **Cross-Method Validation**: Consistency across methods strengthens the argument that the Final Q-Matrix accurately represents the latent skills.

- **Reinforcement of Findings**: Visual tools help illustrate the robustness of the mappings, making the justification more compelling.

#### Educational Relevance and Practicality

**Clear Skill Definitions**

- **Skill 1**: Represented by items that measure a specific aspect of the knowledge domain (e.g., problem-solving).

- **Skill 2**: Comprised of items assessing another distinct competency (e.g., conceptual understanding).

- **Skill 3**: Associated with an item measuring a unique skill (e.g., factual recall).

**Justification**:

- **Actionable Insights**: The Q-Matrix provides educators with clear information about which items assess which skills, facilitating targeted instruction and remediation.

- **Test Design Improvement**: Understanding item-skill relationships helps in refining assessments to better measure the intended skills.

- **Educational Impact**:
  - By understanding the relationships between items and skills, test designers can create assessments that more effectively target specific skills, ensuring a balanced coverage of the identified latent skills. The item-skill mappings can also help identify potentially redundant or less informative items, allowing for more efficient and focused assessments.
  - Moreover, educators can leverage the findings to diagnose student strengths and weaknesses at the skill level. The identification of specific skills associated with each item enables targeted remediation or enrichment activities, focusing on the areas where students may need additional support. This information can also guide the development of instructional materials and resources, ensuring that students have ample opportunities to practice and master the identified skills.

### Limitations and Future Work

Despite the insights provided by this study, there are limitations to consider.

**Acknowledging Split Influences**

- **Item 5**: Exhibits moderate loadings on both Skill 1 and Skill 3.

**Justification**:

- **Assignment Based on Dominant Loading**: Despite the split influence, Item 5 is assigned to Skill 1 due to its higher loading, aligning with the overall structure.

- **Consideration for Revision**: Recognizing the split influence allows for potential item revision to enhance its alignment with a single skill.

**Ensuring Skill Representation**

- **Skill 3**: Currently represented by a single item (Item 1).

**Justification**:

- **Recognition of Limitations**: Acknowledging that Skill 3 relies on a single item highlights an area for potential expansion in future assessments.

- **Maintaining Integrity**: Despite the limited representation, the strong loading of Item 1 on Skill 3 justifies its inclusion in the Q-Matrix.

- **Binary Data Consideration**:
  - The use of Factor Analysis and PCA on binary data may not fully meet the assumptions of these methods. Future research could explore the application of Item Response Theory (IRT) models specifically designed for analyzing binary response data [@van2015handbook].

- **Sample Size and Generalizability**:
  - The small sample size of eight items limits the generalizability of the findings. Replicating the study with a larger set of items and a more diverse student population would help validate the identified skill structure and its applicability to different educational contexts.

## Conclusion

This study makes significant contributions to the field of educational assessment and learning analytics by demonstrating the effectiveness of a comprehensive, multi-method approach for uncovering the latent skill structure in an eight-item test dataset. I have identified a robust and interpretable three-skill model that best represents the underlying knowledge structure by leveraging the complementary strengths of **Factor Analysis**, **K-Means Clustering**, and **Principal Component Analysis (PCA)**.

The key findings of this study include:

1. The identification of three distinct latent skills that capture the essential relationships among the test items.
2. Developing a final **Q-matrix** that provides a precise and empirically derived mapping of items to skills consistent across multiple analytical methods.
3. Validating of the item-skill relationships supports the interpretability of the identified skill structure.

The practical significance of this work lies in its potential to inform and enhance educational assessment and instructional practices. By providing a more precise understanding of the skills assessed by individual test items, this study enables educators and test designers to:

- Develop more targeted and efficient assessments that effectively measure specific skills.
- Identify areas where students may need additional support or remediation based on their performance on skill-related items.
- Design instructional interventions and resources that align with the identified skill structure, promoting more personalized and adaptive learning experiences.

Moreover, the multi-method approach presented in this study serves as a valuable template for future research in educational data mining and learning analytics. Researchers can build upon this methodology to investigate the knowledge structures underlying different types of assessments, learning materials, and educational contexts.

Future research should focus address this study's limitations and explore new avenues for extending its findings. Specific opportunities include:

1. Applying Item Response Theory (IRT) models are specifically designed to analyze binary response data, to validate and refine the identified skill structure.
2. Replicating the study with larger and more diverse datasets, including assessments with a greater number of items and student populations from various educational backgrounds.
3. Investigating the generalizability of the identified skill structure across different domains, grade levels, and assessment formats.
4. Exploring the integration of the derived Q-matrix with adaptive learning systems and intelligent tutoring platforms to enable real-time, skill-based feedback and personalized learning paths.

By addressing these challenges and opportunities, future research can further advance our understanding of knowledge structure mapping and its applications in educational settings, ultimately contributing to the development of more effective and equitable learning experiences for all students.

### Submission Guidelines

This document includes all required explanations. The code and data are organized to facilitate replication and further analysis. Please let me know if additional information is needed.