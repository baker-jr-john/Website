{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "pagetitle: \"John Baker – Learning Analytics\"\n",
        "title: \"Knowledge Structure Mapping: Comprehensive Report\"\n",
        "description: \"An in-depth exploration of knowledge structure mapping using Factor Analysis, KMeans clustering, and PCA to uncover latent skills in an eight-item test dataset.\"\n",
        "date: 2024-11-20\n",
        "# date-modified: \n",
        "author: \n",
        "  - name: John Baker\n",
        "    email: jbaker1@upenn.edu\n",
        "    affiliation:\n",
        "      - name: \"Penn GSE: University of Pennsylvania Graduate School of Education\"\n",
        "        url: https://www.gse.upenn.edu/\n",
        "abstract: |\n",
        "  This study aims to identify the underlying knowledge structure of an eight-item test dataset by applying Factor Analysis, KMeans clustering, and Principal Component Analysis (PCA). Factor Analysis was utilized to uncover latent skills, with results cross-validated using KMeans clustering (simulating Barnes's Q-Matrix method) and PCA. Models with two to four components were compared to determine the optimal skill representation. The findings indicate that a three-component Factor Analysis model best captures the relationships among test items, effectively identifying three distinct skills. The final Q-matrix balances complexity and interpretability, providing a robust mapping of items to latent skills and enhancing the understanding of the dataset's knowledge structure.\n",
        "keywords:\n",
        "  - knowledge structure mapping\n",
        "  - Factor Analysis\n",
        "  - Q-matrix\n",
        "  - latent skills\n",
        "  - PCA\n",
        "bibliography: bibliography/bibliography.bib\n",
        "nocite: |\n",
        "  @*\n",
        "# image: images/image_fx_.png\n",
        "format:\n",
        "  html:\n",
        "    code-link: false\n",
        "draft: true\n",
        "jupyter: python3\n",
        "ipynb-shell-interactivity: all\n",
        "execute: \n",
        "  freeze: false\n",
        "---\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Imagine if educators could uncover the hidden connections between what students know and what they're tested on. This is the power of knowledge structure mapping. **Knowledge structure mapping** allows educators and researchers to uncover the relationships between test items and the underlying skills or concepts they measure. This understanding is crucial for developing effective educational tools, improving assessment strategies, and tailoring instruction to meet individual student needs. By mapping how different items relate to latent skills, educators can identify areas where students may struggle and provide targeted interventions.\n",
        "\n",
        "Determining the optimal representation of latent skills within limited test data is challenging, as traditional methods often rely on assumptions that may not generalize across educational contexts or assessment types. Therefore, there is a need for robust, data-driven approaches that can accurately identify and validate the underlying skill structures in assessment data.\n",
        "\n",
        "This study addresses this gap by investigating the knowledge structure underlying an eight-item test dataset using a comprehensive methodology that balances model complexity and interpretability. By combining advanced statistical and machine learning techniques—specifically, **Factor Analysis** to uncover latent skills, **KMeans clustering** to simulate Barnes's Q-Matrix method for grouping items, and **Principal Component Analysis (PCA)** to validate the identified item-skill relationships—I aim to robustly identify the underlying skill structures. To determine the optimal skill representation, I compare models with varying numbers of components, from two to four, seeking a balance between capturing sufficient detail and maintaining simplicity for educational interpretation and application. The resulting **Q-matrix** derived from this multi-method approach offers a clear, empirically-derived mapping of items to latent skills, enhancing the interpretability and utility of test results for educators and researchers.\n",
        "\n",
        "My approach contributes to the existing body of research by providing a comprehensive methodology that balances complexity with interpretability. The final **Q-matrix** derived from my analysis offers a robust mapping of items to latent skills, enhancing the interpretability of test results. This study not only demonstrates the effectiveness of combining multiple analytical methods for knowledge structure mapping but also provides insights that can inform the development of more nuanced educational assessments and personalized learning strategies.\n",
        "\n",
        "## Background and Related Work\n",
        "\n",
        "**Knowledge structure mapping** is a fundamental process in educational data mining that involves analyzing and visualizing learners' conceptual understanding and cognitive organization of information [@gordon2003learning]. It enables educators and researchers to represent relationships between different pieces of knowledge, facilitating the development of personalized learning experiences and more effective educational tools.\n",
        "\n",
        "### Methods for Knowledge Structure Mapping\n",
        "\n",
        "Several methods have been developed to map knowledge structures, each with its own advantages and limitations. **Learning Factors Analysis (LFA)** is one such method used to evaluate and refine cognitive models [@cen2006learning]. LFA leverages student performance data to improve the accuracy of these models, thereby enhancing personalized learning by tailoring instruction to individual student needs.\n",
        "\n",
        "**Partial Order Knowledge Spaces (POKS)** provide another powerful framework for representing knowledge structures [@desmarais2006learned]. POKS uses partially ordered sets of skills to model how knowledge builds upon itself. For example, mastering addition might be a prerequisite for learning multiplication, reflecting the hierarchical nature of certain learning processes.\n",
        "\n",
        "Another widely used method for knowledge structure mapping is **Factor Analysis**, a statistical technique widely used in knowledge structure mapping to uncover hidden relationships between observed variables—such as test items—and underlying latent variables—such as skills [@beavers2019practical]. By analyzing correlations among test items, Factor Analysis can reveal clusters of items that measure the same underlying skill. This data-driven approach helps in identifying latent skills without requiring prior knowledge of the skill structure.\n",
        "\n",
        "While Factor Analysis and PCA rely on statistical techniques, **Barnes's Q-matrix method** takes a different approach. It is a specific technique for representing the relationship between items and skills using a binary matrix [@barnes2005q]. In this matrix, rows represent test items, columns represent skills, and entries indicate whether a skill is required for a particular item. The Q-matrix provides a visual and analytical tool for understanding which skills are assessed by each item, and it is widely used in cognitive modeling and educational data mining.\n",
        "\n",
        "**KMeans Clustering** can simulate the Q-matrix method by grouping items based on response patterns without prior knowledge of the skill structure. By clustering items that have similar response profiles, researchers can infer potential underlying skills that explain these patterns. This unsupervised learning approach allows for the exploration of latent skill groupings in the absence of predefined skill mappings.\n",
        "\n",
        "**Principal Component Analysis (PCA)** is another statistical method employed in knowledge structure mapping to reduce the dimensionality of data while preserving as much variance as possible. PCA identifies principal components, which are linear combinations of the original variables (test items), and these components can be interpreted as underlying skills or factors influencing student performance. PCA helps in validating the item-skill relationships identified through other methods like Factor Analysis by providing an alternative perspective on the data's structure.\n",
        "\n",
        "These methods collectively provide a toolbox for researchers to uncover the underlying structure of knowledge in educational data.\n",
        "\n",
        "### Applications in Educational Data Mining\n",
        "\n",
        "The knowledge structure mapping methods discussed above have found wide application in educational data mining, including:\n",
        "\n",
        "- **Intelligent Tutoring Systems (ITSs):** Knowledge structure mapping is crucial for ITSs to personalize instruction and provide tailored feedback based on individual student performance and identified skill gaps [@de2008educational].\n",
        "\n",
        "- **Predicting Student Performance:** Understanding knowledge structures enables the prediction of student performance on assessments and helps in identifying students who are at risk of falling behind, allowing for timely interventions [@de2008educational].\n",
        "\n",
        "- **Analyzing Student Behavior:** Knowledge structure mapping can be used to analyze student behavior patterns, such as help-seeking actions, providing insights into how students approach learning tasks and where they may encounter difficulties [@cukurova2022learning].\n",
        "\n",
        "The importance of using data-driven approaches, such as Factor Analysis, KMeans clustering, and PCA, lies in their ability to uncover patterns and relationships that might not be apparent through traditional methods [@chen2018knowedu]. These techniques allow researchers to identify latent skills and understand how knowledge is organized within a dataset, which can be applied to improve educational practices and assessment designs.\n",
        "\n",
        "### Limitations and Challenges\n",
        "\n",
        "Despite their utility, each knowledge structure mapping method has its limitations. Factor Analysis and PCA typically assume that the data are continuous and normally distributed, which may not always be the case with binary test item responses. KMeans clustering requires the specification of the number of clusters in advance and may not capture complex, hierarchical relationships between items and skills. Despite these limitations, when used in combination, these methods can provide a robust analysis of knowledge structures by cross-validating findings and offering complementary insights.\n",
        "\n",
        "## Methods Used\n",
        "\n",
        "### Overview\n",
        "\n",
        "This study employs a combination of statistical and machine learning techniques—**Factor Analysis**, **KMeans Clustering**, and **Principal Component Analysis (PCA)**—to uncover the latent skills underlying an eight-item test dataset. Each method offers unique insights into the data, and their combined use allows for a comprehensive analysis of the knowledge structure. Each technique complements and validates the findings of the others, contributing to a robust understanding of the underlying skill structure.\n",
        "\n",
        "### Factor Analysis\n",
        "\n",
        "**Factor Analysis** was chosen as the primary method to discover the underlying latent skills measured by the test items. This statistical technique identifies factors (latent variables) that explain the patterns of correlations among observed variables (test items). By reducing the dimensionality of the data, Factor Analysis helps reveal the structure of the latent skills that influence student performance.\n",
        "\n",
        "**Rationale**:\n",
        "\n",
        "- **Data-Driven Identification and Correlation Structure**: Given the exploratory nature of this study and the aim to uncover latent skills, Factor Analysis is an appropriate choice, as it does not require prior knowledge of the skill structure and can effectively capture the underlying correlation patterns among test items.\n",
        "\n",
        "**Assumptions and Justifications**:\n",
        "\n",
        "- **Binary Data Consideration and Sample Size Adequacy**: Although Factor Analysis traditionally assumes continuous and normally distributed data, its application to binary data is acceptable in exploratory contexts, particularly when the sample size is sufficient, as in this study.\n",
        "- **Number of Factors**: I initially selected three factors based on the expectation of three underlying skills. To ensure robustness, models with two and four factors were also tested to explore alternative structures.\n",
        "\n",
        "### Barnes's Q-Matrix Method (Simulated using KMeans Clustering)\n",
        "\n",
        "**KMeans Clustering** is used to simulate **Barnes's Q-Matrix method**, providing an alternative perspective on item groupings based on response patterns, without imposing prior assumptions about the skill structure. This allows for a data-driven validation of the Factor Analysis results.\n",
        "\n",
        "**Rationale**:\n",
        "\n",
        "- **Unsupervised Learning**: KMeans Clustering groups items based on similarity in response patterns without prior assumptions about the skill structure, effectively simulating the Q-matrix creation.\n",
        "- **Cross-Validation**: It provides an alternative perspective on item groupings, allowing us to validate the findings from Factor Analysis.\n",
        "\n",
        "**How KMeans Clustering Simulates the Q-Matrix Method**:\n",
        "\n",
        "- **Item Clustering**: By clustering items that have similar response patterns across students, KMeans Clustering effectively groups items that may require the same underlying skill.\n",
        "- **Skill Inference**: Each cluster represents a group of items that are likely associated with a common skill, analogous to columns in the Q-matrix.\n",
        "\n",
        "**Assumptions and Justifications**:\n",
        "\n",
        "- **Number of Clusters**: I set the number of clusters to three, consistent with the initial number of factors in Factor Analysis, to facilitate comparison.\n",
        "- **Distance Metric**: The default Euclidean distance is used, as it is suitable for capturing the similarity of response patterns in binary data.\n",
        "\n",
        "### Principal Component Analysis (PCA)\n",
        "\n",
        "**Principal Component Analysis (PCA)** is employed as an additional method to validate the item-skill relationships identified through Factor Analysis and KMeans Clustering. By examining the variance explained by each principal component, PCA helps confirm the significance of the identified latent skills.\n",
        "\n",
        "**Rationale**:\n",
        "\n",
        "- **Alternative Dimensionality Reduction**: PCA offers an alternative method for identifying underlying structures in the data, providing a means to cross-validate findings from Factor Analysis.\n",
        "- **Variance Explanation**: By examining the amount of variance explained by each principal component, I can infer the significance of the underlying skills.\n",
        "\n",
        "**Assumptions and Justifications**:\n",
        "\n",
        "- **Binary Data Consideration**: While PCA assumes continuous data, its application to binary data is acceptable for exploratory purposes, particularly when used in conjunction with other methods that can validate its findings.\n",
        "- **Number of Components**: Three principal components were extracted to maintain consistency with the other methods and to facilitate direct comparison.\n",
        "\n",
        "### Model Iteration and Comparison\n",
        "\n",
        "To determine the optimal skill representation, I iteratively tested models with varying numbers of components—two, three, and four—across all methods.\n",
        "\n",
        "**Rationale**:\n",
        "\n",
        "- **Exploring Complexity**: Testing multiple models allows us to explore how the complexity of the model affects the interpretability and explanatory power of the latent skills.\n",
        "- **Avoiding Overfitting and Oversimplification**: By comparing models with different numbers of components, I aim to find a balance between capturing sufficient detail and maintaining simplicity.\n",
        "\n",
        "**Assumptions and Justifications**:\n",
        "\n",
        "- **Consistency Across Methods**: Maintaining the same number of components or clusters across different methods aids in comparing and validating the results.\n",
        "- **Interpretability Priority**: The selection of the optimal model is guided by the interpretability of the results, ensuring that the identified skills make practical sense in the context of educational assessment.\n",
        "\n",
        "### Data Preparation and Preprocessing\n",
        "\n",
        "Before applying the methods, the data are prepared and preprocessed to ensure accurate analysis.\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "- **Data Loading**: The dataset is loaded using pandas, containing binary responses (correct or incorrect) for eight test items across multiple students.\n",
        "- **Item Data Extraction**: The 'student' identifier column is excluded to focus on item responses.\n",
        "- **Data Transformation**: For KMeans Clustering, the item data were transposed to cluster items rather than students.\n",
        "\n",
        "**Assumptions and Justifications**:\n",
        "\n",
        "- **Data Quality**: It is assumed that the data are accurate and free from errors or missing values, which is critical for the validity of the analyses.\n",
        "- **Binary Nature of Responses**: The binary nature of the item responses is considered in the selection and application of methods, acknowledging potential limitations.\n",
        "\n",
        "### Summary of Methodological Approach\n",
        "\n",
        "By leveraging the strengths of Factor Analysis, KMeans Clustering, and PCA, this study employs a multi-method approach that mitigates the limitations of individual techniques.\n",
        "\n",
        "- **Factor Analysis** identifies latent skills based on correlation structures.\n",
        "- **KMeans Clustering** groups items based on response pattern similarities without prior assumptions.\n",
        "- **PCA** validates the findings by identifying principal components that explain the most variance.\n",
        "\n",
        "This approach enhances the reliability and robustness of the knowledge structure mapping, providing a comprehensive understanding of the latent skills assessed by the test items.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "### Data Preparation\n",
        "\n",
        "#### Loading the Data\n",
        "\n",
        "To begin the analysis, I loaded the dataset containing binary responses (correct or incorrect) for eight test items from multiple students. The `pandas` library is used for data manipulation due to its efficiency and ease of use with tabular data.\n"
      ],
      "id": "4db9dd4c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('data/8items.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ],
      "id": "4c8f65fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Data Loading**: The dataset `8items.csv` is read into a pandas dataframe called `data`.\n",
        "- **Data Inspection**: Using `data.head()`, I display the first few rows to verify that the data has been loaded correctly.\n",
        "\n",
        "#### Data Exploration\n",
        "\n",
        "Before proceeding, I explored the data to understand its structure and check for anomalies.\n"
      ],
      "id": "d8fd3a2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check the dimensions of the dataset\n",
        "print(f\"Dataset dimensions: {data.shape}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values in each column:\")\n",
        "print(data.isnull().sum())"
      ],
      "id": "dffb3209",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Dataset Dimensions**: I print the shape of the dataframe to confirm the number of students (rows) and items (columns).\n",
        "- **Missing Values**: I check for any missing values that could affect the analysis.\n",
        "\n",
        "**Findings**:\n",
        "\n",
        "- The dataset has the expected dimensions with no missing values, indicating that it is ready for analysis.\n",
        "\n",
        "### Factor Analysis\n",
        "\n",
        "#### Preparing Data for Factor Analysis\n",
        "\n",
        "I extracted the item response data, excluding any non-item columns such as 'student' identifiers.\n"
      ],
      "id": "0e7ac325"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract item data (excluding the 'student' column if present)\n",
        "item_data = data.drop(columns=['student'], errors='ignore')"
      ],
      "id": "d8639543",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Data Extraction**: I drop the 'student' column to focus solely on the item responses.\n",
        "- **Error Handling**: The `errors='ignore'` parameter ensures that if the 'student' column is not present, the code will not raise an error.\n",
        "\n",
        "#### Performing Factor Analysis\n",
        "\n",
        "I apply Factor Analysis with three components to identify latent skills in the dataset. The `FactorAnalysis` module from `sklearn.decomposition` is used to perform the analysis.\n"
      ],
      "id": "83db39dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import FactorAnalysis module\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "\n",
        "# Specify the number of factors (latent skills) to extract\n",
        "n_factors = 3\n",
        "\n",
        "# Initialize the Factor Analysis model\n",
        "fa_model = FactorAnalysis(n_components=n_factors, random_state=42)\n",
        "\n",
        "# Fit the model to the item data\n",
        "fa_model.fit(item_data)"
      ],
      "id": "42070c93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrieve the factor loadings\n",
        "factor_loadings = fa_model.components_.T\n",
        "\n",
        "# Create a dataframe for the factor loadings\n",
        "factor_loadings_df = pd.DataFrame(\n",
        "    factor_loadings,\n",
        "    index=item_data.columns,\n",
        "    columns=[f'Skill_{i+1}' for i in range(n_factors)]\n",
        ")"
      ],
      "id": "1523a3f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Model Initialization**: I initialize the `FactorAnalysis` model with `n_components=3`, intending to extract three latent skills.\n",
        "- **Model Fitting**: The model is fit to `item_data`.\n",
        "- **Factor Loadings**: I obtain the factor loadings, which represent the correlation coefficients between items and factors (skills).\n",
        "- **Dataframe Creation**: The factor loadings are organized into a dataframe for better visualization and interpretation.\n"
      ],
      "id": "c8080c1b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the factor loadings\n",
        "print(factor_loadings_df)"
      ],
      "id": "033ee0e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The factor loadings suggest that items group together based on their highest loadings, indicating the presence of three distinct latent skills.\n",
        "\n",
        "### KMeans Clustering\n",
        "\n",
        "#### Transposing Item Data\n",
        "\n",
        "To cluster items based on their response patterns, I transpose the item data.\n"
      ],
      "id": "a26637a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import KMeans module\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Transpose the item data to have items as rows and students as columns\n",
        "item_data_transposed = item_data.T\n",
        "\n",
        "# Specify the number of clusters (skills)\n",
        "n_clusters = 3\n",
        "\n",
        "# Initialize the KMeans model\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "\n",
        "# Fit the model to the transposed item data\n",
        "kmeans.fit(item_data_transposed)"
      ],
      "id": "09a922bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrieve the cluster labels for each item\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Create a dataframe to display the item-cluster mapping\n",
        "kmeans_q_matrix_df = pd.DataFrame({\n",
        "    'Item': item_data.columns,\n",
        "    'Mapped_Skill': [f'Skill_{label+1}' for label in cluster_labels]\n",
        "})"
      ],
      "id": "1d3de37b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Transposition**: Clustering is performed on items, so I transpose the data to have items as the observations.\n",
        "  \n",
        "#### Applying KMeans Clustering\n",
        "\n",
        "I apply KMeans clustering to group items into clusters representing latent skills.\n",
        "\n",
        "**Explanation**:\n",
        "\n",
        "- **Model Initialization**: I initialize the `KMeans` model with `n_clusters=3`.\n",
        "- **Model Fitting**: The model is fitted to `item_data_transposed`.\n",
        "- **Cluster Labels**: Each item is assigned a cluster label, indicating its grouping.\n",
        "- **Mapping Items to Skills**: I map cluster labels to skill identifiers for interpretation.\n"
      ],
      "id": "c9b61316"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the item-cluster mapping\n",
        "print(kmeans_q_matrix_df)"
      ],
      "id": "25553ea9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The clustering results provide an alternative item-skill mapping that can be compared with the Factor Analysis findings.\n",
        "\n",
        "### Principal Component Analysis (PCA)\n",
        "\n",
        "#### Performing PCA\n",
        "\n",
        "I use PCA to identify principal components that may represent latent skills.\n"
      ],
      "id": "16f92b72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import PCA module\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Initialize the PCA model with three components\n",
        "pca_model = PCA(n_components=3)\n",
        "\n",
        "# Fit the PCA model to the item data\n",
        "pca_model.fit(item_data)"
      ],
      "id": "96bc8da7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrieve the PCA loadings\n",
        "pca_loadings = pca_model.components_.T\n",
        "\n",
        "# Create a dataframe for the PCA loadings\n",
        "pca_loadings_df = pd.DataFrame(\n",
        "    pca_loadings,\n",
        "    index=item_data.columns,\n",
        "    columns=[f'Skill_{i+1}' for i in range(3)]\n",
        ")"
      ],
      "id": "f56b5120",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Model Initialization**: I initialize the `PCA` model with `n_components=3`.\n",
        "- **Model Fitting**: The model is fitted to `item_data`.\n",
        "- **PCA Loadings**: The loadings indicate the contribution of each item to the principal components.\n"
      ],
      "id": "220ac4c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the PCA loadings\n",
        "print(pca_loadings_df)"
      ],
      "id": "66019932",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The PCA results offer additional insights into the item-skill relationships, which can be compared with the results from Factor Analysis and KMeans Clustering.\n",
        "\n",
        "## Results\n",
        "\n",
        "### Mapping Items to Skills Using PCA\n",
        "\n",
        "To further understand the item-skill relationships, I create a Q-matrix based on the **Principal Component Analysis (PCA)** loadings. Each item is assigned to the skill (principal component) with which it has the highest loading.\n"
      ],
      "id": "97f562d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Determine the skill with the highest loading for each item from PCA\n",
        "pca_q_matrix = pca_loadings_df.idxmax(axis=1)\n",
        "\n",
        "# Create the Q-matrix as a dataframe, showing the mapping between items and skills\n",
        "pca_q_matrix_df = pd.DataFrame({'Item': item_data.columns, 'Mapped_Skill': pca_q_matrix.values})\n",
        "pca_q_matrix_df"
      ],
      "id": "76a53d4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparison Across Methods\n",
        "\n",
        "I compare the item-skill mappings obtained from **Factor Analysis**, **KMeans Clustering**, and **PCA** to identify consistent patterns and discrepancies.\n",
        "\n",
        "1. **Consistent Groupings**:\n",
        "   - **Items 2, 4, and 6** consistently group together across all methods, suggesting they measure the same underlying skill.\n",
        "   - **Items 3, 7, and 8** also show consistent grouping in KMeans and PCA results.\n",
        "\n",
        "2. **Method Differences**:\n",
        "   - **Factor Analysis** shows some differences compared to KMeans and PCA, particularly in the assignment of **Items 1 and 5**.\n",
        "   - **KMeans Clustering** and **PCA** exhibit identical groupings, reinforcing the reliability of these methods in this context.\n",
        "\n",
        "3. **Item-Specific Observations**:\n",
        "   - **Item 5**: Its classification varies across methods (assigned to `Skill_2` in Factor Analysis and `Skill_3` in PCA and KMeans), indicating it may be influenced by multiple skills.\n",
        "   - **Item 1**: Assigned to `Skill_3` in both Factor Analysis and PCA, suggesting a strong association.\n",
        "\n",
        "### Testing Alternative Factor Analysis Models\n",
        "\n",
        "To determine the optimal number of latent skills, I test **Factor Analysis** models with two, three, and four components.\n",
        "\n",
        "#### Factor Analysis with Four Components\n"
      ],
      "id": "8070ba0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Performing Factor Analysis with four components to explore the potential presence of additional latent skills\n",
        "n_factors_extended = 4\n",
        "fa_model_extended = FactorAnalysis(n_components=n_factors_extended, random_state=42)\n",
        "fa_model_extended.fit(item_data)\n",
        "\n",
        "# Get the factor loadings for the 4-component model\n",
        "factor_loadings_extended = fa_model_extended.components_.T\n",
        "\n",
        "# Create a dataframe to visualize the factor loadings for the four-component model\n",
        "factor_loadings_extended_df = pd.DataFrame(factor_loadings_extended, index=item_data.columns, columns=[f'Skill_{i+1}' for i in range(n_factors_extended)])\n",
        "factor_loadings_extended_df"
      ],
      "id": "c80f6d32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations from the Four-Component Model**:\n",
        "\n",
        "1. **Consistent Groupings**:\n",
        "   - **Skill_1**: Items 3, 7, and 8 have high loadings, indicating a strong association.\n",
        "   - **Skill_2**: Items 2, 4, and 6 maintain strong relationships.\n",
        "\n",
        "2. **Complex Relationships**:\n",
        "   - **Items 1 and 5** show split loadings between **Skill_3** and **Skill_4**, suggesting they may require multiple skills.\n",
        "   - **Item 4** exhibits secondary loading on **Skill_4**, indicating potential cross-loading.\n",
        "\n",
        "3. **Model Implications**:\n",
        "   - The four-component model reveals nuanced relationships but introduces complexity that may not significantly enhance interpretability.\n",
        "\n",
        "#### Factor Analysis with Two Components\n"
      ],
      "id": "12923f93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Performing Factor Analysis with two components to explore if a simpler model might explain the relationships\n",
        "n_factors_simpler = 2\n",
        "fa_model_simpler = FactorAnalysis(n_components=n_factors_simpler, random_state=42)\n",
        "fa_model_simpler.fit(item_data)\n",
        "\n",
        "# Get the factor loadings for the two-component model\n",
        "factor_loadings_simpler = fa_model_simpler.components_.T\n",
        "\n",
        "# Create a dataframe to visualize the factor loadings for the two-component model\n",
        "factor_loadings_simpler_df = pd.DataFrame(factor_loadings_simpler, index=item_data.columns, columns=[f'Skill_{i+1}' for i in range(n_factors_simpler)])\n",
        "factor_loadings_simpler_df"
      ],
      "id": "d3bd3fb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations from the Two-Component Model**:\n",
        "\n",
        "1. **Simplified Groupings**:\n",
        "   - **Skill_1**: Items 2, 4, and 6 cluster together.\n",
        "   - **Skill_2**: Items 3, 5, 7, and 8 group together.\n",
        "\n",
        "2. **Limitations**:\n",
        "   - **Item 1** does not fit well into this two-skill structure, indicating that the model is too simplistic to capture all item relationships.\n",
        "\n",
        "### Visualizations\n",
        "\n",
        "#### Diagrams\n",
        "\n",
        "I create some [Mermaid](https://mermaid.js.org/) diagrams to gain further insight.[^1]\n",
        "\n",
        "[^1]: Refer to [Creative Assignment 3's GitHub repository](https://github.com/baker-jr-john/Website/blob/main/educ_6191_001/creative_assignments/assignment_3/index.qmd) for the code behind the diagrams.\n",
        "\n",
        "**Comparison Across the Three Methods**\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "graph TB\n",
        "    subgraph PCA\n",
        "        PCA_S3[Skill_3] --- PCA_I1[Item 1]\n",
        "        PCA_S3 --- PCA_I5[Item 5]\n",
        "        \n",
        "        PCA_S2[Skill_2] --- PCA_I2[Item 2]\n",
        "        PCA_S2 --- PCA_I4[Item 4]\n",
        "        PCA_S2 --- PCA_I6[Item 6]\n",
        "        \n",
        "        PCA_S1[Skill_1] --- PCA_I3[Item 3]\n",
        "        PCA_S1 --- PCA_I7[Item 7]\n",
        "        PCA_S1 --- PCA_I8[Item 8]\n",
        "    end\n",
        "    \n",
        "    subgraph KMeans\n",
        "        BQ_S3[Skill_3] --- BQ_I1[Item 1]\n",
        "        BQ_S3 --- BQ_I5[Item 5]\n",
        "        \n",
        "        BQ_S1[Skill_1] --- BQ_I3[Item 3]\n",
        "        BQ_S1 --- BQ_I7[Item 7]\n",
        "        BQ_S1 --- BQ_I8[Item 8]\n",
        "        \n",
        "        BQ_S2[Skill_2] --- BQ_I2[Item 2]\n",
        "        BQ_S2 --- BQ_I4[Item 4]\n",
        "        BQ_S2 --- BQ_I6[Item 6]\n",
        "    end\n",
        "    \n",
        "    subgraph Factor_Analysis\n",
        "        FA_S1[Skill_1] --- FA_I2[Item 2]\n",
        "        FA_S1 --- FA_I4[Item 4]\n",
        "        FA_S1 --- FA_I6[Item 6]\n",
        "        \n",
        "        FA_S2[Skill_2] --- FA_I3[Item 3]\n",
        "        FA_S2 --- FA_I5[Item 5]\n",
        "        FA_S2 --- FA_I7[Item 7]\n",
        "        FA_S2 --- FA_I8[Item 8]\n",
        "        \n",
        "        FA_S3[Skill_3] --- FA_I1[Item 1]\n",
        "    end\n",
        "\n",
        "    style PCA fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style KMeans fill:#9ff,stroke:#333,stroke-width:2px\n",
        "    style Factor_Analysis fill:#ff9,stroke:#333,stroke-width:2px\n",
        "```\n",
        "\n",
        "\n",
        "**Testing Alternative Factor Analysis Models**\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "graph TD\n",
        "    subgraph Strong_Relationships\n",
        "        S1[Skill_1] --- I3[Item 3]\n",
        "        S1 --- I7[Item 7]\n",
        "        S1 --- I8[Item 8]\n",
        "        \n",
        "        S2[Skill_2] --- I2[Item 2]\n",
        "        S2 --- I4[Item 4]\n",
        "        S2 --- I6[Item 6]\n",
        "    end\n",
        "    \n",
        "    subgraph Split_Influences\n",
        "        S3[Skill_3] -.-> I1[Item 1]\n",
        "        S4[Skill_4] -.-> I1\n",
        "        \n",
        "        S3 -.-> I5[Item 5]\n",
        "        S4 -.-> I5\n",
        "        \n",
        "        S4 -.-> I4[Item 4]\n",
        "    end\n",
        "    \n",
        "    style Strong_Relationships fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style Split_Influences fill:#ff9,stroke:#333,stroke-width:2px\n",
        "    \n",
        "    classDef solid stroke-width:4px\n",
        "    classDef dashed stroke-dasharray: 5, 5\n",
        "    class S1,S2,I2,I3,I4,I6,I7,I8 solid\n",
        "    class S3,S4,I1,I5 dashed\n",
        "```\n",
        "\n",
        "\n",
        "**Comparison Across the Three Models**\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "graph TB\n",
        "    subgraph Two_Component_Model\n",
        "        TC_S1[Skill_1] --- TC_I2[Item 2]\n",
        "        TC_S1 --- TC_I4[Item 4]\n",
        "        TC_S1 --- TC_I6[Item 6]\n",
        "        \n",
        "        TC_S2[Skill_2] --- TC_I3[Item 3]\n",
        "        TC_S2 --- TC_I5[Item 5]\n",
        "        TC_S2 --- TC_I7[Item 7]\n",
        "        TC_S2 --- TC_I8[Item 8]\n",
        "        \n",
        "        TC_I1[Item 1<br/>Weak Loadings] -..- TC_S1\n",
        "        TC_I1 -..- TC_S2\n",
        "    end\n",
        "    \n",
        "    subgraph Three_Component_Model\n",
        "        TH_S1[Skill_1] --- TH_I2[Item 2]\n",
        "        TH_S1 --- TH_I4[Item 4]\n",
        "        TH_S1 --- TH_I6[Item 6]\n",
        "        \n",
        "        TH_S2[Skill_2] --- TH_I3[Item 3]\n",
        "        TH_S2 --- TH_I7[Item 7]\n",
        "        TH_S2 --- TH_I8[Item 8]\n",
        "        \n",
        "        TH_S3[Skill_3] --- TH_I1[Item 1]\n",
        "        TH_S3 --- TH_I5[Item 5]\n",
        "    end\n",
        "    \n",
        "    subgraph Four_Component_Model\n",
        "        FC_S1[Skill_1] --- FC_I3[Item 3]\n",
        "        FC_S1 --- FC_I7[Item 7]\n",
        "        FC_S1 --- FC_I8[Item 8]\n",
        "        \n",
        "        FC_S2[Skill_2] --- FC_I2[Item 2]\n",
        "        FC_S2 --- FC_I4[Item 4]\n",
        "        FC_S2 --- FC_I6[Item 6]\n",
        "        \n",
        "        FC_S3[Skill_3] -.-> FC_I1[Item 1]\n",
        "        FC_S4[Skill_4] -.-> FC_I1\n",
        "        \n",
        "        FC_S3 -.-> FC_I5[Item 5]\n",
        "        FC_S4 -.-> FC_I5\n",
        "    end\n",
        "\n",
        "    style Two_Component_Model fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style Three_Component_Model fill:#9ff,stroke:#333,stroke-width:2px\n",
        "    style Four_Component_Model fill:#ff9,stroke:#333,stroke-width:2px\n",
        "```\n",
        "\n",
        "\n",
        "They reinforce and extend previous insights, adding a nuanced understanding of item-skill relationships and the interplay between methods. Here are some key observations derived from the diagrams:\n",
        "\n",
        "##### Consistency Across Methods\n",
        "\n",
        "The three-component structure shows items 2, 4, and 6 consistently mapping to a similar skill across all methods, implying a robust underlying structure. This consistency also appears in items 3, 7, and 8 in KMeans and PCA, suggesting reliability in these assignments.\n",
        "\n",
        "##### Method-Specific Variations\n",
        "\n",
        "Factor Analysis diverges slightly by assigning items 1 and 5 differently than KMeans and PCA. This difference highlights potential complexities in item 5, which seems influenced by multiple skills. These diagrams illustrate how each method offers unique perspectives, yet also converge on certain item-skill relationships, adding confidence to these common groupings.\n",
        "\n",
        "##### Alternative Model Structures\n",
        "\n",
        "The alternative models, such as the four-component model, introduce additional skills that help identify nuanced relationships but also add complexity. For example, the **Four_Component_Model** diagram shows potential secondary skill influences (cross-loadings) in items 1 and 5, indicating they may require multiple skills. Similarly, the two-component model simplifies the structure but struggles to fully capture item 1, highlighting limitations in overly simplified models.\n",
        "\n",
        "##### Insight into Complex Items\n",
        "\n",
        "The **Split_Influences** and **Strong_Relationships** diagrams provide additional insights into items that do not fit neatly into a single skill. For instance, item 5 shows varied associations across methods, supporting the idea that it may assess overlapping skills or a composite skill. This aligns with the **Weak Loadings** observed in two-component models and cross-loadings in four-component models.\n",
        "\n",
        "##### Interpretability\n",
        "\n",
        "The diagrams support the three-skill model as an optimal balance of interpretability and complexity, confirming previous findings. However, they also visualize the potential for models with additional components to capture complex interactions, which may be valuable for specific educational or diagnostic applications where precision is paramount.\n",
        "\n",
        "The diagrams enhance the interpretative clarity of the results, confirm the three-component structure’s robustness, and illustrate how alternative models could provide further insight into complex item relationships if needed.\n",
        "\n",
        "#### Heatmap of Factor Loadings (Three Components)\n",
        "\n",
        "I visualize the factor loadings from the three-component Factor Analysis model using a heatmap.\n"
      ],
      "id": "b4ab2bfb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a heatmap to visualize item-skill relationships from Factor Analysis\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(factor_loadings_df, annot=True, cmap='coolwarm', linewidths=0.5, linecolor='black', cbar=True)\n",
        "plt.title('Item-Skill Relationships (Factor Analysis with 3 Components)')\n",
        "plt.xlabel('Skills')\n",
        "plt.ylabel('Items')\n",
        "plt.show()"
      ],
      "id": "0b65946e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Observations from the Heatmap**:\n",
        "\n",
        "- **Strong Associations**:\n",
        "  - **Item6** has a high loading on **Skill_1** (~0.45).\n",
        "  - **Items 3, 7, and 8** have high loadings on **Skill_2** (~0.39 to 0.40).\n",
        "  - **Item1** shows a notable loading on **Skill_3** (~0.37).\n",
        "\n",
        "- **Weaker Associations**:\n",
        "  - Other items have lower or split loadings, indicating weaker or more complex relationships with the skills.\n",
        "\n",
        "#### Bar Charts for Individual Items\n",
        "\n",
        "I generate bar charts to illustrate the factor loadings of each item across the three skills.\n"
      ],
      "id": "b00a5a4f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create bar charts for each item to show its relationship across skills\n",
        "num_items = len(factor_loadings_df.index)\n",
        "fig, axes = plt.subplots(num_items, 1, figsize=(9, num_items * 2))\n",
        "\n",
        "for i, item in enumerate(factor_loadings_df.index):\n",
        "    axes[i].bar(factor_loadings_df.columns, factor_loadings_df.loc[item], color='skyblue')\n",
        "    axes[i].set_title(f'Relationship of {item} with Skills')\n",
        "    axes[i].set_ylabel('Loading Value')\n",
        "    axes[i].set_ylim(-1, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "id": "ec5ef89b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Insights from the Bar Charts**:\n",
        "\n",
        "- **Item-Specific Relationships**:\n",
        "  - **Item1**: Highest loading on **Skill_3**.\n",
        "  - **Item2**, **Item4**, **Item6**: Highest loadings on **Skill_1**.\n",
        "  - **Items 3, 7, 8**: Highest loadings on **Skill_2**.\n",
        "  - **Item5**: Similar loadings on **Skill_2** and **Skill_3**, indicating potential dual influence.\n",
        "\n",
        "### Creating the Final Q-Matrix\n",
        "\n",
        "Based on the analyses and visualizations, I create the final **Q-matrix** by assigning each item to the skill with which it has the highest loading from the three-component Factor Analysis model.\n"
      ],
      "id": "cb26e586"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creating the final Q-matrix based on the visualization and analysis findings\n",
        "# Assigning each item to the skill with the highest loading from the Factor Analysis with three components\n",
        "final_q_matrix = factor_loadings_df.idxmax(axis=1)\n",
        "\n",
        "# Create a dataframe to visualize the final Q-matrix, showing the mapping between items and skills\n",
        "final_q_matrix_df = pd.DataFrame({'Item': item_data.columns, 'Mapped_Skill': final_q_matrix.values})\n",
        "final_q_matrix_df"
      ],
      "id": "595f0226",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{mermaid}\n",
        "graph TD\n",
        "    subgraph Skill_Mappings\n",
        "        S1[Skill_1] --- I2[Item 2]\n",
        "        S1 --- I4[Item 4]\n",
        "        S1 --- I6[Item 6]\n",
        "        \n",
        "        S2[Skill_2] --- I3[Item 3]\n",
        "        S2 --- I5[Item 5]\n",
        "        S2 --- I7[Item 7]\n",
        "        S2 --- I8[Item 8]\n",
        "        \n",
        "        S3[Skill_3] --- I1[Item 1]\n",
        "    end\n",
        "    \n",
        "    subgraph Evidence_Types\n",
        "        FA[Factor Analysis<br/>Highest Loadings] --- S1\n",
        "        FA --- S2\n",
        "        FA --- S3\n",
        "        \n",
        "        BC[Bar Charts<br/>Visual Validation] --- S1\n",
        "        BC --- S2\n",
        "        BC --- S3\n",
        "    end\n",
        "    \n",
        "    style Skill_Mappings fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style Evidence_Types fill:#9ff,stroke:#333,stroke-width:2px\n",
        "    \n",
        "    classDef skillNode fill:#f96,stroke:#333,stroke-width:2px\n",
        "    classDef itemNode fill:#9f9,stroke:#333,stroke-width:2px\n",
        "    classDef evidenceNode fill:#69f,stroke:#333,stroke-width:2px\n",
        "    \n",
        "    class S1,S2,S3 skillNode\n",
        "    class I1,I2,I3,I4,I5,I6,I7,I8 itemNode\n",
        "    class FA,BC evidenceNode\n",
        "```\n",
        "\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "- **Skill_1**: Assigned to items **2**, **4**, and **6** due to their highest loadings on this skill.\n",
        "- **Skill_2**: Assigned to items **3**, **5**, **7**, and **8** based on their highest loadings.\n",
        "- **Skill_3**: Assigned to **item1**, which has its highest loading on this skill.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- **Consistency with Previous Findings**:\n",
        "  - This Q-matrix aligns with the item-skill relationships observed in the bar charts and heatmaps.\n",
        "  - Items grouped under each skill share similar characteristics and response patterns.\n",
        "\n",
        "- **Item 5**:\n",
        "  - While **item5** had comparable loadings on both **Skill_2** and **Skill_3**, it was assigned to **Skill_2** due to a slightly higher loading.\n",
        "\n",
        "## Discussion\n",
        "\n",
        "### Model Comparison and Selection\n",
        "\n",
        "After comparing models with two, three, and four components, the **three-component Factor Analysis model** emerged as the most suitable representation of the latent skills in the dataset.\n",
        "\n",
        "- **Two-Component Model**:\n",
        "  - **Advantages**: Simplifies the skill structure.\n",
        "  - **Disadvantages**: Fails to capture the complexity of **item1** and provides a less precise mapping for other items.\n",
        "\n",
        "- **Three-Component Model**:\n",
        "  - **Advantages**:\n",
        "    - Accurately captures key item-skill relationships.\n",
        "    - Provides clear and interpretable groupings.\n",
        "    - Balances model complexity with explanatory power.\n",
        "  - **Disadvantages**: Slightly more complex than the two-component model but justified by the improved fit.\n",
        "\n",
        "- **Four-Component Model**:\n",
        "  - **Advantages**: Reveals nuanced relationships and potential cross-loadings.\n",
        "  - **Disadvantages**:\n",
        "    - Adds unnecessary complexity without significant interpretive benefits.\n",
        "    - May overfit the data.\n",
        "\n",
        "### Justification for the Final Q-Matrix\n",
        "\n",
        "The final Q-matrix, derived from the three-component Factor Analysis model, is well-justified by its consistency with the findings from multiple methods.\n",
        "\n",
        "- **Consistency Across Methods**:\n",
        "  - **Items 2, 4, 6** consistently map to **Skill_1**.\n",
        "  - **Items 3, 7, 8** consistently map to **Skill_2**.\n",
        "  - **Item1** is uniquely associated with **Skill_3**.\n",
        "\n",
        "- **Support from PCA and KMeans Clustering**:\n",
        "  - PCA and KMeans results align closely with the Factor Analysis findings, reinforcing the validity of the item-skill mappings.\n",
        "  - For instance, **item1** and **item5** show strong associations with **Skill_3** in both PCA and KMeans, while **Factor Analysis** assigns **item5** to **Skill_2** due to the slightly higher loading.\n",
        "\n",
        "- **Interpretability**:\n",
        "  - The three-skill model provides clear and meaningful interpretations of the data, which is essential for practical applications in educational assessment.\n",
        "\n",
        "### Implications of the Findings\n",
        "\n",
        "The knowledge structure mapping obtained from this study has significant implications for educational practice.\n",
        "\n",
        "- **Stable Item-Skill Relationships**:\n",
        "  - The consistent grouping of certain items suggests robust underlying skills being measured.\n",
        "\n",
        "- **Complex Items**:\n",
        "  - **Item5** exhibits split influences, indicating it may assess multiple skills or a skill that overlaps between **Skill_2** and **Skill_3**.\n",
        "\n",
        "- **Educational Impact**:\n",
        "  - By understanding the relationships between items and skills, test designers can create assessments that more effectively target specific skills, ensuring a balanced coverage of the identified latent skills. The item-skill mappings can also help identify potentially redundant or less informative items, allowing for more efficient and focused assessments.\n",
        "  - Moreover, educators can leverage the findings to diagnose student strengths and weaknesses at the skill level. The identification of specific skills associated with each item enables targeted remediation or enrichment activities, focusing on the areas where students may need additional support. This information can also guide the development of instructional materials and resources, ensuring that students have ample opportunities to practice and master the identified skills.\n",
        "\n",
        "### Limitations and Future Work\n",
        "\n",
        "Despite the insights provided by this study, there are limitations to consider.\n",
        "\n",
        "- **Binary Data Consideration**:\n",
        "  - The use of Factor Analysis and PCA on binary data may not fully meet the assumptions of these methods. Future research could explore the application of Item Response Theory (IRT) models, which are specifically designed for analyzing binary response data.\n",
        "\n",
        "- **Sample Size and Generalizability**:\n",
        "  - The small sample size of eight items limits the generalizability of the findings. Replicating the study with a larger set of items and a more diverse student population would help validate the identified skill structure and its applicability to different educational contexts.\n",
        "\n",
        "- **Cross-Validation**:\n",
        "  - Incorporating cross-validation techniques could strengthen the confidence in the selected model.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This study makes significant contributions to the field of educational assessment and learning analytics by demonstrating the effectiveness of a comprehensive, multi-method approach for uncovering the latent skill structure in an eight-item test dataset. By leveraging the complementary strengths of **Factor Analysis**, **KMeans Clustering**, and **Principal Component Analysis (PCA)**, I have identified a robust and interpretable three-skill model that best represents the underlying knowledge structure.\n",
        "\n",
        "The key findings of this study include:\n",
        "\n",
        "1. The identification of three distinct latent skills that capture the essential relationships among the test items.\n",
        "2. The development of a final **Q-matrix** that provides a clear and empirically-derived mapping of items to skills, consistent across multiple analytical methods.\n",
        "3. The validation of the item-skill relationships through visualizations, including heatmaps and bar charts, which support the interpretability of the identified skill structure.\n",
        "\n",
        "The practical significance of this work lies in its potential to inform and enhance educational assessment and instructional practices. By providing a more precise understanding of the skills assessed by individual test items, this study enables educators and test designers to:\n",
        "\n",
        "- Develop more targeted and efficient assessments that effectively measure specific skills.\n",
        "- Identify areas where students may need additional support or remediation based on their performance on skill-related items.\n",
        "- Design instructional interventions and resources that align with the identified skill structure, promoting more personalized and adaptive learning experiences.\n",
        "\n",
        "Moreover, the multi-method approach presented in this study serves as a valuable template for future research in educational data mining and learning analytics. Researchers can build upon this methodology to investigate the knowledge structures underlying different types of assessments, learning materials, and educational contexts.\n",
        "\n",
        "Future research should focus on addressing the limitations of this study and exploring new avenues for extending its findings. Specific opportunities include:\n",
        "\n",
        "1. Applying Item Response Theory (IRT) models, which are specifically designed for analyzing binary response data, to validate and refine the identified skill structure.\n",
        "2. Replicating the study with larger and more diverse datasets, including assessments with a greater number of items and student populations from various educational backgrounds.\n",
        "3. Investigating the generalizability of the identified skill structure across different domains, grade levels, and assessment formats.\n",
        "4. Exploring the integration of the derived Q-matrix with adaptive learning systems and intelligent tutoring platforms to enable real-time, skill-based feedback and personalized learning paths.\n",
        "\n",
        "By addressing these challenges and opportunities, future research can further advance our understanding of knowledge structure mapping and its applications in educational settings, ultimately contributing to the development of more effective and equitable learning experiences for all students.\n",
        "\n",
        "### Submission Guidelines\n",
        "\n",
        "This document includes all required explanations. The code and data are organized to facilitate replication and further analysis. Please let me know if additional information is needed."
      ],
      "id": "0f969201"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Library/Frameworks/Python.framework/Versions/3.12/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}