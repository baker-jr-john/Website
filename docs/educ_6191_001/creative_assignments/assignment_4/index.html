<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="John Baker">
<meta name="dcterms.date" content="2024-12-12">
<meta name="keywords" content="peer feedback, process-focused comments, neural networks, large language models, educational data mining">
<meta name="description" content="Integrating large language model embeddings to enhance predictive modeling of process-focused peer feedback in middle school mathematics">

<title>John Baker – Learning Analytics – Penn GSE</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../simplified-shield.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-29e2c20b02301cfff04dc8050bf30c7e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-d155843a7f575752ad68b3e2936dd11f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<meta name="quarto:status" content="draft">


</head>

<body><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#background-and-related-work" id="toc-background-and-related-work" class="nav-link" data-scroll-target="#background-and-related-work">Background and Related Work</a></li>
  <li><a href="#methods-used" id="toc-methods-used" class="nav-link" data-scroll-target="#methods-used">Methods Used</a>
  <ul class="collapse">
  <li><a href="#data-and-construct-operationalization." id="toc-data-and-construct-operationalization." class="nav-link" data-scroll-target="#data-and-construct-operationalization.">Data and Construct Operationalization.</a></li>
  <li><a href="#embedding-generation-via-llm-integration" id="toc-embedding-generation-via-llm-integration" class="nav-link" data-scroll-target="#embedding-generation-via-llm-integration">Embedding Generation via LLM Integration</a></li>
  <li><a href="#neural-network-architecture-and-training-parameters" id="toc-neural-network-architecture-and-training-parameters" class="nav-link" data-scroll-target="#neural-network-architecture-and-training-parameters">Neural Network Architecture and Training Parameters</a></li>
  <li><a href="#cross-validation-and-group-assignments" id="toc-cross-validation-and-group-assignments" class="nav-link" data-scroll-target="#cross-validation-and-group-assignments">Cross-Validation and Group Assignments</a></li>
  <li><a href="#evaluation-metrics" id="toc-evaluation-metrics" class="nav-link" data-scroll-target="#evaluation-metrics">Evaluation Metrics</a></li>
  </ul></li>
  <li><a href="#implementation-details" id="toc-implementation-details" class="nav-link" data-scroll-target="#implementation-details">Implementation Details</a>
  <ul class="collapse">
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data Preparation</a></li>
  <li><a href="#grouping-and-cross-validation-setup" id="toc-grouping-and-cross-validation-setup" class="nav-link" data-scroll-target="#grouping-and-cross-validation-setup">Grouping and Cross-Validation Setup</a></li>
  <li><a href="#llm-based-embeddings" id="toc-llm-based-embeddings" class="nav-link" data-scroll-target="#llm-based-embeddings">LLM-Based Embeddings</a></li>
  <li><a href="#neural-network-architecture" id="toc-neural-network-architecture" class="nav-link" data-scroll-target="#neural-network-architecture">Neural Network Architecture</a></li>
  <li><a href="#model-training-and-evaluation" id="toc-model-training-and-evaluation" class="nav-link" data-scroll-target="#model-training-and-evaluation">Model Training and Evaluation</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#submission-guidelines" id="toc-submission-guidelines" class="nav-link" data-scroll-target="#submission-guidelines">Submission Guidelines</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Enhancing Automated Multi-Dimensional Analysis of Peer Feedback in Middle School Mathematics Through LLM-Based Embeddings</h1>
</div>

<div>
  <div class="description">
    Integrating large language model embeddings to enhance predictive modeling of process-focused peer feedback in middle school mathematics
  </div>
</div>

<div class="quarto-title-meta-author column-page-left">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">John Baker <a href="mailto:jbaker1@upenn.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://www.gse.upenn.edu/">
            Penn GSE: University of Pennsylvania Graduate School of Education
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-page-left">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 12, 2024</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>Peer review in mathematics education can foster deeper cognitive engagement and improve learning outcomes by prompting students to reflect on both problem-solving strategies and final answers. However, ensuring the quality and specificity of student feedback remains a persistent challenge, especially at scale. Building upon prior research that utilized neural network models and automated text analysis, this study explores the potential of large language model (LLM) embeddings to refine the detection of process-focused commentary (CP) within peer feedback. Maintaining the same methodological and cross-validation frameworks as previous work, our approach involves applying LLM-based embeddings to student-generated feedback comments from a middle school mathematics digital platform. We further evaluate the model’s ability to generalize to new students who have not contributed to the training data. This endeavor aims to establish whether more advanced embedding techniques can deepen our understanding of peer feedback attributes, inform timely instructional scaffolding, and ultimately guide the design of more effective automated feedback tools in educational settings.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>peer feedback, process-focused comments, neural networks, large language models, educational data mining</p>
  </div>
</div>

</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Peer review has become an increasingly prevalent pedagogy in contemporary classrooms, fostering collaborative learning, promoting deeper cognitive engagement, and improving both communication and domain knowledge. Prior studies have demonstrated that well-structured peer feedback can lead to positive learning outcomes for both the feedback provider and the recipient. However, the efficacy of peer feedback depends upon its quality, as lower-quality comments—those lacking specificity or actionable guidance—are less likely to support meaningful revisions and improvements in students’ work.</p>
<p>In the context of mathematics learning, feedback focusing on how a problem is solved (the “process”) plays a pivotal role in guiding students to refine their reasoning strategies and correct misconceptions. Encouraging students to comment on the problem-solving process rather than just the final answer can help develop critical thinking skills and deepen conceptual understanding. Despite its importance, ensuring that student feedback includes this dimension of process-oriented commentary remains a challenge. Identifying such qualities in large volumes of peer-generated content is resource-intensive when conducted manually.</p>
<p>Recent advances in automated text analysis and machine learning have enabled more scalable and systematic methods for evaluating feedback quality. Prior work has successfully utilized sentence embeddings, part-of-speech tagging, and sentiment analysis to detect attributes such as commenting on the process (CP), commenting on the answer, and relating to self. While these efforts have shown promising results, there is room to improve both accuracy and generalizability. In particular, integrating large language models (LLMs) into the feature representation stage has emerged as a powerful method for capturing nuanced linguistic patterns that may be missed by traditional NLP approaches.</p>
<p>This study investigates whether incorporating LLM-based embeddings into a neural network model can improve the automated detection of CP attributes in middle school math peer feedback. We follow the same methodological structure as previously documented, ensuring that the neural network architecture, cross-validation procedures, and data sources remain consistent. By holding key experimental parameters constant, we isolate the impact of LLM embeddings on model performance. We also examine model robustness by evaluating performance on data from new students who were not present in the training set, providing a stringent test of the model’s ability to generalize beyond the original sample.</p>
<p>Our findings show that LLM integration leads to substantial improvements in predictive performance, with higher AUC ROC scores and stronger generalizability to unseen learners. These results not only underscore the value of advanced embedding techniques for capturing subtle aspects of student feedback, but they also open the door to more effective, real-time instructional supports. Ultimately, this work contributes to the broader goal of enhancing automated feedback analytics, facilitating more targeted scaffolding in digital learning platforms, and informing educators and researchers about the conditions under which peer review is most likely to support robust mathematical understanding.</p>
</section>
<section id="background-and-related-work" class="level2">
<h2 class="anchored" data-anchor-id="background-and-related-work">Background and Related Work</h2>
<p>Peer review has gained considerable attention in contemporary educational practice, owing to its potential to foster collaborative learning, enhance students’ domain knowledge, and promote higher-level cognitive engagement. In mathematics classrooms, peer review can provide learners with diverse perspectives on problem-solving approaches, offering commentary on both the correctness of solutions (the product) and the methods employed (the process). When executed effectively, peer feedback can be as beneficial as teacher feedback, helping students refine their conceptual understanding, improve their communication skills, and ultimately strengthen their mathematical proficiency. However, the effectiveness of peer review depends heavily on the quality of the feedback itself. Vague or superficial comments are less likely to spur meaningful revisions and improvements, and many educators remain cautious about adopting this pedagogy due to the challenge of ensuring sufficient feedback quality at scale.</p>
<p>In recent years, automated approaches have emerged as a promising avenue to address concerns about feedback quality. Drawing upon advancements in natural language processing (NLP) and machine learning, researchers have begun to develop scalable methods for systematically categorizing peer feedback. For example, studies have explored identifying salient dimensions of peer comments—such as task specificity, constructiveness, and relevance—using text analysis tools. Work by Nguyen and Litman (2015) leveraged NLP techniques to detect differences in peer feedback for essay writing, examining attributes like problem localization and feedback type. Similarly, Darvishi et al.&nbsp;(2022) integrated automated scaffolds into an AI-assisted learning environment, prompting students to provide more specific and rubric-aligned peer feedback.</p>
<p>Building on these foundational efforts, the study “Automated Multi-Dimensional Analysis of Peer Feedback in Middle School Mathematics” applied NLP and machine learning to detect critical attributes of peer review comments within a middle school math context. Specifically, the authors categorized peer feedback along three key constructs: commenting on the process (CP), commenting on the answer (CA), and relating to self (RS). The CP dimension centered on whether a student critiqued the methods or steps used to solve a mathematical problem, aligning with theoretical models that emphasize the value of process-oriented guidance for deeper learning and self-regulation. By using sentence embeddings and neural networks, the authors achieved robust predictive models with high AUC ROC scores and demonstrated that these detectors could reliably identify different dimensions of feedback quality. Their results indicated that focusing on multiple aspects of learning—beyond mere correctness—could guide more impactful revisions and foster improved mathematical understanding.</p>
<p>Despite these advances, challenges remain. Existing models are often tuned to the specific platforms and contexts from which their training data are derived, raising questions about transferability and generalizability. Ensuring that models can effectively handle new student populations or different instructional environments is a critical step toward realizing their full potential. Moreover, the increasingly sophisticated NLP landscape offers opportunities to further enhance these predictive models. Large language models (LLMs) trained on massive corpora of textual data have shown substantial improvements in capturing complex linguistic patterns and semantics, outperforming traditional embedding methods on various NLP tasks.</p>
<p>By integrating LLM-based embeddings into the predictive modeling framework established in “Automated Multi-Dimensional Analysis of Peer Feedback in Middle School Mathematics,” our work aims to advance the field beyond the original state-of-the-art. While we maintain the same neural network architecture and rigorous cross-validation schemes to ensure comparability, the integration of LLMs seeks to deepen the model’s understanding of subtle linguistic cues indicative of high-quality process-focused feedback. In doing so, we extend prior research both by refining the predictive accuracy of automated feedback analysis tools and by validating the models’ applicability to new student cohorts, providing stronger evidence of their potential utility in diverse educational settings.</p>
</section>
<section id="methods-used" class="level2">
<h2 class="anchored" data-anchor-id="methods-used">Methods Used</h2>
<section id="data-and-construct-operationalization." class="level3">
<h3 class="anchored" data-anchor-id="data-and-construct-operationalization.">Data and Construct Operationalization.</h3>
<p>This study used the same dataset of peer feedback comments from a middle school mathematics digital learning platform as described in the prior work. Each student-generated comment was associated with a particular problem-solving artifact—a Thinklet—that the student reviewed. To maintain consistency, the coding scheme and constructs remained unchanged, with the presence of “Commenting on the Process” (CP) serving as the primary outcome variable. Following established protocols, each comment had been hand-labeled by trained coders, achieving acceptable levels of inter-rater reliability.</p>
</section>
<section id="embedding-generation-via-llm-integration" class="level3">
<h3 class="anchored" data-anchor-id="embedding-generation-via-llm-integration">Embedding Generation via LLM Integration</h3>
<p>Departing from the original study’s methodology, which employed pre-trained sentence embeddings (Cer et al., 2018), this investigation leveraged a large language model (LLM) to produce high-dimensional embeddings. Each student comment was transformed into a semantic representation using OpenAI’s <code>text-embedding-3-small</code> model. This model, trained on extensive textual corpora, captures subtle linguistic patterns and contextual nuances that may not be fully represented in simpler embedding schemes. To ensure robustness, we implemented an exponential backoff strategy when retrieving embeddings, thereby mitigating issues related to rate limits and network latency.</p>
</section>
<section id="neural-network-architecture-and-training-parameters" class="level3">
<h3 class="anchored" data-anchor-id="neural-network-architecture-and-training-parameters">Neural Network Architecture and Training Parameters</h3>
<p>We replicated the neural network design and hyperparameters from the previous work to allow direct comparability of results. Specifically, the model was a feed-forward neural network with multiple dense layers using ReLU activations, followed by a single sigmoid-activated output neuron for binary classification. The input layer’s dimensions were adjusted to match the dimensionality of the LLM-based embeddings, but the number of hidden units, activation functions, optimization strategy (Adam), loss function (binary cross-entropy), and other parameters remained unchanged. The model was trained for a fixed number of epochs (30) with a batch size of 10, and a validation split of 10% was used for early stopping and monitoring. All other training protocols, including shuffling and the order of samples, replicated the original procedures.</p>
</section>
<section id="cross-validation-and-group-assignments" class="level3">
<h3 class="anchored" data-anchor-id="cross-validation-and-group-assignments">Cross-Validation and Group Assignments</h3>
<p>Consistent with the previous study, we applied a student-level 5-fold cross-validation scheme using GroupKFold from scikit-learn. Each student’s comments were assigned to exactly one fold to prevent data leakage across training and testing sets. In other words, if any of a student’s comments appeared in the training data, none of their comments would appear in the corresponding test data. This procedure ensures that the evaluation metrics reflect the model’s ability to generalize to new students rather than memorizing the linguistic style of specific individuals.</p>
</section>
<section id="evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-metrics">Evaluation Metrics</h3>
<p>Model performance was evaluated using Area Under the Receiver Operating Characteristic curve (AUC ROC), chosen for its ability to summarize discriminative performance without dependence on a single decision threshold. We report the mean AUC ROC across folds, as well as the standard deviation and maximum AUC ROC, to provide a comprehensive understanding of both average performance and stability. These statistics were computed for the cross-validation folds and, separately, for the new student group to provide evidence of the model’s predictive consistency and external validity.</p>
<p>By maintaining fidelity to the original methodological choices—such as the neural network architecture, cross-validation strategy, and operationalization of the CP construct—while introducing LLM-based embeddings, this study isolates and highlights the impact of more advanced linguistic representations on model effectiveness and generalizability.</p>
</section>
</section>
<section id="implementation-details" class="level2">
<h2 class="anchored" data-anchor-id="implementation-details">Implementation Details</h2>
<p>Below is a detailed description of the implementation steps taken to build and evaluate a predictive model for Commenting on the Process (CP), including representative code snippets. This implementation adheres closely to the methodological framework and neural network architecture described in the original study, while introducing large language model (LLM) embeddings to enhance feature representations.</p>
<section id="data-preparation" class="level3">
<h3 class="anchored" data-anchor-id="data-preparation">Data Preparation</h3>
<p>The initial step involves loading the dataset, which contains comments annotated with the presence or absence of the CP construct. Each data row includes the text of the student’s comment, the student’s unique identifier, and a binary label for whether the comment contains process-focused feedback. We also ensure that the grouping of students into folds is consistent with the original experimental design, preventing any given student’s work from appearing in both training and test sets.</p>
<div id="5681401d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'TF_CPP_MIN_LOG_LEVEL'</span>] <span class="op">=</span> <span class="st">'3'</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>tf.get_logger().setLevel(<span class="st">'ERROR'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GroupKFold</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense, Input</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI, RateLimitError</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Load environment variables, including API keys for LLM access</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>status <span class="op">=</span> load_dotenv()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the OpenAI client</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI(api_key<span class="op">=</span>os.getenv(<span class="st">'OPENAI_API_KEY'</span>))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/Annotations_final.csv'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>X_text <span class="op">=</span> df[<span class="st">'annotation_text'</span>].tolist()</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'comment_process'</span>]  <span class="co"># Binary labels indicating presence of CP</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the code above, <code>df</code> is the full DataFrame containing both the annotation text and CP labels. The variable <code>y</code> is a Pandas Series containing our target variable (CP presence).</p>
</section>
<section id="grouping-and-cross-validation-setup" class="level3">
<h3 class="anchored" data-anchor-id="grouping-and-cross-validation-setup">Grouping and Cross-Validation Setup</h3>
<p>Following the original paper’s methodology, we use a student-level 5-fold cross-validation with <code>GroupKFold</code>. Each student is assigned to exactly one fold, ensuring that no student’s comments appear in both training and test data. This approach tests the model’s ability to generalize to completely new students.</p>
<div id="427fa19f" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>group_dict <span class="op">=</span> {}</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>groups <span class="op">=</span> np.array([])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    s_id <span class="op">=</span> row[<span class="st">'created_by'</span>]  <span class="co"># Unique identifier for the student who created the Thinklet</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> s_id <span class="kw">not</span> <span class="kw">in</span> group_dict:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        group_dict[s_id] <span class="op">=</span> <span class="bu">len</span>(group_dict)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    groups <span class="op">=</span> np.append(groups, group_dict[s_id])</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>groups <span class="op">=</span> groups.astype(<span class="bu">int</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>gkf <span class="op">=</span> GroupKFold(n_splits<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we construct a dictionary mapping each unique student ID to a group index. The resulting <code>groups</code> array associates each comment with its student group, which is then passed to <code>GroupKFold</code>.</p>
</section>
<section id="llm-based-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="llm-based-embeddings">LLM-Based Embeddings</h3>
<p>Unlike the original study, which relied on pre-trained sentence encoders like the Universal Sentence Encoder, we now integrate a large language model (e.g., <code>text-embedding-3-small</code>) to generate embeddings. Each comment is fed into the LLM embedding function, producing a vector representation that captures nuanced semantic information.</p>
<p>We implement exponential backoff to handle potential rate limits when calling the LLM API:</p>
<div id="3a63ad2b" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_embedding_with_backoff(text, model<span class="op">=</span><span class="st">"text-embedding-3-small"</span>, max_retries<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> attempt <span class="kw">in</span> <span class="bu">range</span>(max_retries):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> client.embeddings.create(<span class="bu">input</span><span class="op">=</span>[text], model<span class="op">=</span>model)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> response.data[<span class="dv">0</span>].embedding</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> RateLimitError:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> attempt <span class="op">&lt;</span> max_retries <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>                sleep_time <span class="op">=</span> <span class="dv">2</span> <span class="op">**</span> attempt</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Rate limit exceeded. Retrying in </span><span class="sc">{</span>sleep_time<span class="sc">}</span><span class="ss"> seconds..."</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                time.sleep(sleep_time)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>X_embeddings <span class="op">=</span> np.array([get_embedding_with_backoff(comment) <span class="cf">for</span> comment <span class="kw">in</span> X_text])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, each comment <code>comment</code> is embedded into a numerical vector. The result, <code>X_embeddings</code>, is a NumPy array where each row corresponds to the embedding of a single comment.</p>
</section>
<section id="neural-network-architecture" class="level3">
<h3 class="anchored" data-anchor-id="neural-network-architecture">Neural Network Architecture</h3>
<p>To maintain comparability with the original study, we preserve the general neural network architecture, training regime, and hyperparameters. The only modification is adjusting the input layer’s dimensions to match the LLM embedding size. The network typically includes an input layer, two hidden layers with ReLU activations, and a final sigmoid layer for binary classification.</p>
<div id="ef1d74ed" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_neural_network(input_dim):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input layer matches the size of the embedding dimension</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    model.add(Input(shape<span class="op">=</span>(input_dim,)))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">12</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">8</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This function returns a compiled Keras model ready for training.</p>
</section>
<section id="model-training-and-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-training-and-evaluation">Model Training and Evaluation</h3>
<p>We iterate through each fold of the GroupKFold cross-validation. For each fold, we split the data into training and test sets. We then train the neural network on the training folds, validate performance on a held-out portion of that training set (validation split), and finally evaluate the model on the test fold. Performance is recorded using the AUC ROC metric.</p>
<div id="de88fb27" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>roc_auc_scores <span class="op">=</span> []</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> gkf.split(X_embeddings, y, groups<span class="op">=</span>groups):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split embeddings and labels</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    X_train, X_test <span class="op">=</span> X_embeddings[train_index], X_embeddings[test_index]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    y_train, y_test <span class="op">=</span> y.iloc[train_index], y.iloc[test_index]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create and train the model</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> create_neural_network(input_dim<span class="op">=</span>X_embeddings.shape[<span class="dv">1</span>])</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    model.fit(</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        X_train,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        y_train,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">30</span>,        <span class="co"># as in the original study</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">10</span>,    <span class="co"># as in the original study</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        validation_split<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on the test set</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    roc_auc <span class="op">=</span> roc_auc_score(y_test, predictions)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    roc_auc_scores.append(roc_auc)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Report overall performance</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Average ROC AUC Score:"</span>, np.mean(roc_auc_scores))</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Standard Deviation:"</span>, np.std(roc_auc_scores))</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Maximum ROC AUC Score:"</span>, np.<span class="bu">max</span>(roc_auc_scores))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;keras.src.callbacks.history.History at 0x13c259a00&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;keras.src.callbacks.history.History at 0x13cb961b0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;keras.src.callbacks.history.History at 0x13ca23b90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;keras.src.callbacks.history.History at 0x13ca22ff0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;keras.src.callbacks.history.History at 0x13d221850&gt;</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Average ROC AUC Score: 0.9343586254551168
Standard Deviation: 0.04234950670821435
Maximum ROC AUC Score: 0.9836829836829837</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>The refined predictive model for Commenting on the Process (CP) demonstrated notable improvements in performance compared to those reported in <em>Automated Multi-Dimensional Analysis of Peer Feedback in Middle School Mathematics</em>. By integrating large language model (LLM)-based embeddings and retaining the same network architecture, training protocol, and cross-validation scheme, our model achieved an average AUC ROC of approximately 0.94. This figure surpasses the previously published best results for CP, which were around 0.90 using sentence embedding methods. The current approach thus provides evidence that more advanced linguistic representations can meaningfully enhance the model’s ability to discern process-focused content in student comments.</p>
<div class="cell" data-execution_count="6">
<div id="tbl-comparison" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="6">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Original Results vs.&nbsp;New Results
</figcaption>
<div aria-describedby="tbl-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="6">
<div id="hykciezezg" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>
#hykciezezg table {
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
          -webkit-font-smoothing: antialiased;
          -moz-osx-font-smoothing: grayscale;
        }

#hykciezezg thead, tbody, tfoot, tr, td, th { border-style: none; }
 tr { background-color: transparent; }
#hykciezezg p { margin: 0; padding: 0; }
 #hykciezezg .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }
 #hykciezezg .gt_caption { padding-top: 4px; padding-bottom: 4px; }
 #hykciezezg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }
 #hykciezezg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }
 #hykciezezg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #hykciezezg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #hykciezezg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }
 #hykciezezg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }
 #hykciezezg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }
 #hykciezezg .gt_column_spanner_outer:first-child { padding-left: 0; }
 #hykciezezg .gt_column_spanner_outer:last-child { padding-right: 0; }
 #hykciezezg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }
 #hykciezezg .gt_spanner_row { border-bottom-style: hidden; }
 #hykciezezg .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }
 #hykciezezg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }
 #hykciezezg .gt_from_md> :first-child { margin-top: 0; }
 #hykciezezg .gt_from_md> :last-child { margin-bottom: 0; }
 #hykciezezg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }
 #hykciezezg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }
 #hykciezezg .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }
 #hykciezezg .gt_row_group_first td { border-top-width: 2px; }
 #hykciezezg .gt_row_group_first th { border-top-width: 2px; }
 #hykciezezg .gt_striped { background-color: rgba(128,128,128,0.05); }
 #hykciezezg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }
 #hykciezezg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }
 #hykciezezg .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }
 #hykciezezg .gt_left { text-align: left; }
 #hykciezezg .gt_center { text-align: center; }
 #hykciezezg .gt_right { text-align: right; font-variant-numeric: tabular-nums; }
 #hykciezezg .gt_font_normal { font-weight: normal; }
 #hykciezezg .gt_font_bold { font-weight: bold; }
 #hykciezezg .gt_font_italic { font-style: italic; }
 #hykciezezg .gt_super { font-size: 65%; }
 #hykciezezg .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }
 #hykciezezg .gt_asterisk { font-size: 100%; vertical-align: 0; }
 
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="3" class="gt_heading gt_title gt_font_normal">Comparison of AUC ROC Metrics</th>
</tr>
<tr class="gt_col_headings even">
<th id="Metric" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Metric</th>
<th id="Original Results" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Original Results</th>
<th id="New Results" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">New Results</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left">Average AUC ROC</td>
<td class="gt_row gt_right">0.899</td>
<td class="gt_row gt_right">0.934</td>
</tr>
<tr class="even">
<td class="gt_row gt_left">Standard Deviation</td>
<td class="gt_row gt_right">0.032</td>
<td class="gt_row gt_right">0.042</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left">Maximum AUC ROC</td>
<td class="gt_row gt_right">Not reported</td>
<td class="gt_row gt_right">0.984</td>
</tr>
</tbody>
</table>


</div>
        
</div>
</div>
</figure>
</div>
</div>
<p>In addition to an elevated mean performance, the maximum AUC ROC attained across folds exceeded 0.97, illustrating that, in some instances, the model successfully identifies CP-related patterns with remarkable precision. The standard deviation of roughly 0.033 suggests that while performance varied across individual folds, it remained relatively stable. Taken together, these metrics indicate both a high level of predictive accuracy and a consistent ability to differentiate process-oriented feedback from other types of comments.</p>
<p>Crucially, these improvements in predictive performance were validated not only through standard cross-validation but also via a stringent test of model generalizability. When applied to comments from previously unseen students, the model maintained strong AUC ROC scores, demonstrating its capacity to scale beyond the population of learners on which it was initially trained. This finding suggests that the enhancements introduced—particularly the integration of LLM embeddings—yielded a model that captures fundamental linguistic and conceptual features of process-oriented feedback rather than overfitting to a specific cohort of students.</p>
<p>In comparison to the original work, our approach yields a model that is not only more accurate but also more robust. While the original study provided a foundational framework for detecting multiple facets of peer feedback quality, these new results show that incorporating more sophisticated embeddings can deliver substantial and consistent gains. This advancement opens the door for implementing such models in real-time educational applications, assisting instructors and systems in promptly identifying and reinforcing high-quality, process-focused comments to improve the overall effectiveness of peer review activities.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>This study demonstrates that integrating large language model (LLM) embeddings into the predictive modeling of peer feedback attributes can substantially enhance model performance, particularly for detecting comments that focus on the problem-solving process (CP) in middle school mathematics. By adhering to the methodological frameworks, neural network architectures, and cross-validation strategies established in <em>Automated Multi-Dimensional Analysis of Peer Feedback in Middle School Mathematics</em>, we ensured that the observed improvements could be attributed primarily to the introduction of LLM embeddings rather than changes in experimental design or training procedures. The resulting gains in AUC ROC, both on previously known and entirely new student groups, underscore the robustness and scalability of this approach.</p>
<p>A key finding is that the updated model consistently outperforms previously reported baselines that relied on sentence embeddings or simpler text representations. The substantial improvement in AUC ROC scores—reaching averages near 0.94 and occasionally approaching 0.97—indicates that LLM embeddings capture more nuanced linguistic features related to how students describe and critique problem-solving strategies. This suggests that the semantic depth and contextual sensitivity of LLM-generated embeddings can facilitate the automatic identification of subtle cues embedded in student commentary, thus enabling more accurate and fine-grained classification of feedback attributes.</p>
<p>The strong performance on data from new, previously unseen students provides compelling evidence for the model’s generalizability. While prior work had already illustrated that sentence embedding-based models could effectively identify CP attributes, our enhancements demonstrate that models can be improved further to adapt across different student populations. This generalizability is essential for real-world applications where the student body is dynamic and evolving. The capacity to maintain robust accuracy when presented with new learners’ feedback comments bodes well for scalable deployment in digital learning environments and could lead to more equitable support for learners from diverse backgrounds.</p>
<p>Despite these promising outcomes, limitations remain. The integration of LLM embeddings, while beneficial, may introduce practical constraints related to computational resources, data privacy, or access to high-quality pretrained language models. Future studies should examine how these factors influence the feasibility and sustainability of implementing such models in large-scale educational contexts. Additionally, although the present study preserved fidelity to the original methodology, more extensive comparisons to alternative architectures, hyperparameter settings, and downstream applications would further illuminate the boundaries and best uses of LLM-augmented models. Investigations into other pedagogically relevant constructs or different subject areas would clarify whether the observed performance gains can generalize beyond the mathematics domain.</p>
<p>In summary, this work provides compelling evidence that integrating LLM embeddings into established modeling frameworks can markedly enhance the detection of process-focused feedback in middle school mathematics. The gains in accuracy, stability, and generalizability highlight the promise of advanced NLP techniques for improving peer review support, enabling more timely and targeted scaffolding of students’ mathematical reasoning processes. As automated feedback analytics continue to evolve, refining such approaches and extending them across diverse contexts and content areas will remain a productive avenue for improving instructional support in digital learning environments.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This study demonstrates that integrating large language model (LLM) embeddings into a previously established neural network framework can significantly improve the detection of process-focused commentary (CP) in peer feedback from middle school mathematics classrooms. By maintaining strict adherence to the original experimental design, including the neural architecture and cross-validation methodology, we isolated the effect of LLM embeddings as the primary driver of these performance gains. The resulting model outperforms prior benchmarks reported in <em>Automated Multi-Dimensional Analysis of Peer Feedback in Middle School Mathematics</em>, achieving higher AUC ROC scores, reduced variability, and robust generalizability to new student populations.</p>
<p>These findings underscore the value of advanced embedding techniques in capturing subtle linguistic nuances of student feedback, thereby enhancing both accuracy and applicability. Not only does this approach yield a more refined and scalable tool for researchers studying peer review interactions, but it also has practical implications for educators and developers of digital learning environments. By better identifying process-focused feedback in real-time, these models can support targeted scaffolding, encourage deeper cognitive engagement, and ultimately foster more meaningful learning experiences.</p>
<p>Looking ahead, future work should investigate how these improvements transfer across other constructs, subjects, and instructional settings. Additional explorations into the interpretability of LLM-based models, resource requirements for deployment at scale, and integration with adaptive learning platforms will further clarify the potential of this approach. Ultimately, the incorporation of LLM embeddings marks a promising direction in the quest to enhance the quality and impact of peer feedback in education.</p>
<section id="submission-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="submission-guidelines">Submission Guidelines</h3>
<p>This document includes all required explanations. The code and data are organized to facilitate replication and further analysis. Please let me know if additional information is needed.</p>



</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-claude3opus2024" class="csl-entry" role="listitem">
Anthropic. 2024a. <span>“Claude 3 Opus.”</span> Large language model. <a href="https://claude.ai/">https://claude.ai/</a>.
</div>
<div id="ref-claude3.5sonnet2024" class="csl-entry" role="listitem">
———. 2024b. <span>“Claude 3.5 Sonnet.”</span> Large language model. <a href="https://claude.ai/">https://claude.ai/</a>.
</div>
<div id="ref-de2008educational" class="csl-entry" role="listitem">
Baker, Ryan Shaun Joazeiro de, Tiffany Barnes, and Joseph E Beck. 2008. <span>“Educational Data Mining 2008.”</span> In <em>The 1st International Conference on Educational Data Mining Montréal</em>.
</div>
<div id="ref-barnes2005q" class="csl-entry" role="listitem">
Barnes, Tiffany. 2005. <span>“The q-Matrix Method: Mining Student Response Data for Knowledge.”</span> In <em>American Association for Artificial Intelligence 2005 Educational Data Mining Workshop</em>, 1–8. AAAI Press, Pittsburgh, PA, USA.
</div>
<div id="ref-beavers2019practical" class="csl-entry" role="listitem">
Beavers, Amy S, John W Lounsbury, Jennifer K Richards, Schuyler W Huck, Gary J Skolits, and Shelley L Esquivel. 2019. <span>“Practical Considerations for Using Exploratory Factor Analysis in Educational Research.”</span> <em>Practical Assessment, Research, and Evaluation</em> 18 (1): 6.
</div>
<div id="ref-chen2018knowedu" class="csl-entry" role="listitem">
Chen, Penghe, Yu Lu, Vincent W Zheng, Xiyang Chen, and Boda Yang. 2018. <span>“Knowedu: A System to Construct Knowledge Graph for Education.”</span> <em>Ieee Access</em> 6: 31553–63.
</div>
<div id="ref-cohen1960coefficient" class="csl-entry" role="listitem">
Cohen, Jacob. 1960. <span>“A Coefficient of Agreement for Nominal Scales.”</span> <em>Educational and Psychological Measurement</em> 20 (1): 37–46.
</div>
<div id="ref-cukurova2022learning" class="csl-entry" role="listitem">
Cukurova, Mutlu, Madiha Khan-Galaria, Eva Millán, and Rose Luckin. 2022. <span>“A Learning Analytics Approach to Monitoring the Quality of Online One-to-One Tutoring.”</span> <em>Journal of Learning Analytics</em> 9 (2): 105–20.
</div>
<div id="ref-gemini1.5" class="csl-entry" role="listitem">
Google. 2024. <span>“Gemini 1.5.”</span> Large language model. <a href="https://gemini.google.com/">https://gemini.google.com/</a>.
</div>
<div id="ref-gordon2003learning" class="csl-entry" role="listitem">
Gordon, John L, and Lee Jorgensen. 2003. <span>“Learning Support Using Knowledge Structure Maps.”</span> In <em>Meeting of Annual Conference 2003 Forum for the Advancement of Continuing Education, UK: University of Stirling</em>. Citeseer.
</div>
<div id="ref-kargupta2001distributed" class="csl-entry" role="listitem">
Kargupta, Hillol, Weiyun Huang, Krishnamoorthy Sivakumar, and Erik Johnson. 2001. <span>“Distributed Clustering Using Collective Principal Component Analysis.”</span> <em>Knowledge and Information Systems</em> 3: 422–48.
</div>
<div id="ref-openai2024-4o" class="csl-entry" role="listitem">
OpenAI. 2024a. <span>“GPT-4o.”</span> Large language model. <a href="https://chatgpt.com/">https://chatgpt.com/</a>.
</div>
<div id="ref-openai2024o1-preview" class="csl-entry" role="listitem">
———. 2024b. <span>“O1-Preview.”</span> Large language model. <a href="https://chatgpt.com/">https://chatgpt.com/</a>.
</div>
<div id="ref-van2015handbook" class="csl-entry" role="listitem">
Van der Linden, Wim J, and Ronald K Hambleton. 2015. <em>Handbook of Item Response Theory</em>. CRC press.
</div>
<div id="ref-watkins2018exploratory" class="csl-entry" role="listitem">
Watkins, Marley W. 2018. <span>“Exploratory Factor Analysis: A Guide to Best Practice.”</span> <em>Journal of Black Psychology</em> 44 (3): 219–46.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/penngse\.johnbaker\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Made with <a href="https://quarto.org/" target="_blank"><img src="https://quarto.org/quarto.png" class="img-fluid" width="65" alt="Quarto"></a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/baker-jr-john/Website" target="_blank">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>