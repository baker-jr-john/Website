<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="John Baker">
<meta name="dcterms.date" content="2024-09-18">
<meta name="description" content="A machine learning model to detect off-task behavior">

<title>Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection – Penn GSE</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<meta name="quarto:status" content="draft">


</head>

<body><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction:</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology:</a></li>
  <li><a href="#class-0-majority-class" id="toc-class-0-majority-class" class="nav-link" data-scroll-target="#class-0-majority-class">1. <strong>Class 0 (Majority Class)</strong>:</a></li>
  <li><a href="#class-1-minority-class" id="toc-class-1-minority-class" class="nav-link" data-scroll-target="#class-1-minority-class">2. <strong>Class 1 (Minority Class)</strong>:</a></li>
  <li><a href="#overall-metrics" id="toc-overall-metrics" class="nav-link" data-scroll-target="#overall-metrics">3. <strong>Overall Metrics</strong>:</a></li>
  <li><a href="#key-observations" id="toc-key-observations" class="nav-link" data-scroll-target="#key-observations">Key Observations:</a></li>
  <li><a href="#insights" id="toc-insights" class="nav-link" data-scroll-target="#insights">Insights:</a></li>
  <li><a href="#class-0-majority-class-1" id="toc-class-0-majority-class-1" class="nav-link" data-scroll-target="#class-0-majority-class-1">1. <strong>Class 0 (Majority Class)</strong>:</a></li>
  <li><a href="#class-1-minority-class-1" id="toc-class-1-minority-class-1" class="nav-link" data-scroll-target="#class-1-minority-class-1">2. <strong>Class 1 (Minority Class)</strong>:</a></li>
  <li><a href="#overall-metrics-1" id="toc-overall-metrics-1" class="nav-link" data-scroll-target="#overall-metrics-1">3. <strong>Overall Metrics</strong>:</a></li>
  <li><a href="#key-observations-1" id="toc-key-observations-1" class="nav-link" data-scroll-target="#key-observations-1">Key Observations:</a></li>
  <li><a href="#comparison-with-previous-models" id="toc-comparison-with-previous-models" class="nav-link" data-scroll-target="#comparison-with-previous-models"><strong>Comparison with Previous Models</strong>:</a></li>
  <li><a href="#what-this-means" id="toc-what-this-means" class="nav-link" data-scroll-target="#what-this-means">What This Means:</a></li>
  <li><a href="#class-0-majority-class-2" id="toc-class-0-majority-class-2" class="nav-link" data-scroll-target="#class-0-majority-class-2">1. <strong>Class 0 (Majority Class)</strong>:</a></li>
  <li><a href="#class-1-minority-class-2" id="toc-class-1-minority-class-2" class="nav-link" data-scroll-target="#class-1-minority-class-2">2. <strong>Class 1 (Minority Class)</strong>:</a></li>
  <li><a href="#overall-metrics-2" id="toc-overall-metrics-2" class="nav-link" data-scroll-target="#overall-metrics-2">3. <strong>Overall Metrics</strong>:</a></li>
  <li><a href="#key-observations-2" id="toc-key-observations-2" class="nav-link" data-scroll-target="#key-observations-2">Key Observations:</a></li>
  <li><a href="#adjusted-kappa-score" id="toc-adjusted-kappa-score" class="nav-link" data-scroll-target="#adjusted-kappa-score">1. <strong>Adjusted Kappa Score</strong>:</a></li>
  <li><a href="#class-0-majority-class-3" id="toc-class-0-majority-class-3" class="nav-link" data-scroll-target="#class-0-majority-class-3">2. <strong>Class 0 (Majority Class)</strong>:</a></li>
  <li><a href="#class-1-minority-class-3" id="toc-class-1-minority-class-3" class="nav-link" data-scroll-target="#class-1-minority-class-3">3. <strong>Class 1 (Minority Class)</strong>:</a></li>
  <li><a href="#overall-metrics-3" id="toc-overall-metrics-3" class="nav-link" data-scroll-target="#overall-metrics-3">4. <strong>Overall Metrics</strong>:</a></li>
  <li><a href="#key-observations-3" id="toc-key-observations-3" class="nav-link" data-scroll-target="#key-observations-3">Key Observations:</a></li>
  <li><a href="#observations" id="toc-observations" class="nav-link" data-scroll-target="#observations">Observations:</a></li>
  <li><a href="#results-breakdown" id="toc-results-breakdown" class="nav-link" data-scroll-target="#results-breakdown">Results Breakdown:</a></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation">Interpretation:</a></li>
  <li><a href="#breakdown-of-the-graph" id="toc-breakdown-of-the-graph" class="nav-link" data-scroll-target="#breakdown-of-the-graph">Breakdown of the Graph:</a></li>
  <li><a href="#observations-1" id="toc-observations-1" class="nav-link" data-scroll-target="#observations-1">Observations:</a></li>
  <li><a href="#key-insights" id="toc-key-insights" class="nav-link" data-scroll-target="#key-insights">Key Insights:</a></li>
  <li><a href="#purpose-of-this-code" id="toc-purpose-of-this-code" class="nav-link" data-scroll-target="#purpose-of-this-code">Purpose of This Code:</a></li>
  <li><a href="#best-threshold-for-maximum-f1-score-0.90" id="toc-best-threshold-for-maximum-f1-score-0.90" class="nav-link" data-scroll-target="#best-threshold-for-maximum-f1-score-0.90">1. <strong>Best Threshold for Maximum F1-Score: 0.90</strong></a></li>
  <li><a href="#precision-at-best-threshold-0.50" id="toc-precision-at-best-threshold-0.50" class="nav-link" data-scroll-target="#precision-at-best-threshold-0.50">2. <strong>Precision at Best Threshold: 0.50</strong></a></li>
  <li><a href="#recall-at-best-threshold-0.67" id="toc-recall-at-best-threshold-0.67" class="nav-link" data-scroll-target="#recall-at-best-threshold-0.67">3. <strong>Recall at Best Threshold: 0.67</strong></a></li>
  <li><a href="#kappa-score-at-best-threshold-0.55" id="toc-kappa-score-at-best-threshold-0.55" class="nav-link" data-scroll-target="#kappa-score-at-best-threshold-0.55">4. <strong>Kappa Score at Best Threshold: 0.55</strong></a></li>
  <li><a href="#interpretation-1" id="toc-interpretation-1" class="nav-link" data-scroll-target="#interpretation-1">Interpretation:</a></li>
  <li><a href="#interpretation-of-the-kappa-score" id="toc-interpretation-of-the-kappa-score" class="nav-link" data-scroll-target="#interpretation-of-the-kappa-score">Interpretation of the Kappa Score:</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways:</a></li>
  <li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose:</a></li>
  <li><a href="#class-0-majority-class-4" id="toc-class-0-majority-class-4" class="nav-link" data-scroll-target="#class-0-majority-class-4">1. <strong>Class 0 (Majority Class)</strong>:</a></li>
  <li><a href="#class-1-minority-class-4" id="toc-class-1-minority-class-4" class="nav-link" data-scroll-target="#class-1-minority-class-4">2. <strong>Class 1 (Minority Class)</strong>:</a></li>
  <li><a href="#overall-metrics-4" id="toc-overall-metrics-4" class="nav-link" data-scroll-target="#overall-metrics-4">3. <strong>Overall Metrics</strong>:</a></li>
  <li><a href="#key-observations-4" id="toc-key-observations-4" class="nav-link" data-scroll-target="#key-observations-4">Key Observations:</a></li>
  <li><a href="#breakdown" id="toc-breakdown" class="nav-link" data-scroll-target="#breakdown">Breakdown:</a></li>
  <li><a href="#key-observations-5" id="toc-key-observations-5" class="nav-link" data-scroll-target="#key-observations-5">Key Observations:</a></li>
  <li><a href="#what-this-means-1" id="toc-what-this-means-1" class="nav-link" data-scroll-target="#what-this-means-1">What This Means:</a></li>
  <li><a href="#explanation-of-the-confusion-matrix" id="toc-explanation-of-the-confusion-matrix" class="nav-link" data-scroll-target="#explanation-of-the-confusion-matrix">Explanation of the Confusion Matrix:</a></li>
  <li><a href="#metrics-derived-from-the-confusion-matrix" id="toc-metrics-derived-from-the-confusion-matrix" class="nav-link" data-scroll-target="#metrics-derived-from-the-confusion-matrix">Metrics derived from the confusion matrix:</a></li>
  <li><a href="#key-takeaways-1" id="toc-key-takeaways-1" class="nav-link" data-scroll-target="#key-takeaways-1">Key Takeaways:</a></li>
  <li><a href="#summary-of-whats-happening" id="toc-summary-of-whats-happening" class="nav-link" data-scroll-target="#summary-of-whats-happening">Summary of What’s Happening:</a></li>
  <li><a href="#why-perform-these-steps" id="toc-why-perform-these-steps" class="nav-link" data-scroll-target="#why-perform-these-steps">Why Perform These Steps?</a></li>
  <li><a href="#cross-validation-f1-scores" id="toc-cross-validation-f1-scores" class="nav-link" data-scroll-target="#cross-validation-f1-scores">Cross-Validation F1 Scores:</a></li>
  <li><a href="#mean-f1-score" id="toc-mean-f1-score" class="nav-link" data-scroll-target="#mean-f1-score">Mean F1 Score:</a></li>
  <li><a href="#standard-deviation-of-f1-scores" id="toc-standard-deviation-of-f1-scores" class="nav-link" data-scroll-target="#standard-deviation-of-f1-scores">Standard Deviation of F1 Scores:</a></li>
  <li><a href="#interpretation-2" id="toc-interpretation-2" class="nav-link" data-scroll-target="#interpretation-2">Interpretation:</a></li>
  <li><a href="#results-and-discussion" id="toc-results-and-discussion" class="nav-link" data-scroll-target="#results-and-discussion">Results and Discussion:</a></li>
  <li><a href="#implications-and-future-directions" id="toc-implications-and-future-directions" class="nav-link" data-scroll-target="#implications-and-future-directions">Implications and Future Directions:</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion:</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection</h1>
</div>

<div>
  <div class="description">
    A machine learning model to detect off-task behavior
  </div>
</div>

<div class="quarto-title-meta-author column-page-left">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">John Baker </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Penn GSE: University of Pennsylvania Graduate School of Education
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-page-left">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 18, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction:</h3>
<p>In the field of educational data mining, detecting off-task behavior is crucial for understanding student engagement and improving learning outcomes. This paper presents an in-depth analysis of machine learning models designed to classify off-task behavior in educational settings. We explore the challenges of working with imbalanced datasets and evaluate the performance of various classifiers, including Random Forest, XGBoost, and Gradient Boosting. Through a series of experiments and analyses, we aim to optimize model performance and provide insights into the complexities of behavior detection in educational contexts.</p>
</section>
<section id="methodology" class="level3">
<h3 class="anchored" data-anchor-id="methodology">Methodology:</h3>
<p>Our study employed a multi-step approach to develop and evaluate machine learning models:</p>
<ol type="1">
<li>Data Preparation: We utilized a dataset containing features related to student behavior, with a binary target variable indicating off-task status (OffTask: Y/N).</li>
<li>Model Selection: We implemented three main classifiers: Random Forest, XGBoost, and Gradient Boosting.</li>
<li>Handling Class Imbalance: To address the imbalanced nature of the dataset, we applied the Synthetic Minority Over-sampling Technique (SMOTE).</li>
<li>Hyperparameter Tuning: We used GridSearchCV to optimize model parameters, focusing on maximizing the F1-score.</li>
<li>Threshold Optimization: We explored various decision thresholds to balance precision and recall, particularly for the minority class (off-task behavior).</li>
<li>Performance Evaluation: We assessed model performance using metrics such as Cohen’s Kappa score, precision, recall, F1-score, and confusion matrices.</li>
<li>Cross-Validation: We employed k-fold cross-validation to ensure robust performance estimates across different data subsets.</li>
</ol>
<p>This code snippet is focused on training a machine learning model to classify whether a task is “OffTask” (a binary outcome). Let’s break it down step by step:</p>
<div id="55c8c152" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score, GridSearchCV</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, GradientBoostingClassifier</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, cohen_kappa_score, precision_recall_curve, classification_report, confusion_matrix</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li>Importing Libraries</li>
</ol>
<ul>
<li>pandas: Used for data manipulation.</li>
<li>train_test_split: Used to split the dataset into training and testing sets.</li>
<li>GridSearchCV: Helps in finding the optimal hyperparameters for the model.</li>
<li>RandomForestClassifier: A decision-tree-based classifier that combines many trees to improve performance.</li>
<li>SMOTE: Synthetic Minority Over-sampling Technique, used to handle class imbalance in the training data.</li>
<li>classification_report: Used to generate a detailed report on model performance metrics.</li>
</ul>
<div id="be14c6c5" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="annotated-cell-2"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-2-1"><a href="#annotated-cell-2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-2-2" class="code-annotation-target"><a href="#annotated-cell-2-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'data/ca1-dataset.csv'</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-2" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="2" data-code-annotation="2">Loading the Dataset</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>Loads the dataset from the CSV file.</li>
</ul>
<div id="c908ec6e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'OffTask'</span>] <span class="op">=</span> data[<span class="st">'OffTask'</span>].<span class="bu">map</span>({<span class="st">'N'</span>: <span class="dv">0</span>, <span class="st">'Y'</span>: <span class="dv">1</span>})  <span class="co"># Encode target variable</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.drop(columns<span class="op">=</span>[<span class="st">'Unique-id'</span>, <span class="st">'namea'</span>, <span class="st">'OffTask'</span>])  <span class="co"># Features</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">'OffTask'</span>]  <span class="co"># Target variable</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li>Preparing the Data</li>
</ol>
<ul>
<li>The target variable OffTask is encoded, converting ‘N’ (No) to 0 and ‘Y’ (Yes) to 1.</li>
<li>X is set as the feature set by dropping irrelevant columns (‘Unique-id’, ‘namea’, ‘OffTask’).
<ul>
<li>y is the target variable, which is the encoded OffTask column.</li>
</ul></li>
</ul>
<div id="162d5c9f" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="4" type="1">
<li>Splitting Data</li>
</ol>
<ul>
<li>The dataset is split into training (80%) and testing sets (20%).</li>
</ul>
<div id="3ab76fe0" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply SMOTE to the training data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>X_train_resampled, y_train_resampled <span class="op">=</span> smote.fit_resample(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="5" type="1">
<li>Handling Imbalanced Data with SMOTE</li>
</ol>
<ul>
<li>SMOTE is applied to balance the classes in the training data. It creates synthetic samples for the minority class (OffTask == 1).
<ul>
<li>X_train_resampled and y_train_resampled contain the balanced training data.</li>
</ul></li>
</ul>
<div id="aeae186f" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the ratio of classes</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>class_0_count <span class="op">=</span> <span class="bu">sum</span>(y_train_resampled <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>class_1_count <span class="op">=</span> <span class="bu">sum</span>(y_train_resampled <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>ratio_of_classes <span class="op">=</span> class_0_count <span class="op">/</span> class_1_count</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="6" type="1">
<li>Class Distribution Check</li>
</ol>
<ul>
<li>Counts the number of instances in each class after resampling, to calculate the class ratio (0 = not off-task, 1 = off-task).</li>
</ul>
<div id="82cf82b8" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>, class_weight<span class="op">=</span><span class="st">'balanced'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="7" type="1">
<li>Defining the Model</li>
</ol>
<ul>
<li>A RandomForest model is instantiated. The class_weight=‘balanced’ argument is used to adjust weights inversely proportional to class frequencies.</li>
</ul>
<div id="0eea4548" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter grid</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>],</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="va">None</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="8" type="1">
<li>Setting Up Hyperparameter Tuning (GridSearchCV)</li>
</ol>
<ul>
<li>Defines the parameter grid for GridSearchCV to find the optimal combination of hyperparameters:
<ul>
<li>n_estimators: Number of trees.</li>
<li>max_depth: Maximum depth of trees.</li>
<li>min_samples_split: Minimum samples required to split a node.</li>
<li>min_samples_leaf: Minimum number of samples required in a leaf node.</li>
</ul></li>
</ul>
<div id="611191c5" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up GridSearchCV</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, param_grid<span class="op">=</span>param_grid,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                           scoring<span class="op">=</span><span class="st">'f1'</span>, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="9" type="1">
<li>GridSearchCV for Hyperparameter Tuning</li>
</ol>
<ul>
<li>GridSearchCV is initialized with:
<ul>
<li>model: The RandomForest classifier.</li>
<li>param_grid: The defined hyperparameter grid.</li>
<li>scoring=‘f1’: Uses the F1 score as the evaluation metric.</li>
<li>cv=5: Performs 5-fold cross-validation.</li>
<li>n_jobs=-1: Utilizes all available CPU cores.</li>
<li>verbose=2: Provides detailed output.</li>
</ul></li>
</ul>
<div id="e770039f" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GridSearchCV</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train_resampled, y_train_resampled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 108 candidates, totalling 540 fits</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=RandomForestClassifier(class_weight='balanced',
                                              random_state=42),
             n_jobs=-1,
             param_grid={'max_depth': [None, 10, 20, 30],
                         'min_samples_leaf': [1, 2, 4],
                         'min_samples_split': [2, 5, 10],
                         'n_estimators': [50, 100, 200]},
             scoring='f1', verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=RandomForestClassifier(class_weight='balanced',
                                              random_state=42),
             n_jobs=-1,
             param_grid={'max_depth': [None, 10, 20, 30],
                         'min_samples_leaf': [1, 2, 4],
                         'min_samples_split': [2, 5, 10],
                         'n_estimators': [50, 100, 200]},
             scoring='f1', verbose=2)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: RandomForestClassifier</label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=50,
                       random_state=42)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=50,
                       random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<ol start="10" type="1">
<li>Fitting the Model</li>
</ol>
<ul>
<li>Fits the GridSearchCV on the resampled training data to find the best hyperparameters.</li>
</ul>
<div id="d26b72c0" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="annotated-cell-11"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-11-1"><a href="#annotated-cell-11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best parameters</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-11" data-target-annotation="11" onclick="event.preventDefault();">11</a><span id="annotated-cell-11-2" class="code-annotation-target"><a href="#annotated-cell-11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best parameters found: "</span>, grid_search.best_params_)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-11" data-target-annotation="11">11</dt>
<dd>
<span data-code-cell="annotated-cell-11" data-code-lines="2" data-code-annotation="11">Output Best Parameters</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best parameters found:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}</code></pre>
</div>
</div>
<p>The best hyperparameters found for the <strong>RandomForestClassifier</strong> are:</p>
<ul>
<li><strong>max_depth = 20</strong>: The trees can grow to a depth of 20, allowing the model to capture more complexity in the data while preventing overfitting beyond that depth.</li>
<li><strong>min_samples_leaf = 1</strong>: A leaf node will have at least one sample, allowing for more detailed splits.</li>
<li><strong>min_samples_split = 2</strong>: A node will split if it has at least two samples, which is the default and provides the most flexibility for splitting.</li>
<li><strong>n_estimators = 50</strong>: The model will use 50 trees in the forest, balancing computational cost and performance.</li>
</ul>
<p>This setup likely balances the need for depth and leaf size with computational efficiency. If you want to further evaluate or adjust performance, you could test this configuration against other models or datasets.</p>
<p>In this code snippet, the model is being trained on resampled data, then evaluated on the test set using metrics like Cohen’s Kappa score and a classification report. Let’s go through it step by step:</p>
<div id="29d6ac44" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="annotated-cell-12"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-12-1"><a href="#annotated-cell-12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model on the resampled data</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-12" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-12-2" class="code-annotation-target"><a href="#annotated-cell-12-2" aria-hidden="true" tabindex="-1"></a>model.fit(X_train_resampled, y_train_resampled)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-12" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-12" data-code-lines="2" data-code-annotation="1">Train the Model</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display" data-execution_count="12">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(class_weight='balanced', random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked=""><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(class_weight='balanced', random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
<ul>
<li>This line trains the RandomForestClassifier (from the previous step) on the resampled training data (X_train_resampled and y_train_resampled).</li>
<li>The model will learn the relationships between the features in X_train_resampled and the target y_train_resampled (which includes synthetic samples from SMOTE).</li>
</ul>
<div id="a085fee9" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="annotated-cell-13"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-13-1"><a href="#annotated-cell-13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-13" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-13-2" class="code-annotation-target"><a href="#annotated-cell-13-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-13" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-13" data-code-lines="2" data-code-annotation="2">Make Predictions</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>After training, the model is used to predict the target labels for the test data (X_test), which was not resampled.</li>
<li>The predicted labels (y_pred) are compared with the actual labels (y_test) to evaluate performance.</li>
</ul>
<div id="066c1a6d" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="annotated-cell-14"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-14-1"><a href="#annotated-cell-14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-14" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-14-2" class="code-annotation-target"><a href="#annotated-cell-14-2" aria-hidden="true" tabindex="-1"></a>kappa <span class="op">=</span> cohen_kappa_score(y_test, y_pred)</span>
<span id="annotated-cell-14-3"><a href="#annotated-cell-14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Kappa Score (RandomForest):"</span>, kappa)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-14" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-14" data-code-lines="2" data-code-annotation="3">Evaluate the Model with Cohen’s Kappa Score</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Kappa Score (RandomForest): 0.40175953079178883</code></pre>
</div>
</div>
<ul>
<li>Cohen’s Kappa score is a statistic that measures inter-rater agreement for categorical items. It adjusts for the possibility that agreement occurs by chance. A Kappa score close to 1 means high agreement, while a score near 0 indicates little agreement beyond chance.</li>
<li>In this case, it evaluates how well the model’s predictions (y_pred) agree with the true labels (y_test).</li>
</ul>
<p>A <strong>Cohen’s Kappa Score</strong> of <strong>0.4018</strong> suggests a <strong>moderate level of agreement</strong> between the model’s predictions and the true labels on the test set. Here’s what this means:</p>
<ul>
<li><strong>Interpretation of Kappa Score:</strong>
<ul>
<li>A score of <strong>1</strong> would indicate perfect agreement (i.e., the model’s predictions exactly match the true labels).</li>
<li>A score of <strong>0</strong> would indicate that the agreement is no better than random guessing.</li>
<li><strong>0.40–0.59</strong> typically suggests <strong>moderate agreement</strong>. So, while your model is better than random, there is still room for improvement.</li>
</ul></li>
</ul>
<div id="412996b7" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="annotated-cell-15"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-15" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-15-1" class="code-annotation-target"><a href="#annotated-cell-15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-15" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-15" data-code-lines="1" data-code-annotation="4">Classification Report</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.98      0.97      0.97       147
           1       0.38      0.50      0.43         6

    accuracy                           0.95       153
   macro avg       0.68      0.73      0.70       153
weighted avg       0.96      0.95      0.95       153
</code></pre>
</div>
</div>
<ul>
<li>The classification report provides a detailed breakdown of the model’s performance in terms of:
<ul>
<li>Precision: The ratio of true positives to all predicted positives (measures how accurate the positive predictions are).</li>
<li>Recall (Sensitivity): The ratio of true positives to all actual positives (measures the model’s ability to detect positive instances).</li>
<li>F1-score: The harmonic mean of precision and recall, providing a balance between the two.</li>
<li>Support: The number of actual occurrences of each class in y_test.</li>
</ul></li>
</ul>
<p>The classification report provides important details about your model’s performance on both classes (0 and 1). Here’s a breakdown:</p>
</section>
<section id="class-0-majority-class" class="level3">
<h3 class="anchored" data-anchor-id="class-0-majority-class">1. <strong>Class 0 (Majority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.98 – Out of all the predictions where the model predicted class 0, 98% were correct.</li>
<li><strong>Recall</strong>: 0.97 – The model correctly identified 97% of all actual class 0 instances.</li>
<li><strong>F1-score</strong>: 0.97 – The harmonic mean of precision and recall is high, indicating excellent performance for class 0.</li>
</ul>
</section>
<section id="class-1-minority-class" class="level3">
<h3 class="anchored" data-anchor-id="class-1-minority-class">2. <strong>Class 1 (Minority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.38 – Out of all the predictions where the model predicted class 1, only 38% were correct. This shows that the model struggles to accurately predict the minority class.</li>
<li><strong>Recall</strong>: 0.50 – The model correctly identified 50% of actual class 1 instances, meaning it missed half of the off-task cases.</li>
<li><strong>F1-score</strong>: 0.43 – This is quite low, indicating a poor balance between precision and recall for class 1.</li>
</ul>
</section>
<section id="overall-metrics" class="level3">
<h3 class="anchored" data-anchor-id="overall-metrics">3. <strong>Overall Metrics</strong>:</h3>
<ul>
<li><strong>Accuracy</strong>: 0.95 – The model predicts 95% of the test instances correctly. However, because class 0 dominates the dataset, accuracy is not a good measure of performance in this case.</li>
<li><strong>Macro avg</strong> (averaging performance for both classes equally):
<ul>
<li><strong>Precision</strong>: 0.68</li>
<li><strong>Recall</strong>: 0.73</li>
<li><strong>F1-score</strong>: 0.70 – These averages suggest that the model performs significantly better for the majority class than the minority class.</li>
</ul></li>
<li><strong>Weighted avg</strong> (weighted by the number of instances in each class):
<ul>
<li><strong>Precision</strong>: 0.96</li>
<li><strong>Recall</strong>: 0.95</li>
<li><strong>F1-score</strong>: 0.95 – These values are dominated by class 0’s performance, which inflates the overall scores.</li>
</ul></li>
</ul>
</section>
<section id="key-observations" class="level3">
<h3 class="anchored" data-anchor-id="key-observations">Key Observations:</h3>
<ol type="1">
<li><strong>Class Imbalance Issue</strong>: The model is performing very well for class 0 (the majority class) but poorly for class 1 (the minority class), as seen from the low precision, recall, and F1-score for class 1.</li>
<li><strong>False Positives for Class 1</strong>: Precision for class 1 is only 0.38, meaning that a high proportion of the model’s class 1 predictions are incorrect.</li>
<li><strong>False Negatives for Class 1</strong>: The recall for class 1 (0.50) suggests that the model is missing half of the actual class 1 instances.</li>
</ol>
<p>In this code snippet, the model being used is XGBoost (eXtreme Gradient Boosting), and the process follows a similar structure to the RandomForestClassifier model, but with some key differences. Let’s break it down step by step:</p>
<div id="a2060d58" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="annotated-cell-16"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-16-1"><a href="#annotated-cell-16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the XGBoost model without the use_label_encoder parameter</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-16" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-16-2" class="code-annotation-target"><a href="#annotated-cell-16-2" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> XGBClassifier(eval_metric<span class="op">=</span><span class="st">'logloss'</span>, scale_pos_weight<span class="op">=</span>ratio_of_classes)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-16" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-16" data-code-lines="2" data-code-annotation="1">XGBoost Model Initialization</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>XGBClassifier: This is the classifier from the XGBoost library, which is an efficient and flexible implementation of gradient boosting.</li>
<li>eval_metric=‘logloss’: The evaluation metric used is logarithmic loss (logloss), which is commonly used for binary classification problems. It penalizes incorrect predictions, especially those made with high confidence.</li>
<li>scale_pos_weight=ratio_of_classes: This parameter helps to adjust the balance between the positive and negative classes in the dataset. ratio_of_classes is the ratio of the number of class 0 to class 1 instances (calculated earlier). Setting this helps XGBoost handle class imbalance by giving higher weight to the minority class.</li>
</ul>
<div id="23abaf62" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="annotated-cell-17"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-17-1"><a href="#annotated-cell-17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-17" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-17-2" class="code-annotation-target"><a href="#annotated-cell-17-2" aria-hidden="true" tabindex="-1"></a>xgb_model.fit(X_train_resampled, y_train_resampled)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-17" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-17" data-code-lines="2" data-code-annotation="2">Training the XGBoost Model</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display" data-execution_count="17">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='logloss',
              feature_types=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked=""><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;XGBClassifier<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='logloss',
              feature_types=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>
</div>
</div>
<ul>
<li>The model is trained on the resampled data (X_train_resampled, y_train_resampled) that was balanced using SMOTE in the previous steps. XGBoost learns the relationships between the features and the target (OffTask) using the training set.</li>
</ul>
<div id="2b022e91" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="annotated-cell-18"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-18-1"><a href="#annotated-cell-18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-18-2" class="code-annotation-target"><a href="#annotated-cell-18-2" aria-hidden="true" tabindex="-1"></a>y_pred_xgb <span class="op">=</span> xgb_model.predict(X_test)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-18" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="2" data-code-annotation="3">Making Predictions</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>After training, the XGBoost model makes predictions (y_pred_xgb) on the test set (X_test), which was not resampled.</li>
</ul>
<div id="862a4ebc" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="annotated-cell-19"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-19-1"><a href="#annotated-cell-19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-19" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-19-2" class="code-annotation-target"><a href="#annotated-cell-19-2" aria-hidden="true" tabindex="-1"></a>kappa_xgb <span class="op">=</span> cohen_kappa_score(y_test, y_pred_xgb)</span>
<span id="annotated-cell-19-3"><a href="#annotated-cell-19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Kappa Score (XGBoost):"</span>, kappa_xgb)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-19" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-19" data-code-lines="2" data-code-annotation="4">Evaluating the Model with Cohen’s Kappa Score</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Kappa Score (XGBoost): 0.29655172413793107</code></pre>
</div>
</div>
<ul>
<li>Cohen’s Kappa score is calculated again to measure how well the predicted labels (y_pred_xgb) agree with the true labels (y_test), taking into account the possibility of chance agreement. This will give a similar measure of agreement as with the RandomForest model.</li>
</ul>
<p>The <strong>Cohen’s Kappa Score</strong> for the <strong>XGBoost</strong> model is <strong>0.2966</strong>, which suggests <strong>fair agreement</strong> between the model’s predictions and the actual labels. Here’s a brief interpretation:</p>
<ul>
<li><strong>Comparison to Random Forest (Kappa Score: 0.4018)</strong>: The Kappa score for the XGBoost model is lower than that of the Random Forest model, indicating that XGBoost is not performing as well in terms of agreement with the true labels, especially when adjusted for chance.</li>
</ul>
</section>
<section id="insights" class="level3">
<h3 class="anchored" data-anchor-id="insights">Insights:</h3>
<ol type="1">
<li><strong>Class Imbalance</strong>: Even though XGBoost uses the <code>scale_pos_weight</code> parameter to handle class imbalance, it’s still struggling to improve performance for the minority class (class 1).</li>
<li><strong>Lower Performance</strong>: XGBoost may require further tuning or feature engineering to match or surpass the performance of the Random Forest model in this particular scenario.</li>
</ol>
<div id="9ee86e98" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="annotated-cell-20"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-20" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-20-1" class="code-annotation-target"><a href="#annotated-cell-20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_xgb))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-20" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-20" data-code-lines="1" data-code-annotation="5">Classification Report</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.98      0.94      0.96       147
           1       0.25      0.50      0.33         6

    accuracy                           0.92       153
   macro avg       0.61      0.72      0.65       153
weighted avg       0.95      0.92      0.93       153
</code></pre>
</div>
</div>
<p>The <strong>XGBoost classification report</strong> reveals interesting insights about the model’s performance on both classes:</p>
</section>
<section id="class-0-majority-class-1" class="level3">
<h3 class="anchored" data-anchor-id="class-0-majority-class-1">1. <strong>Class 0 (Majority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.98 – Out of all the predictions where the model predicted class 0, 98% were correct.</li>
<li><strong>Recall</strong>: 0.94 – The model correctly identified 94% of all actual class 0 instances.</li>
<li><strong>F1-score</strong>: 0.96 – The harmonic mean of precision and recall is high, indicating strong performance for the majority class.</li>
</ul>
</section>
<section id="class-1-minority-class-1" class="level3">
<h3 class="anchored" data-anchor-id="class-1-minority-class-1">2. <strong>Class 1 (Minority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.25 – Only 25% of the predictions made for class 1 were correct. This shows that the model is generating a significant number of <strong>false positives</strong> for class 1.</li>
<li><strong>Recall</strong>: 0.50 – The model correctly identified 50% of actual class 1 instances, meaning it’s missing half of the off-task instances.</li>
<li><strong>F1-score</strong>: 0.33 – This low score indicates poor performance for class 1 in terms of balancing precision and recall.</li>
</ul>
</section>
<section id="overall-metrics-1" class="level3">
<h3 class="anchored" data-anchor-id="overall-metrics-1">3. <strong>Overall Metrics</strong>:</h3>
<ul>
<li><strong>Accuracy</strong>: 0.92 – The model predicts 92% of the test instances correctly. However, accuracy is inflated by the high performance on the majority class (class 0).</li>
<li><strong>Macro avg</strong> (equal averaging for both classes):
<ul>
<li><strong>Precision</strong>: 0.61</li>
<li><strong>Recall</strong>: 0.72</li>
<li><strong>F1-score</strong>: 0.65 – These scores provide a more balanced look, showing the model’s struggles with the minority class.</li>
</ul></li>
<li><strong>Weighted avg</strong> (weighted by the number of instances in each class):
<ul>
<li><strong>Precision</strong>: 0.95</li>
<li><strong>Recall</strong>: 0.92</li>
<li><strong>F1-score</strong>: 0.93 – These scores are skewed by the majority class’s performance, making the overall model look better than it actually is for class 1.</li>
</ul></li>
</ul>
</section>
<section id="key-observations-1" class="level3">
<h3 class="anchored" data-anchor-id="key-observations-1">Key Observations:</h3>
<ol type="1">
<li><strong>Poor Precision for Class 1</strong>: Precision for class 1 is low at 0.25, meaning that most of the positive predictions for class 1 are incorrect.</li>
<li><strong>Moderate Recall for Class 1</strong>: The recall for class 1 (0.50) is better than Random Forest (0.50), indicating that the XGBoost model is identifying a higher proportion of the minority class, but still missing half.</li>
<li><strong>Imbalance in Class Performance</strong>: The model performs very well for the majority class but struggles significantly with the minority class.</li>
</ol>
<p>This code snippet is focused on training a Gradient Boosting model and evaluating its performance on the test set. Here’s what is happening in each step:</p>
<div id="ab45d82f" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="annotated-cell-21"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-21-1"><a href="#annotated-cell-21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Gradient Boosting model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-21" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-21-2" class="code-annotation-target"><a href="#annotated-cell-21-2" aria-hidden="true" tabindex="-1"></a>gb_model <span class="op">=</span> GradientBoostingClassifier(</span>
<span id="annotated-cell-21-3"><a href="#annotated-cell-21-3" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="annotated-cell-21-4"><a href="#annotated-cell-21-4" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,</span>
<span id="annotated-cell-21-5"><a href="#annotated-cell-21-5" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">10</span>,</span>
<span id="annotated-cell-21-6"><a href="#annotated-cell-21-6" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">200</span>,</span>
<span id="annotated-cell-21-7"><a href="#annotated-cell-21-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="annotated-cell-21-8"><a href="#annotated-cell-21-8" aria-hidden="true" tabindex="-1"></a>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-21" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-21" data-code-lines="2" data-code-annotation="1">Defining the Gradient Boosting Model</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>GradientBoostingClassifier: A machine learning algorithm that builds an ensemble of weak learners (typically decision trees) and optimizes them sequentially to minimize the error.</li>
<li>learning_rate=0.2: The rate at which the model learns. Lower values slow down the learning process but may lead to better accuracy.</li>
<li>max_depth=5: The maximum depth of the individual trees in the model. A depth of 5 helps balance complexity and overfitting.</li>
<li>min_samples_split=10: The minimum number of samples required to split an internal node. This helps reduce overfitting by ensuring that nodes don’t split too readily.</li>
<li>n_estimators=200: The number of trees (weak learners) in the ensemble. More trees can increase accuracy but also add computational cost.</li>
<li>random_state=42: Ensures reproducibility by fixing the random number generation seed.</li>
</ul>
<div id="96a55914" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="annotated-cell-22"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-22-1"><a href="#annotated-cell-22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model on the resampled training data</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-22" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-22-2" class="code-annotation-target"><a href="#annotated-cell-22-2" aria-hidden="true" tabindex="-1"></a>gb_model.fit(X_train_resampled, y_train_resampled)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-22" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-22" data-code-lines="2" data-code-annotation="2">Fitting the Model</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display" data-execution_count="22">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_split=10,
                           n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" checked=""><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GradientBoostingClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html">?<span>Documentation for GradientBoostingClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_split=10,
                           n_estimators=200, random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
<ul>
<li>The Gradient Boosting model is trained on the resampled training data (X_train_resampled and y_train_resampled) to account for class imbalance.</li>
<li>The model sequentially builds decision trees and combines them to minimize error across the ensemble.</li>
</ul>
<div id="1e31f191" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="annotated-cell-23"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-23-1"><a href="#annotated-cell-23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-23-2" class="code-annotation-target"><a href="#annotated-cell-23-2" aria-hidden="true" tabindex="-1"></a>y_pred_gb <span class="op">=</span> gb_model.predict(X_test)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-23" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="2" data-code-annotation="3">Making Predictions</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>After training, the model is used to make predictions on the unbalanced test set (X_test), producing the predicted labels (y_pred_gb).</li>
</ul>
<div id="b0258304" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="annotated-cell-24"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-24-1"><a href="#annotated-cell-24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-24" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-24-2" class="code-annotation-target"><a href="#annotated-cell-24-2" aria-hidden="true" tabindex="-1"></a>kappa_gb <span class="op">=</span> cohen_kappa_score(y_test, y_pred_gb)</span>
<span id="annotated-cell-24-3"><a href="#annotated-cell-24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Kappa Score (Gradient Boosting):"</span>, kappa_gb)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-24" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-24" data-code-lines="2" data-code-annotation="4">Evaluating the Model with Cohen’s Kappa Score</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Kappa Score (Gradient Boosting): 0.4137931034482758</code></pre>
</div>
</div>
<p>The <strong>Cohen’s Kappa Score</strong> for the <strong>Gradient Boosting</strong> model is <strong>0.4138</strong>, which indicates <strong>moderate agreement</strong> between the model’s predictions and the true labels. Here’s a quick analysis of this score:</p>
</section>
<section id="comparison-with-previous-models" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-previous-models"><strong>Comparison with Previous Models</strong>:</h3>
<ol type="1">
<li><strong>Gradient Boosting (0.4138)</strong>: The Kappa score for Gradient Boosting is slightly higher than that of the <strong>Random Forest (0.4018)</strong> and notably higher than <strong>XGBoost (0.2966)</strong>. This suggests that <strong>Gradient Boosting</strong> is performing the best so far in terms of agreement with the true labels, particularly when accounting for class imbalance.</li>
</ol>
</section>
<section id="what-this-means" class="level3">
<h3 class="anchored" data-anchor-id="what-this-means">What This Means:</h3>
<ul>
<li>This score indicates that the <strong>Gradient Boosting</strong> model is slightly better at handling the data’s class imbalance compared to Random Forest and XGBoost.</li>
<li>While the improvement is modest, this might suggest that Gradient Boosting is capturing more informative patterns in the data compared to the other models.</li>
</ul>
<div id="a89295b4" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="annotated-cell-25"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-25" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-25-1" class="code-annotation-target"><a href="#annotated-cell-25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_gb))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-25" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-25" data-code-lines="1" data-code-annotation="5">Classification Report</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.99      0.95      0.97       147
           1       0.33      0.67      0.44         6

    accuracy                           0.93       153
   macro avg       0.66      0.81      0.70       153
weighted avg       0.96      0.93      0.94       153
</code></pre>
</div>
</div>
<p>The <strong>classification report</strong> for the <strong>Gradient Boosting</strong> model provides important insights about the model’s performance on both the majority (class 0) and minority (class 1) classes. Here’s a detailed breakdown:</p>
</section>
<section id="class-0-majority-class-2" class="level3">
<h3 class="anchored" data-anchor-id="class-0-majority-class-2">1. <strong>Class 0 (Majority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.99 – The model is almost perfect in predicting class 0 correctly. Only 1% of the class 0 predictions were incorrect.</li>
<li><strong>Recall</strong>: 0.95 – The model correctly identifies 95% of the actual class 0 instances.</li>
<li><strong>F1-score</strong>: 0.97 – The high F1-score indicates strong overall performance for class 0, balancing precision and recall.</li>
</ul>
</section>
<section id="class-1-minority-class-2" class="level3">
<h3 class="anchored" data-anchor-id="class-1-minority-class-2">2. <strong>Class 1 (Minority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.33 – Only 33% of the class 1 predictions are correct, which means the model is still generating a considerable number of false positives.</li>
<li><strong>Recall</strong>: 0.67 – The model identifies 67% of the actual class 1 instances, meaning it correctly captures more of the minority class than in the other models.</li>
<li><strong>F1-score</strong>: 0.44 – This is a modest improvement compared to the previous models, showing that the model is starting to handle the minority class a bit better.</li>
</ul>
</section>
<section id="overall-metrics-2" class="level3">
<h3 class="anchored" data-anchor-id="overall-metrics-2">3. <strong>Overall Metrics</strong>:</h3>
<ul>
<li><strong>Accuracy</strong>: 0.93 – 93% of the total predictions are correct, but because of class imbalance, accuracy can be misleading. We need to focus more on the performance for class 1.</li>
<li><strong>Macro avg</strong> (equal averaging for both classes):
<ul>
<li><strong>Precision</strong>: 0.66</li>
<li><strong>Recall</strong>: 0.81</li>
<li><strong>F1-score</strong>: 0.70 – This average reflects that the model is doing relatively well at balancing both classes, though the performance on the minority class is still lagging.</li>
</ul></li>
<li><strong>Weighted avg</strong> (weighted by the number of instances in each class):
<ul>
<li><strong>Precision</strong>: 0.96</li>
<li><strong>Recall</strong>: 0.93</li>
<li><strong>F1-score</strong>: 0.94 – These scores are dominated by class 0’s performance.</li>
</ul></li>
</ul>
</section>
<section id="key-observations-2" class="level3">
<h3 class="anchored" data-anchor-id="key-observations-2">Key Observations:</h3>
<ol type="1">
<li><strong>Improvement for Class 1</strong>: The recall for class 1 (0.67) is better than what was observed with <strong>Random Forest</strong> and <strong>XGBoost</strong>, meaning the model is identifying a higher proportion of the actual minority class instances.</li>
<li><strong>Low Precision for Class 1</strong>: Precision is still low (0.33), indicating that the model struggles with false positives for the minority class.</li>
<li><strong>F1-Score for Class 1</strong>: The F1-score of 0.44 is an improvement over the previous models (Random Forest and XGBoost), showing that Gradient Boosting is doing a better job of handling the minority class, even if it still has room to improve.</li>
</ol>
<p>This code chunk demonstrates adjusting the decision threshold for the Gradient Boosting model’s predictions, and then evaluating the model’s performance based on this new threshold. Let’s break it down step by step:</p>
<div id="1c564df9" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="annotated-cell-26"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-26-1"><a href="#annotated-cell-26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted probabilities</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-26" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-26-2" class="code-annotation-target"><a href="#annotated-cell-26-2" aria-hidden="true" tabindex="-1"></a>y_pred_proba_gb <span class="op">=</span> gb_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-26" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-26" data-code-lines="2" data-code-annotation="1">Get Predicted Probabilities</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>gb_model.predict_proba(X_test): This function returns the predicted probabilities for each class (class 0 and class 1) on the test set.</li>
<li>[:, 1]: The output of predict_proba contains two columns: the first column corresponds to the probability that a sample belongs to class 0, and the second column corresponds to the probability that a sample belongs to class 1. By selecting [:, 1], you extract the probabilities for class 1 (the positive class).</li>
</ul>
<p>This step generates the probability estimates for each sample in the test set, which you’ll later use to make final predictions based on a custom threshold.</p>
<div id="72168973" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="annotated-cell-27"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-27-1"><a href="#annotated-cell-27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a new threshold</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-27" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-27-2" class="code-annotation-target"><a href="#annotated-cell-27-2" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="annotated-cell-27-3"><a href="#annotated-cell-27-3" aria-hidden="true" tabindex="-1"></a>y_pred_adjusted_gb <span class="op">=</span> (y_pred_proba_gb <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-27" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-27" data-code-lines="2" data-code-annotation="2">Set a New Threshold</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>threshold = 0.3: Instead of using the default decision threshold of 0.5 (which classifies a sample as class 1 if the predicted probability is ≥ 0.5), you set a new threshold of 0.3. This means that any sample with a predicted probability of 0.3 or higher will be classified as class 1.</li>
<li>y_pred_adjusted_gb = (y_pred_proba_gb &gt;= threshold).astype(int): This line compares each predicted probability to the new threshold (0.3). If the probability is greater than or equal to 0.3, the sample is classified as class 1; otherwise, it’s classified as class 0. The result is stored in y_pred_adjusted_gb.</li>
</ul>
<div id="af5eed42" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="annotated-cell-28"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-28-1"><a href="#annotated-cell-28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model with the adjusted predictions</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-28" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-28-2" class="code-annotation-target"><a href="#annotated-cell-28-2" aria-hidden="true" tabindex="-1"></a>kappa_adjusted_gb <span class="op">=</span> cohen_kappa_score(y_test, y_pred_adjusted_gb)</span>
<span id="annotated-cell-28-3"><a href="#annotated-cell-28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Adjusted Kappa Score (Gradient Boosting):"</span>, kappa_adjusted_gb)</span>
<span id="annotated-cell-28-4"><a href="#annotated-cell-28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_adjusted_gb))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-28" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-28" data-code-lines="2" data-code-annotation="3">Evaluate the Model with the Adjusted Predictions</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Adjusted Kappa Score (Gradient Boosting): 0.36514522821576767
              precision    recall  f1-score   support

           0       0.99      0.93      0.96       147
           1       0.29      0.67      0.40         6

    accuracy                           0.92       153
   macro avg       0.64      0.80      0.68       153
weighted avg       0.96      0.92      0.94       153
</code></pre>
</div>
</div>
<ul>
<li>cohen_kappa_score(y_test, y_pred_adjusted_gb): The Cohen’s Kappa Score is recalculated using the adjusted predictions (y_pred_adjusted_gb) to evaluate how well the adjusted model’s predictions agree with the true labels (y_test), adjusting for agreement that might happen by chance.</li>
<li>classification_report(y_test, y_pred_adjusted_gb): The classification report provides precision, recall, F1-score, and support for each class, but now based on the adjusted predictions (with the 0.3 threshold instead of the default 0.5).</li>
</ul>
<p>Why Adjust the Threshold? - Lowering the threshold (from 0.5 to 0.3 in this case) typically increases recall for the minority class (class 1) because more samples are classified as positive (class 1). This can help identify more true positives but may also increase false positives, affecting precision. - Customizing the threshold is a common technique when the default decision boundary (0.5) does not provide the best balance between precision and recall, especially when dealing with imbalanced datasets.</p>
<p>Purpose of this Adjustment: - By lowering the threshold, you’re trying to improve the model’s ability to detect the minority class (class 1), likely aiming to improve recall at the cost of precision. The Kappa score and classification report will help evaluate whether this adjustment provides a better trade-off for the given task.</p>
<p>The <strong>Adjusted Kappa Score</strong> and <strong>classification report</strong> show the effects of lowering the decision threshold to <strong>0.3</strong>. Let’s break down the results:</p>
</section>
<section id="adjusted-kappa-score" class="level3">
<h3 class="anchored" data-anchor-id="adjusted-kappa-score">1. <strong>Adjusted Kappa Score</strong>:</h3>
<ul>
<li><strong>Adjusted Kappa Score (0.3651)</strong>: After lowering the threshold, the Kappa score is <strong>0.365</strong>, which is slightly lower than the previous score of <strong>0.4138</strong> at the default threshold. This suggests a decrease in overall agreement between the model’s predictions and the actual labels, adjusting for chance.</li>
</ul>
</section>
<section id="class-0-majority-class-3" class="level3">
<h3 class="anchored" data-anchor-id="class-0-majority-class-3">2. <strong>Class 0 (Majority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.99 – The model still performs exceptionally well in correctly predicting class 0 (the majority class). Very few false positives for class 0.</li>
<li><strong>Recall</strong>: 0.93 – The recall for class 0 has decreased slightly from <strong>0.95</strong> (before the threshold adjustment) to <strong>0.93</strong>, indicating that more class 0 instances are being misclassified as class 1 due to the lower threshold.</li>
<li><strong>F1-score</strong>: 0.96 – The F1-score remains strong, meaning the model’s balance between precision and recall is still good for class 0.</li>
</ul>
</section>
<section id="class-1-minority-class-3" class="level3">
<h3 class="anchored" data-anchor-id="class-1-minority-class-3">3. <strong>Class 1 (Minority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.29 – The precision for class 1 has dropped from <strong>0.33</strong> (at the 0.5 threshold) to <strong>0.29</strong>. This means that a higher percentage of the predictions for class 1 are incorrect, reflecting an increase in false positives.</li>
<li><strong>Recall</strong>: 0.67 – The recall remains unchanged from <strong>0.67</strong>, which means the model is still identifying 67% of the actual class 1 instances, capturing more minority class cases than it would with a higher threshold.</li>
<li><strong>F1-score</strong>: 0.40 – The F1-score for class 1 has slightly improved (from <strong>0.44</strong> at 0.5 threshold to <strong>0.40</strong> now), reflecting a minor improvement in handling class 1.</li>
</ul>
</section>
<section id="overall-metrics-3" class="level3">
<h3 class="anchored" data-anchor-id="overall-metrics-3">4. <strong>Overall Metrics</strong>:</h3>
<ul>
<li><strong>Accuracy</strong>: 0.92 – The overall accuracy has decreased slightly (from <strong>0.93</strong> to <strong>0.92</strong>), which is expected since more class 0 instances are being misclassified due to the lower threshold.</li>
<li><strong>Macro avg</strong>:
<ul>
<li><strong>Precision</strong>: 0.64 – The model’s ability to correctly identify both classes has worsened due to the lower precision for class 1.</li>
<li><strong>Recall</strong>: 0.80 – The recall for both classes has improved slightly, as the model is now identifying more true positives for class 1.</li>
<li><strong>F1-score</strong>: 0.68 – A slight decrease from the F1-score of 0.70 with the default threshold.</li>
</ul></li>
<li><strong>Weighted avg</strong>: Dominated by the performance on class 0, but there is a slight decrease in all metrics due to the threshold adjustment.</li>
</ul>
</section>
<section id="key-observations-3" class="level3">
<h3 class="anchored" data-anchor-id="key-observations-3">Key Observations:</h3>
<ul>
<li><strong>Impact of Threshold Adjustment</strong>: Lowering the threshold to 0.3 has led to an <strong>increase in recall for class 1</strong>, meaning the model is identifying more true positives for the minority class. However, this comes at the cost of <strong>precision</strong> for class 1, as more false positives are generated.</li>
<li><strong>Trade-off Between Precision and Recall</strong>: The model is better at finding class 1 instances, but the precision suffers, indicating that many of the instances it classifies as class 1 are actually class 0.</li>
<li><strong>Overall Decrease in Kappa Score</strong>: The slight drop in the Kappa score reflects that the overall model performance has worsened slightly in terms of agreement between predictions and actual labels.</li>
</ul>
<p>This code snippet is designed to experiment with different decision thresholds for the Gradient Boosting model, then evaluate how precision, recall, and Cohen’s Kappa score change as the threshold varies. Here’s a breakdown of what’s happening:</p>
<div id="fc8452a1" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="annotated-cell-29"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-29-1"><a href="#annotated-cell-29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Experiment with different thresholds</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-29-2" class="code-annotation-target"><a href="#annotated-cell-29-2" aria-hidden="true" tabindex="-1"></a>thresholds <span class="op">=</span> np.arange(<span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.05</span>)</span>
<span id="annotated-cell-29-3"><a href="#annotated-cell-29-3" aria-hidden="true" tabindex="-1"></a>precisions <span class="op">=</span> []</span>
<span id="annotated-cell-29-4"><a href="#annotated-cell-29-4" aria-hidden="true" tabindex="-1"></a>recalls <span class="op">=</span> []</span>
<span id="annotated-cell-29-5"><a href="#annotated-cell-29-5" aria-hidden="true" tabindex="-1"></a>kappa_scores <span class="op">=</span> []</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-29" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="2" data-code-annotation="1">Setting Thresholds and Storing Results</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>thresholds: A range of thresholds is defined from 0.0 to 1.0 in increments of 0.05. These are the decision thresholds that will be used to convert predicted probabilities into binary class predictions (class 0 or class 1).</li>
<li>precisions, recalls, and kappa_scores: Empty lists are initialized to store the precision, recall, and Kappa scores for each threshold.</li>
</ul>
<div id="f323dae2" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="annotated-cell-30"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-30" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-30-1" class="code-annotation-target"><a href="#annotated-cell-30-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="annotated-cell-30-2"><a href="#annotated-cell-30-2" aria-hidden="true" tabindex="-1"></a>    y_pred_adjusted <span class="op">=</span> (y_pred_proba_gb <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="annotated-cell-30-3"><a href="#annotated-cell-30-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-30-4"><a href="#annotated-cell-30-4" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> np.<span class="bu">sum</span>(y_pred_adjusted[y_test <span class="op">==</span> <span class="dv">1</span>]) <span class="op">/</span> np.<span class="bu">sum</span>(y_pred_adjusted) <span class="cf">if</span> np.<span class="bu">sum</span>(y_pred_adjusted) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="annotated-cell-30-5"><a href="#annotated-cell-30-5" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> np.<span class="bu">sum</span>(y_pred_adjusted[y_test <span class="op">==</span> <span class="dv">1</span>]) <span class="op">/</span> np.<span class="bu">sum</span>(y_test) <span class="cf">if</span> np.<span class="bu">sum</span>(y_test) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="annotated-cell-30-6"><a href="#annotated-cell-30-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-30-7"><a href="#annotated-cell-30-7" aria-hidden="true" tabindex="-1"></a>    kappa <span class="op">=</span> cohen_kappa_score(y_test, y_pred_adjusted)</span>
<span id="annotated-cell-30-8"><a href="#annotated-cell-30-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-30-9"><a href="#annotated-cell-30-9" aria-hidden="true" tabindex="-1"></a>    precisions.append(precision)</span>
<span id="annotated-cell-30-10"><a href="#annotated-cell-30-10" aria-hidden="true" tabindex="-1"></a>    recalls.append(recall)</span>
<span id="annotated-cell-30-11"><a href="#annotated-cell-30-11" aria-hidden="true" tabindex="-1"></a>    kappa_scores.append(kappa)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-30" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-30" data-code-lines="1" data-code-annotation="2">Looping Over Thresholds and Calculating Metrics</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>y_pred_adjusted = (y_pred_proba_gb &gt;= threshold).astype(int): For each threshold, the predicted probabilities (y_pred_proba_gb) are converted into binary class predictions (0 or 1) using the current threshold.</li>
<li>Precision Calculation: Precision is calculated as the number of true positives divided by the total number of positive predictions (np.sum(y_pred_adjusted)), i.e., the ratio of correct positive predictions to all positive predictions. If no positive predictions are made, precision is set to 0.</li>
<li>Recall Calculation: Recall is calculated as the number of true positives divided by the total number of actual positives (np.sum(y_test)), i.e., the ratio of correct positive predictions to all actual positives.</li>
<li>Kappa Score: Cohen’s Kappa score is computed for each threshold to evaluate the agreement between predicted and actual labels while adjusting for chance.</li>
<li>Append Results: After calculating precision, recall, and Kappa score for the current threshold, these values are appended to their respective lists (precisions, recalls, kappa_scores).</li>
</ul>
<div id="dd60b86c" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="annotated-cell-31"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-31" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-31-1" class="code-annotation-target"><a href="#annotated-cell-31-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="annotated-cell-31-2"><a href="#annotated-cell-31-2" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="annotated-cell-31-3"><a href="#annotated-cell-31-3" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="annotated-cell-31-4"><a href="#annotated-cell-31-4" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, kappa_scores, label<span class="op">=</span><span class="st">'Kappa Score'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="annotated-cell-31-5"><a href="#annotated-cell-31-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision, Recall, and Kappa Score vs. Threshold'</span>)</span>
<span id="annotated-cell-31-6"><a href="#annotated-cell-31-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="annotated-cell-31-7"><a href="#annotated-cell-31-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="annotated-cell-31-8"><a href="#annotated-cell-31-8" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="fl">0.0</span>, <span class="fl">1.1</span>, <span class="fl">0.1</span>))</span>
<span id="annotated-cell-31-9"><a href="#annotated-cell-31-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="annotated-cell-31-10"><a href="#annotated-cell-31-10" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="annotated-cell-31-11"><a href="#annotated-cell-31-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-31" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-31" data-code-lines="1" data-code-annotation="3">Plotting Precision, Recall, and Kappa Score vs.&nbsp;Threshold</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-32-output-1.png" width="823" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>This section plots the three performance metrics (precision, recall, and Kappa score) against the thresholds:
<ul>
<li>X-axis: The threshold values.</li>
<li>Y-axis: The corresponding values for precision, recall, and Kappa score.</li>
</ul></li>
<li>The plot will help visualize how each metric changes as the decision threshold is adjusted.</li>
</ul>
<p>This graph displays the variation of Precision, Recall, and Kappa Score as a function of different decision thresholds for a classifier. Here’s a breakdown of each component:</p>
<ol type="1">
<li><p><strong>X-axis (Threshold)</strong>: This axis represents the decision threshold values, ranging from 0 to 1. A decision threshold determines the probability cut-off point at which the model predicts a positive class. Lower thresholds mean the model is more lenient in predicting the positive class, while higher thresholds make it stricter.</p></li>
<li><p><strong>Y-axis (Score)</strong>: This represents the corresponding score values for Precision, Recall, and Kappa Score, ranging from 0 to 1.</p></li>
<li><p><strong>Precision (Blue Line)</strong>:</p>
<ul>
<li>Precision measures the proportion of true positive predictions out of all positive predictions made by the model. In the graph, Precision increases as the threshold increases. Higher thresholds generally improve Precision because the model is making fewer positive predictions, but these are more likely to be correct.</li>
</ul></li>
<li><p><strong>Recall (Orange Line)</strong>:</p>
<ul>
<li>Recall measures the proportion of actual positives that the model correctly identifies. At lower thresholds, Recall is high (it starts at 1.0 at threshold 0), meaning the model is predicting most of the actual positives. However, as the threshold increases, the Recall stabilizes at around 0.7 across most threshold values before sharply dropping at the highest threshold (around 0.9).</li>
</ul></li>
<li><p><strong>Kappa Score (Green Line)</strong>:</p>
<ul>
<li>The Kappa Score evaluates the agreement between predicted labels and true labels while accounting for the possibility of random chance. The Kappa Score is relatively low at the lower thresholds but increases steadily as the threshold rises. It peaks around a threshold of 0.9, suggesting this might be the optimal threshold for balancing precision and recall, and then sharply decreases again at the highest threshold.</li>
</ul></li>
</ol>
</section>
<section id="observations" class="level3">
<h3 class="anchored" data-anchor-id="observations">Observations:</h3>
<ul>
<li><strong>Recall</strong> stays high for most threshold values, indicating that the model is capturing a lot of true positives consistently across the threshold range.</li>
<li><strong>Precision</strong> steadily rises, meaning that as the threshold increases, the model is making fewer but more accurate positive predictions.</li>
<li><strong>Kappa Score</strong> trends upward and peaks around a threshold of 0.9, indicating this might be a good balance between the precision and recall.</li>
</ul>
<p>In conclusion, this graph helps to analyze the trade-offs between Precision, Recall, and Kappa Score at different decision thresholds. Based on the graph, a threshold around 0.9 seems to offer a good balance between precision, recall, and the overall performance as measured by the Kappa score. However, this depends on your specific requirements, such as whether you prioritize minimizing false positives (favoring higher precision) or capturing all true positives (favoring higher recall).</p>
<div id="d9fc6a13" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="annotated-cell-32"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-32" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-32-1" class="code-annotation-target"><a href="#annotated-cell-32-1" aria-hidden="true" tabindex="-1"></a>best_threshold_index <span class="op">=</span> np.argmax(recalls)</span>
<span id="annotated-cell-32-2"><a href="#annotated-cell-32-2" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> thresholds[best_threshold_index]</span>
<span id="annotated-cell-32-3"><a href="#annotated-cell-32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Threshold for Maximum Recall: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="annotated-cell-32-4"><a href="#annotated-cell-32-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision at Best Threshold: </span><span class="sc">{</span>precisions[best_threshold_index]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="annotated-cell-32-5"><a href="#annotated-cell-32-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall at Best Threshold: </span><span class="sc">{</span>recalls[best_threshold_index]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="annotated-cell-32-6"><a href="#annotated-cell-32-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa Score at Best Threshold: </span><span class="sc">{</span>kappa_scores[best_threshold_index]<span class="sc">:.2f}</span><span class="ss">"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-32" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-32" data-code-lines="1" data-code-annotation="4">Finding and Printing the Best Threshold for Maximum Recall</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Threshold for Maximum Recall: 0.00
Precision at Best Threshold: 0.04
Recall at Best Threshold: 1.00
Kappa Score at Best Threshold: 0.00</code></pre>
</div>
</div>
<ul>
<li>best_threshold_index = np.argmax(recalls): This finds the index where recall is maximized. np.argmax() returns the index of the highest value in the recalls list.</li>
<li>best_threshold = thresholds[best_threshold_index]: The best threshold is selected based on the index where recall is maximized.</li>
<li>Print Statements: The threshold that maximizes recall, along with the precision, recall, and Kappa score at that threshold, is printed for further analysis.</li>
</ul>
<p>Purpose of this Experiment: - Threshold Tuning: By experimenting with different thresholds, the goal is to find the threshold that provides the best balance between precision and recall. Specifically, this code focuses on finding the threshold that maximizes recall, which can be useful when it’s important to correctly identify as many true positives as possible (e.g., identifying all instances of class 1, even if precision drops). - Trade-off Analysis: The plot and metrics allow for a visual and numerical comparison of how precision, recall, and Kappa score vary with the threshold, helping you make informed decisions about where to set the threshold based on your goals (e.g., prioritize recall or precision).</p>
<p>The results of finding the best threshold for <strong>maximum recall</strong> reveal some important insights:</p>
</section>
<section id="results-breakdown" class="level3">
<h3 class="anchored" data-anchor-id="results-breakdown">Results Breakdown:</h3>
<ul>
<li><p><strong>Best Threshold for Maximum Recall: 0.00</strong>: The threshold that maximizes recall is <strong>0.00</strong>, meaning that the model classifies all instances as class 1 (positive) since even the smallest predicted probability would be treated as class 1. This guarantees <strong>100% recall</strong> because all actual positive instances are identified (but also all the negative ones, leading to many false positives).</p></li>
<li><p><strong>Precision at Best Threshold: 0.04</strong>: The precision is <strong>very low (0.04)</strong>, meaning that out of all the instances classified as class 1, only 4% are actually correct. This indicates a <strong>high number of false positives</strong>, as almost every instance is incorrectly predicted as class 1.</p></li>
<li><p><strong>Recall at Best Threshold: 1.00</strong>: Recall is maximized at <strong>100%</strong>, meaning that the model is successfully identifying all instances of class 1 (i.e., no false negatives). While this may seem ideal for recall, it comes at a heavy cost to precision and overall model performance.</p></li>
<li><p><strong>Kappa Score at Best Threshold: 0.00</strong>: The <strong>Kappa score is 0</strong>, meaning that the model’s predictions are no better than random guessing at this threshold. This makes sense because, with a threshold of 0.00, the model is effectively classifying all instances as positive (class 1), which doesn’t demonstrate any meaningful predictive power.</p></li>
</ul>
</section>
<section id="interpretation" class="level3">
<h3 class="anchored" data-anchor-id="interpretation">Interpretation:</h3>
<ul>
<li><strong>Why Did This Happen?</strong>
<ul>
<li>By setting the threshold to <strong>0.00</strong>, the model classifies every instance as class 1, ensuring that all actual positives are captured (hence the perfect recall). However, this results in many false positives, as all instances, including those that should be class 0, are classified as class 1.</li>
<li>This outcome is typical when prioritizing <strong>recall</strong> over other metrics, especially when the model is evaluated on imbalanced datasets. A threshold of 0.00 forces the model to prioritize recall at the expense of precision, causing a near-total misclassification of the majority class (class 0).</li>
</ul></li>
<li><strong>Trade-off Between Precision and Recall</strong>:
<ul>
<li>Maximizing recall usually comes at the cost of precision. In this case, you’ve found the extreme point where recall is maximized but precision drops to almost zero.</li>
<li>This threshold would only be useful in scenarios where <strong>missing any positive instances is critical</strong>, even if it means generating a lot of false positives (e.g., in medical screenings or fraud detection, where catching every positive case is more important than precision).</li>
</ul></li>
</ul>
<p>This code snippet is focused on <strong>evaluating and selecting the best decision threshold</strong> for the model based on the <strong>F1-score</strong>, which balances precision and recall. Let’s break down what’s happening:</p>
<div id="d2629e56" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="annotated-cell-33"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-33-1"><a href="#annotated-cell-33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize lists to store precision, recall, and F1-score values</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-33" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-33-2" class="code-annotation-target"><a href="#annotated-cell-33-2" aria-hidden="true" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-33" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-33" data-code-lines="2" data-code-annotation="1">Initialize Lists to Store Metrics</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>A list called <code>f1_scores</code> is initialized to store the <strong>F1-score</strong> values calculated for each threshold. F1-score is a key metric for balancing precision and recall, especially for imbalanced datasets.</li>
</ul>
<div id="3c9fe56c" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="annotated-cell-34"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-34-1"><a href="#annotated-cell-34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate precision, recall, and F1-score for each threshold</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-34" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-34-2" class="code-annotation-target"><a href="#annotated-cell-34-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="annotated-cell-34-3"><a href="#annotated-cell-34-3" aria-hidden="true" tabindex="-1"></a>    y_pred_adjusted <span class="op">=</span> (y_pred_proba_gb <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="annotated-cell-34-4"><a href="#annotated-cell-34-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-34-5"><a href="#annotated-cell-34-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate precision and recall</span></span>
<span id="annotated-cell-34-6"><a href="#annotated-cell-34-6" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> np.<span class="bu">sum</span>(y_pred_adjusted[y_test <span class="op">==</span> <span class="dv">1</span>]) <span class="op">/</span> np.<span class="bu">sum</span>(y_pred_adjusted) <span class="cf">if</span> np.<span class="bu">sum</span>(y_pred_adjusted) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="annotated-cell-34-7"><a href="#annotated-cell-34-7" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> np.<span class="bu">sum</span>(y_pred_adjusted[y_test <span class="op">==</span> <span class="dv">1</span>]) <span class="op">/</span> np.<span class="bu">sum</span>(y_test) <span class="cf">if</span> np.<span class="bu">sum</span>(y_test) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="annotated-cell-34-8"><a href="#annotated-cell-34-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-34-9"><a href="#annotated-cell-34-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate F1-score</span></span>
<span id="annotated-cell-34-10"><a href="#annotated-cell-34-10" aria-hidden="true" tabindex="-1"></a>    f1_score <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (precision <span class="op">*</span> recall) <span class="op">/</span> (precision <span class="op">+</span> recall) <span class="cf">if</span> (precision <span class="op">+</span> recall) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="annotated-cell-34-11"><a href="#annotated-cell-34-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-34-12"><a href="#annotated-cell-34-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append F1-score to the list</span></span>
<span id="annotated-cell-34-13"><a href="#annotated-cell-34-13" aria-hidden="true" tabindex="-1"></a>    f1_scores.append(f1_score)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-34" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-34" data-code-lines="2" data-code-annotation="2">Loop Over Different Thresholds</span>
</dd>
</dl>
</div>
</div>
<ul>
<li>The loop iterates over a range of thresholds (<code>thresholds</code>), which were defined earlier (e.g., from 0 to 1 in steps of 0.05).</li>
<li><strong><code>y_pred_adjusted = (y_pred_proba_gb &gt;= threshold).astype(int)</code></strong>: This line converts the predicted probabilities into binary class predictions (0 or 1) based on the current threshold.</li>
<li><strong>Precision</strong>: The number of true positives (correct class 1 predictions) divided by the total number of positive predictions. If no positive predictions were made, precision is set to 0.</li>
<li><strong>Recall</strong>: The number of true positives divided by the total number of actual positives in the test set. If there are no actual positives, recall is set to 0.</li>
</ul>
<ol start="3" type="1">
<li>Calculate the F1-Score</li>
</ol>
<ul>
<li>The <strong>F1-score</strong> is calculated using the formula:<br>
[ F1 = 2 ]
<ul>
<li>If both precision and recall are 0, the F1-score is set to 0 to avoid division by zero.</li>
<li>The F1-score balances precision and recall, making it useful for scenarios where both metrics are important, especially when dealing with class imbalances.</li>
</ul></li>
<li>The calculated F1-score for each threshold is appended to the <code>f1_scores</code> list.</li>
</ul>
<div id="5793d72a" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Precision, Recall, and F1-Score curve</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, f1_scores, label<span class="op">=</span><span class="st">'F1 Score'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision, Recall, and F1 Score vs. Threshold'</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="fl">0.0</span>, <span class="fl">1.1</span>, <span class="fl">0.1</span>))</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-36-output-1.png" width="823" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol start="4" type="1">
<li>Plot Precision, Recall, and F1-Score vs.&nbsp;Threshold</li>
</ol>
<ul>
<li>This section creates a plot showing how <strong>precision</strong>, <strong>recall</strong>, and <strong>F1-score</strong> change as the threshold varies.
<ul>
<li><strong>X-axis</strong>: The threshold values (0 to 1).</li>
<li><strong>Y-axis</strong>: The corresponding precision, recall, and F1-score values.</li>
</ul></li>
<li>The plot helps visualize the trade-offs between precision, recall, and the F1-score as the threshold changes, which can help determine the best threshold for a specific goal.</li>
</ul>
<p>This graph visualizes <strong>Precision</strong>, <strong>Recall</strong>, and <strong>F1 Score</strong> as a function of different decision thresholds, similar to the previous one but with the addition of the <strong>F1 Score</strong>.</p>
</section>
<section id="breakdown-of-the-graph" class="level3">
<h3 class="anchored" data-anchor-id="breakdown-of-the-graph">Breakdown of the Graph:</h3>
<ol type="1">
<li><p><strong>X-axis (Threshold)</strong>: The decision threshold values range from 0 to 1, indicating how strict the model is in deciding whether to classify an instance as positive.</p></li>
<li><p><strong>Y-axis (Score)</strong>: The scores for Precision, Recall, and F1 are represented on this axis, ranging from 0 to 1.</p></li>
<li><p><strong>Precision (Blue Line)</strong>:</p>
<ul>
<li>Precision measures the percentage of true positives out of the total positive predictions made. As the threshold increases, Precision steadily improves because the model becomes more conservative and selective in predicting the positive class, leading to fewer false positives.</li>
</ul></li>
<li><p><strong>Recall (Orange Line)</strong>:</p>
<ul>
<li>Recall represents the percentage of actual positives that are correctly identified. In this graph, Recall starts at 1.0 at a threshold of 0 (the model is classifying everything as positive) and then stabilizes at around 0.7 for most threshold values. At very high thresholds, Recall sharply drops, indicating the model is becoming too conservative and missing many actual positives.</li>
</ul></li>
<li><p><strong>F1 Score (Green Line)</strong>:</p>
<ul>
<li>The F1 Score is the harmonic mean of Precision and Recall, providing a single measure of performance that balances the trade-off between these two metrics. It is particularly useful when the class distribution is imbalanced or when both Precision and Recall are important. In this graph, the F1 Score starts relatively high at lower thresholds, increases steadily, peaks around a threshold of 0.9, and then decreases sharply at the highest thresholds. The peak indicates the best balance between Precision and Recall, where both metrics are reasonably high.</li>
</ul></li>
</ol>
</section>
<section id="observations-1" class="level3">
<h3 class="anchored" data-anchor-id="observations-1">Observations:</h3>
<ul>
<li><strong>Recall</strong> stays relatively high across most threshold values, stabilizing around 0.7 before dropping near the highest threshold.</li>
<li><strong>Precision</strong> increases steadily, with higher thresholds leading to fewer but more accurate positive predictions.</li>
<li><strong>F1 Score</strong> increases as both Precision and Recall improve, peaking around a threshold of 0.9. This threshold appears to offer the best balance between Precision and Recall.</li>
</ul>
</section>
<section id="key-insights" class="level3">
<h3 class="anchored" data-anchor-id="key-insights">Key Insights:</h3>
<ul>
<li><strong>Threshold 0.9</strong> seems to provide the optimal balance between Precision and Recall, as reflected by the peak F1 Score.</li>
<li>At <strong>lower thresholds</strong>, Recall dominates, indicating that the model is predicting most positives but at the cost of lower Precision (more false positives).</li>
<li>At <strong>higher thresholds</strong>, Precision improves but Recall falls, suggesting the model is more cautious, predicting fewer positives but with greater accuracy.</li>
</ul>
<p>This graph helps in selecting a threshold that balances both Precision and Recall, with the <strong>F1 Score</strong> offering a useful summary metric when both are important to optimize.</p>
<div id="d2f2ca27" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="annotated-cell-36"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-36-1"><a href="#annotated-cell-36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the best threshold based on maximum F1-score</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-36" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-36-2" class="code-annotation-target"><a href="#annotated-cell-36-2" aria-hidden="true" tabindex="-1"></a>best_threshold_index <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="annotated-cell-36-3"><a href="#annotated-cell-36-3" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> thresholds[best_threshold_index]</span>
<span id="annotated-cell-36-4"><a href="#annotated-cell-36-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Threshold for Maximum F1-Score: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="annotated-cell-36-5"><a href="#annotated-cell-36-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision at Best Threshold: </span><span class="sc">{</span>precisions[best_threshold_index]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="annotated-cell-36-6"><a href="#annotated-cell-36-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall at Best Threshold: </span><span class="sc">{</span>recalls[best_threshold_index]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="annotated-cell-36-7"><a href="#annotated-cell-36-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa Score at Best Threshold: </span><span class="sc">{</span>kappa_scores[best_threshold_index]<span class="sc">:.2f}</span><span class="ss">"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-36" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-36" data-code-lines="2" data-code-annotation="5">Find and Print the Best Threshold Based on F1-Score</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Threshold for Maximum F1-Score: 0.90
Precision at Best Threshold: 0.50
Recall at Best Threshold: 0.67
Kappa Score at Best Threshold: 0.55</code></pre>
</div>
</div>
<ul>
<li><strong><code>best_threshold_index = np.argmax(f1_scores)</code></strong>: Finds the index of the maximum F1-score from the <code>f1_scores</code> list.</li>
<li><strong><code>best_threshold = thresholds[best_threshold_index]</code></strong>: Using the index of the maximum F1-score, this retrieves the corresponding threshold value that maximizes the F1-score.</li>
<li><strong>Print Statements</strong>: The script prints the best threshold, along with the precision, recall, and Kappa score at that threshold. This helps you see the trade-offs between these metrics and allows you to decide whether the chosen threshold aligns with your goals.</li>
</ul>
</section>
<section id="purpose-of-this-code" class="level3">
<h3 class="anchored" data-anchor-id="purpose-of-this-code">Purpose of This Code:</h3>
<ul>
<li>The code aims to find the best decision threshold based on <strong>F1-score</strong>, which balances precision and recall.</li>
<li>It provides a comprehensive evaluation of how different thresholds impact key performance metrics (precision, recall, F1-score, and Kappa score).</li>
<li>It helps you <strong>optimize the threshold</strong> to improve model performance, especially for cases where precision and recall are critical and where class imbalance is present.</li>
</ul>
<p>The results from the code show that the <strong>best threshold</strong> for maximizing the <strong>F1-score</strong> is <strong>0.90</strong>. Here’s a breakdown of the key metrics at this threshold:</p>
</section>
<section id="best-threshold-for-maximum-f1-score-0.90" class="level3">
<h3 class="anchored" data-anchor-id="best-threshold-for-maximum-f1-score-0.90">1. <strong>Best Threshold for Maximum F1-Score: 0.90</strong></h3>
<ul>
<li>A threshold of <strong>0.90</strong> means that the model is quite conservative in classifying a sample as class 1 (positive). It requires a predicted probability of at least 0.90 before classifying a sample as positive.</li>
<li>This is a relatively high threshold, indicating that the model is more selective about labeling class 1 instances, which tends to reduce false positives but might also miss some true positives.</li>
</ul>
</section>
<section id="precision-at-best-threshold-0.50" class="level3">
<h3 class="anchored" data-anchor-id="precision-at-best-threshold-0.50">2. <strong>Precision at Best Threshold: 0.50</strong></h3>
<ul>
<li><strong>Precision: 0.50</strong>: Half of the instances predicted as class 1 are actually correct. A precision of 0.50 means the model is fairly balanced in making positive predictions, though there is still a significant proportion of false positives.</li>
<li><strong>Trade-off</strong>: By setting the threshold to 0.90, precision is improved compared to lower thresholds where the model might have more false positives.</li>
</ul>
</section>
<section id="recall-at-best-threshold-0.67" class="level3">
<h3 class="anchored" data-anchor-id="recall-at-best-threshold-0.67">3. <strong>Recall at Best Threshold: 0.67</strong></h3>
<ul>
<li><strong>Recall: 0.67</strong>: The model correctly identifies <strong>67%</strong> of the actual class 1 instances. This is a decent recall, but some true positives are missed (false negatives). This is expected with a higher threshold like 0.90, where the model is more conservative in predicting class 1.</li>
<li><strong>Trade-off</strong>: While recall is decent, it is not maximized due to the high threshold, which reduces the likelihood of predicting class 1 and increases false negatives.</li>
</ul>
</section>
<section id="kappa-score-at-best-threshold-0.55" class="level3">
<h3 class="anchored" data-anchor-id="kappa-score-at-best-threshold-0.55">4. <strong>Kappa Score at Best Threshold: 0.55</strong></h3>
<ul>
<li><strong>Kappa Score: 0.55</strong>: The Kappa score indicates <strong>moderate agreement</strong> between the model’s predictions and the actual labels, adjusting for chance. This is a relatively strong Kappa score, suggesting the threshold of 0.90 provides good overall performance.</li>
</ul>
</section>
<section id="interpretation-1" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-1">Interpretation:</h3>
<ul>
<li><strong>Balanced Performance</strong>: The F1-score is maximized at this threshold, indicating a <strong>balance between precision and recall</strong>. The high threshold of 0.90 ensures that the model is making more conservative (and accurate) positive predictions, leading to fewer false positives and a reasonable number of true positives.</li>
<li><strong>Improved Kappa</strong>: The Kappa score of <strong>0.55</strong> is higher than in earlier scenarios, indicating that this threshold provides better agreement between predicted and actual values compared to other thresholds.</li>
</ul>
<p>This code snippet applies the <strong>best threshold</strong> (0.90) that was found in the previous analysis and evaluates the performance of the <strong>Gradient Boosting model</strong> using that threshold. Here’s a step-by-step breakdown:</p>
<div id="939f80fa" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="annotated-cell-37"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-37-1"><a href="#annotated-cell-37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions using the new threshold</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-37" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-37-2" class="code-annotation-target"><a href="#annotated-cell-37-2" aria-hidden="true" tabindex="-1"></a>y_pred_final <span class="op">=</span> (gb_model.predict_proba(X_test)[:, <span class="dv">1</span>] <span class="op">&gt;=</span> <span class="fl">0.90</span>).astype(<span class="bu">int</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-37" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-37" data-code-lines="2" data-code-annotation="1">Make Predictions Using the New Threshold</span>
</dd>
</dl>
</div>
</div>
<ul>
<li><strong><code>gb_model.predict_proba(X_test)[:, 1]</code></strong>: This line computes the predicted probabilities for class 1 (positive class) on the test set (<code>X_test</code>). The <code>[:, 1]</code> selects the probabilities associated with class 1 (since <code>predict_proba</code> gives the probabilities for both class 0 and class 1).</li>
<li><strong><code>&gt;= 0.90</code></strong>: This applies the new threshold of <strong>0.90</strong>. If the predicted probability for class 1 is greater than or equal to 0.90, the sample is classified as class 1. Otherwise, it is classified as class 0.</li>
<li><strong><code>.astype(int)</code></strong>: Converts the boolean result (True/False) into integers (1 for class 1, 0 for class 0). The result is stored in <code>y_pred_final</code>, which contains the final class predictions based on the 0.90 threshold.</li>
</ul>
<div id="32fea77a" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="annotated-cell-38"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-38-1"><a href="#annotated-cell-38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model with the new predictions</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-38" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-38-2" class="code-annotation-target"><a href="#annotated-cell-38-2" aria-hidden="true" tabindex="-1"></a>kappa_final <span class="op">=</span> cohen_kappa_score(y_test, y_pred_final)</span>
<span id="annotated-cell-38-3"><a href="#annotated-cell-38-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Kappa Score with Threshold 0.90:"</span>, kappa_final)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-38" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-38" data-code-lines="2" data-code-annotation="2">Evaluate the Model Using Cohen’s Kappa Score</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Kappa Score with Threshold 0.90: 0.5513196480938416</code></pre>
</div>
</div>
<ul>
<li><strong><code>cohen_kappa_score(y_test, y_pred_final)</code></strong>: This calculates the <strong>Cohen’s Kappa Score</strong> using the actual test labels (<code>y_test</code>) and the final predictions (<code>y_pred_final</code>). The Kappa score evaluates the level of agreement between the predicted and true values, adjusting for agreement that could occur by chance.</li>
<li>The Kappa score is printed to provide a measure of the overall model performance after applying the new threshold.</li>
</ul>
<p>The <strong>Final Kappa Score</strong> of <strong>0.5513</strong> indicates <strong>moderate agreement</strong> between the model’s predictions and the true labels at the selected threshold of <strong>0.90</strong>. Here’s what this means:</p>
</section>
<section id="interpretation-of-the-kappa-score" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-the-kappa-score">Interpretation of the Kappa Score:</h3>
<ul>
<li>A Kappa score between <strong>0.41 and 0.60</strong> typically suggests <strong>moderate agreement</strong> between the predicted and true values.</li>
<li>This Kappa score (<strong>0.5513</strong>) indicates that the model, with a threshold of 0.90, has improved agreement between its predictions and actual labels compared to chance, but there is still room for improvement.</li>
</ul>
</section>
<section id="key-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways">Key Takeaways:</h3>
<ul>
<li><strong>Higher Kappa</strong>: The Kappa score is higher than what was observed at other thresholds like <strong>0.50</strong> or <strong>0.00</strong>, suggesting that this threshold strikes a good balance between precision and recall for this particular dataset.</li>
<li><strong>Moderate Performance</strong>: A Kappa score in this range means the model is making reasonably good predictions but may still have some misclassifications, particularly between classes 0 and 1.</li>
</ul>
<div id="b8ef3df5" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="annotated-cell-39"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-39-1"><a href="#annotated-cell-39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the classification report</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-39" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-39-2" class="code-annotation-target"><a href="#annotated-cell-39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_final))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-39" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-39" data-code-lines="2" data-code-annotation="3">Print the Classification Report</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.99      0.97      0.98       147
           1       0.50      0.67      0.57         6

    accuracy                           0.96       153
   macro avg       0.74      0.82      0.78       153
weighted avg       0.97      0.96      0.96       153
</code></pre>
</div>
</div>
<ul>
<li><strong><code>classification_report(y_test, y_pred_final)</code></strong>: This function prints a detailed <strong>classification report</strong> containing metrics like precision, recall, F1-score, and support for each class (class 0 and class 1).
<ul>
<li><strong>Precision</strong>: The proportion of true positive predictions out of all predicted positives.</li>
<li><strong>Recall</strong>: The proportion of actual positives that were correctly predicted by the model.</li>
<li><strong>F1-score</strong>: The harmonic mean of precision and recall, giving a balance between the two.</li>
<li><strong>Support</strong>: The number of actual occurrences of each class in <code>y_test</code>.</li>
</ul></li>
</ul>
<p>The report provides a comprehensive evaluation of how well the model performs under the new threshold, showing whether the adjustments improve the balance between precision and recall, especially for the minority class (class 1).</p>
</section>
<section id="purpose" class="level3">
<h3 class="anchored" data-anchor-id="purpose">Purpose:</h3>
<p>This code essentially finalizes the model by using the <strong>threshold of 0.90</strong> found earlier and evaluates its performance. The aim is to see how well the model predicts under the new threshold and to compare its performance against previous thresholds.</p>
<p>The <strong>classification report</strong> provides a detailed breakdown of the model’s performance at the chosen threshold of <strong>0.90</strong>. Here’s a closer look at the metrics:</p>
</section>
<section id="class-0-majority-class-4" class="level3">
<h3 class="anchored" data-anchor-id="class-0-majority-class-4">1. <strong>Class 0 (Majority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.99 – The model is very accurate when predicting class 0 (the majority class). Only 1% of the predictions for class 0 are false positives.</li>
<li><strong>Recall</strong>: 0.97 – The model correctly identifies 97% of the actual class 0 instances, meaning it misses very few class 0 instances.</li>
<li><strong>F1-score</strong>: 0.98 – The harmonic mean of precision and recall is very high, indicating excellent performance for class 0.</li>
</ul>
</section>
<section id="class-1-minority-class-4" class="level3">
<h3 class="anchored" data-anchor-id="class-1-minority-class-4">2. <strong>Class 1 (Minority Class)</strong>:</h3>
<ul>
<li><strong>Precision</strong>: 0.50 – Out of all the instances the model predicted as class 1, 50% were correct. This means the model is still generating a fair number of false positives for class 1.</li>
<li><strong>Recall</strong>: 0.67 – The model correctly identifies 67% of the actual class 1 instances, meaning it is still missing 33% of true positives (false negatives).</li>
<li><strong>F1-score</strong>: 0.57 – This F1-score shows a moderate balance between precision and recall for class 1. While the model is capturing most of the actual class 1 cases, there’s a trade-off with false positives.</li>
</ul>
</section>
<section id="overall-metrics-4" class="level3">
<h3 class="anchored" data-anchor-id="overall-metrics-4">3. <strong>Overall Metrics</strong>:</h3>
<ul>
<li><strong>Accuracy</strong>: 0.96 – The model is correctly classifying 96% of the total instances. However, given the class imbalance, accuracy is not the best indicator of performance, and the focus should be on precision, recall, and F1-score for class 1.</li>
<li><strong>Macro avg</strong>:
<ul>
<li><strong>Precision</strong>: 0.74</li>
<li><strong>Recall</strong>: 0.82</li>
<li><strong>F1-score</strong>: 0.78 – These averages reflect the balance between classes. While class 0 performs extremely well, class 1 struggles more, which is reflected in these average values.</li>
</ul></li>
<li><strong>Weighted avg</strong>:
<ul>
<li><strong>Precision</strong>: 0.97</li>
<li><strong>Recall</strong>: 0.96</li>
<li><strong>F1-score</strong>: 0.96 – These values are heavily influenced by the performance of class 0 (the majority class), which inflates the overall metrics.</li>
</ul></li>
</ul>
</section>
<section id="key-observations-4" class="level3">
<h3 class="anchored" data-anchor-id="key-observations-4">Key Observations:</h3>
<ol type="1">
<li><strong>Class Imbalance Issue</strong>: The model is performing very well for class 0 but has <strong>lower precision</strong> for class 1 (0.50), meaning it is generating false positives when predicting class 1.</li>
<li><strong>Improved Recall for Class 1</strong>: The recall for class 1 is <strong>0.67</strong>, which shows that the model is able to identify the majority of actual class 1 instances, though some are still being missed.</li>
<li><strong>F1-Score for Class 1</strong>: The F1-score of <strong>0.57</strong> indicates a moderate balance between precision and recall for the minority class. This is an improvement over previous thresholds but could still be further optimized depending on your goals.</li>
</ol>
<p>This code snippet performs three distinct tasks: calculating and visualizing the <strong>confusion matrix</strong>, performing <strong>k-fold cross-validation</strong>, and reporting <strong>cross-validation scores</strong>. Here’s a step-by-step breakdown of what’s happening:</p>
<div id="42f8a05b" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="annotated-cell-40"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-40-1"><a href="#annotated-cell-40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print confusion matrix</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-40" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-40-2" class="code-annotation-target"><a href="#annotated-cell-40-2" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred_final)</span>
<span id="annotated-cell-40-3"><a href="#annotated-cell-40-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, conf_matrix)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-40" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-40" data-code-lines="2" data-code-annotation="1">Confusion Matrix Calculation and Printing</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix:
 [[143   4]
 [  2   4]]</code></pre>
</div>
</div>
<ul>
<li><strong><code>confusion_matrix(y_test, y_pred_final)</code></strong>: This function calculates the <strong>confusion matrix</strong>, which summarizes the model’s performance in terms of:
<ul>
<li><strong>True Positives (TP)</strong>: Correct predictions of class 1.</li>
<li><strong>True Negatives (TN)</strong>: Correct predictions of class 0.</li>
<li><strong>False Positives (FP)</strong>: Incorrectly predicting class 1 when it is actually class 0.</li>
<li><strong>False Negatives (FN)</strong>: Incorrectly predicting class 0 when it is actually class 1.</li>
</ul>
The result is printed, showing the matrix of counts for these categories.</li>
</ul>
<p>The <strong>confusion matrix</strong> provides valuable insights into the performance of your model at the threshold of <strong>0.90</strong>:</p>
<pre><code>Confusion Matrix:
 [[143   4]
 [  2   4]]</code></pre>
</section>
<section id="breakdown" class="level3">
<h3 class="anchored" data-anchor-id="breakdown">Breakdown:</h3>
<ol type="1">
<li><strong>True Negatives (TN)</strong>: <strong>143</strong>
<ul>
<li>The model correctly predicted <strong>143 instances</strong> as class 0 (“Not OffTask”).</li>
</ul></li>
<li><strong>False Positives (FP)</strong>: <strong>4</strong>
<ul>
<li>The model incorrectly predicted <strong>4 instances</strong> as class 1 (“OffTask”), when they actually belong to class 0. These are false positives, meaning the model is making some mistakes when identifying off-task behavior.</li>
</ul></li>
<li><strong>False Negatives (FN)</strong>: <strong>2</strong>
<ul>
<li>The model incorrectly predicted <strong>2 instances</strong> as class 0 (“Not OffTask”), when they actually belong to class 1. These are false negatives, meaning the model missed identifying these off-task instances.</li>
</ul></li>
<li><strong>True Positives (TP)</strong>: <strong>4</strong>
<ul>
<li>The model correctly predicted <strong>4 instances</strong> as class 1 (“OffTask”). These are true positives, meaning the model correctly identified off-task behavior in 4 cases.</li>
</ul></li>
</ol>
</section>
<section id="key-observations-5" class="level3">
<h3 class="anchored" data-anchor-id="key-observations-5">Key Observations:</h3>
<ul>
<li><strong>True Negatives (143)</strong> are very high, which shows the model is strong at correctly identifying “Not OffTask” instances (class 0).</li>
<li><strong>False Positives (4)</strong> and <strong>False Negatives (2)</strong> are relatively low, which suggests the model is doing a decent job in general, but there are still some misclassifications.
<ul>
<li>False positives (classifying “Not OffTask” as “OffTask”) might indicate the model is being a bit too aggressive in predicting off-task behavior.</li>
<li>False negatives (missing actual “OffTask” cases) suggest there is room for improvement in identifying all off-task cases.</li>
</ul></li>
<li><strong>True Positives (4)</strong>: The model correctly identifies off-task behavior 4 out of 6 times, which is reflected in the recall for class 1 from the earlier classification report (recall of 0.67).</li>
</ul>
</section>
<section id="what-this-means-1" class="level3">
<h3 class="anchored" data-anchor-id="what-this-means-1">What This Means:</h3>
<ul>
<li>The model is doing well with <strong>class 0</strong> (“Not OffTask”), as expected given the class imbalance.</li>
<li>It is identifying the majority of <strong>class 1</strong> (“OffTask”) cases but still missing some, which is a typical challenge in imbalanced datasets.</li>
</ul>
<div id="2ae2b8ae" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the confusion matrix</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Not OffTask (0)'</span>, <span class="st">'OffTask (1)'</span>], </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Not OffTask (0)'</span>, <span class="st">'OffTask (1)'</span>])</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-42-output-1.png" width="623" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li>Visualizing the Confusion Matrix</li>
</ol>
<ul>
<li><strong><code>sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')</code></strong>: This uses Seaborn to create a heatmap of the confusion matrix. The following options are set:
<ul>
<li><strong><code>annot=True</code></strong>: Annotates each cell with the numeric count (e.g., TP, FP, etc.).</li>
<li><strong><code>fmt='d'</code></strong>: Ensures the annotations are integers (not floats).</li>
<li><strong><code>cmap='Blues'</code></strong>: Sets the color scheme to shades of blue for visual appeal.</li>
</ul></li>
<li><strong>Labels and Titles</strong>: X-axis and Y-axis are labeled with the predicted and actual class names (“Not OffTask (0)” and “OffTask (1)”), and the plot is titled “Confusion Matrix.”</li>
<li>The matrix is plotted to visually convey the counts of true positives, true negatives, false positives, and false negatives.</li>
</ul>
<p>This is a <strong>Confusion Matrix</strong>, which is a common tool used in classification tasks to evaluate the performance of a machine learning model. It provides a summary of the prediction results on a classification problem by showing how many instances of each class were correctly and incorrectly predicted.</p>
</section>
<section id="explanation-of-the-confusion-matrix" class="level3">
<h3 class="anchored" data-anchor-id="explanation-of-the-confusion-matrix">Explanation of the Confusion Matrix:</h3>
<ul>
<li><strong>Rows represent the actual class labels</strong> (in this case, “Not OffTask” and “OffTask”).</li>
<li><strong>Columns represent the predicted class labels</strong> (what the model predicted for those same classes).</li>
</ul>
<p>Let’s break down the elements in the matrix:</p>
<ol type="1">
<li><strong>Top-left (143)</strong>:
<ul>
<li>This value represents <strong>True Negatives (TN)</strong>. These are instances where the actual class was “Not OffTask (0)” and the model correctly predicted “Not OffTask (0)”.</li>
<li>There are 143 instances correctly classified as “Not OffTask.”</li>
</ul></li>
<li><strong>Top-right (4)</strong>:
<ul>
<li>This value represents <strong>False Positives (FP)</strong>. These are instances where the actual class was “Not OffTask (0)”, but the model incorrectly predicted “OffTask (1)”.</li>
<li>There are 4 instances where the model predicted “OffTask,” but the actual label was “Not OffTask.”</li>
</ul></li>
<li><strong>Bottom-left (2)</strong>:
<ul>
<li>This value represents <strong>False Negatives (FN)</strong>. These are instances where the actual class was “OffTask (1)”, but the model incorrectly predicted “Not OffTask (0)”.</li>
<li>There are 2 instances where the model missed predicting “OffTask” when it should have.</li>
</ul></li>
<li><strong>Bottom-right (4)</strong>:
<ul>
<li>This value represents <strong>True Positives (TP)</strong>. These are instances where the actual class was “OffTask (1)” and the model correctly predicted “OffTask (1)”.</li>
<li>There are 4 instances correctly classified as “OffTask.”</li>
</ul></li>
</ol>
</section>
<section id="metrics-derived-from-the-confusion-matrix" class="level3">
<h3 class="anchored" data-anchor-id="metrics-derived-from-the-confusion-matrix">Metrics derived from the confusion matrix:</h3>
<ul>
<li><p><strong>Accuracy</strong>: The overall correctness of the model. Calculated as:</p>
<p>[ = = = , ( 96.14%) ]</p></li>
<li><p><strong>Precision</strong>: The proportion of predicted positives that are actually positive:</p>
<p>[ = = = = 0.5 , ( 50%) ]</p></li>
<li><p><strong>Recall (Sensitivity)</strong>: The proportion of actual positives that are correctly predicted:</p>
<p>[ = = = , ( 66.67%) ]</p></li>
<li><p><strong>F1 Score</strong>: The harmonic mean of Precision and Recall:</p>
<p>[ = 2 = 2 ]</p></li>
</ul>
</section>
<section id="key-takeaways-1" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways-1">Key Takeaways:</h3>
<ul>
<li>The model performs well on predicting the “Not OffTask” class, as seen by the high number of <strong>True Negatives (143)</strong>.</li>
<li>However, the model struggles with identifying the “OffTask” class, with only <strong>4 True Positives</strong> and 2 instances where it missed predicting the class (False Negatives), alongside 4 False Positives.</li>
<li>The overall <strong>accuracy</strong> is high, but the relatively low <strong>precision</strong> for the “OffTask” class shows that the model is making some incorrect predictions when it predicts “OffTask.”</li>
</ul>
<p>This confusion matrix helps understand where the model is strong (predicting “Not OffTask”) and where it needs improvement (predicting “OffTask”).</p>
<div id="1c3e538d" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="annotated-cell-43"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-43-1"><a href="#annotated-cell-43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform k-fold cross-validation</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-43" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-43-2" class="code-annotation-target"><a href="#annotated-cell-43-2" aria-hidden="true" tabindex="-1"></a>cv_scores <span class="op">=</span> cross_val_score(gb_model, X, y, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'f1'</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-43" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-43" data-code-lines="2" data-code-annotation="3">Performing k-Fold Cross-Validation</span>
</dd>
</dl>
</div>
</div>
<ul>
<li><strong><code>cross_val_score(gb_model, X, y, cv=5, scoring='f1')</code></strong>: This function performs <strong>k-fold cross-validation</strong> on the Gradient Boosting model (<code>gb_model</code>), splitting the dataset into <strong>5 folds</strong> (<code>cv=5</code>), training on 4 folds, and testing on the remaining fold, repeated 5 times. The <strong>F1-score</strong> is used as the evaluation metric (<code>scoring='f1'</code>).
<ul>
<li><strong>F1-score</strong> is chosen because it balances precision and recall, which is especially important for imbalanced datasets like this.</li>
</ul>
Cross-validation helps evaluate how well the model generalizes to different subsets of the data, providing a more robust performance estimate.</li>
</ul>
<div id="391f24e1" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="annotated-cell-44"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-44-1"><a href="#annotated-cell-44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the cross-validation scores</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-44" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-44-2" class="code-annotation-target"><a href="#annotated-cell-44-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cross-Validation F1 Scores:"</span>, cv_scores)</span>
<span id="annotated-cell-44-3"><a href="#annotated-cell-44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean F1 Score:"</span>, np.mean(cv_scores))</span>
<span id="annotated-cell-44-4"><a href="#annotated-cell-44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Standard Deviation of F1 Scores:"</span>, np.std(cv_scores))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-44" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-44" data-code-lines="2" data-code-annotation="4">Printing Cross-Validation Scores</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Cross-Validation F1 Scores: [0.25       0.54545455 0.5        0.2        0.        ]
Mean F1 Score: 0.2990909090909091
Standard Deviation of F1 Scores: 0.20136722754852265</code></pre>
</div>
</div>
<ul>
<li><strong><code>cv_scores</code></strong>: The cross-validation process returns an array of F1-scores, one for each of the 5 folds.</li>
<li><strong><code>np.mean(cv_scores)</code></strong>: The average F1-score across the 5 folds is calculated, providing a general estimate of the model’s performance.</li>
<li><strong><code>np.std(cv_scores)</code></strong>: The standard deviation of the F1-scores is computed, showing how much variation there is in model performance across different folds.</li>
</ul>
</section>
<section id="summary-of-whats-happening" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-whats-happening">Summary of What’s Happening:</h3>
<ol type="1">
<li><strong>Confusion Matrix</strong>: The confusion matrix is calculated, printed, and visualized. It gives insights into the model’s prediction errors (false positives and false negatives) and its ability to classify both classes.</li>
<li><strong>Cross-Validation</strong>: The model undergoes 5-fold cross-validation, which evaluates its generalization performance and calculates F1-scores for each fold. The mean and standard deviation of these scores are printed to assess the model’s stability and consistency.</li>
</ol>
</section>
<section id="why-perform-these-steps" class="level3">
<h3 class="anchored" data-anchor-id="why-perform-these-steps">Why Perform These Steps?</h3>
<ul>
<li><strong>Confusion Matrix</strong>: Helps you understand exactly where the model is making errors—whether it’s more prone to false positives or false negatives.</li>
<li><strong>Cross-Validation</strong>: Ensures the model generalizes well to different subsets of the data, providing a more reliable estimate of its performance across unseen data.</li>
</ul>
<p>The cross-validation results provide important insights into the variability and performance of your model across different data subsets:</p>
</section>
<section id="cross-validation-f1-scores" class="level3">
<h3 class="anchored" data-anchor-id="cross-validation-f1-scores">Cross-Validation F1 Scores:</h3>
<ul>
<li>These scores represent the <strong>F1-scores</strong> (which balance precision and recall) across 5 different folds of the dataset.</li>
<li>The values vary significantly, ranging from <strong>0.0</strong> to <strong>0.545</strong>, indicating that the model’s performance is not consistent across the different subsets.</li>
</ul>
</section>
<section id="mean-f1-score" class="level3">
<h3 class="anchored" data-anchor-id="mean-f1-score">Mean F1 Score:</h3>
<ul>
<li>The <strong>mean F1-score</strong> is approximately <strong>0.299</strong>, meaning that, on average, the model’s performance in terms of balancing precision and recall is relatively low.</li>
<li>This is likely due to the difficulty of identifying the minority class (class 1), which is typical in imbalanced datasets like yours.</li>
</ul>
</section>
<section id="standard-deviation-of-f1-scores" class="level3">
<h3 class="anchored" data-anchor-id="standard-deviation-of-f1-scores">Standard Deviation of F1 Scores:</h3>
<ul>
<li>A <strong>standard deviation of 0.201</strong> indicates that the F1-scores fluctuate considerably between folds, suggesting <strong>instability in the model’s performance</strong> across different data splits.</li>
<li>This large variation implies that the model performs well on some subsets of data but poorly on others, which could be a sign of <strong>overfitting to specific folds</strong> or difficulties with the minority class (class 1) in certain splits.</li>
</ul>
</section>
<section id="interpretation-2" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-2">Interpretation:</h3>
<ol type="1">
<li><p><strong>Inconsistent Performance</strong>: The wide range of F1-scores (from <strong>0</strong> to <strong>0.545</strong>) suggests that the model may struggle with generalization, particularly when it comes to identifying class 1 (“OffTask”). Some folds likely have fewer class 1 examples, leading to poor performance in those cases.</p></li>
<li><p><strong>Average F1-Score</strong>: The average F1-score of <strong>0.299</strong> shows that while the model does identify some off-task cases, it is not particularly strong in consistently balancing precision and recall across folds.</p></li>
<li><p><strong>High Variability</strong>: The high standard deviation (<strong>0.201</strong>) indicates that the model’s performance is quite unstable, performing well in some data splits but failing in others (e.g., scoring <strong>0.0</strong> on one fold).</p></li>
</ol>
</section>
<section id="results-and-discussion" class="level3">
<h3 class="anchored" data-anchor-id="results-and-discussion">Results and Discussion:</h3>
<ol type="1">
<li><p>Model Performance Comparison: The Gradient Boosting model emerged as the top performer, achieving a Cohen’s Kappa score of 0.5513 at a decision threshold of 0.90. This score indicates moderate agreement between predicted and actual labels, surpassing both the Random Forest and XGBoost models.</p></li>
<li><p>Precision-Recall Trade-off: At the optimized threshold, the Gradient Boosting model achieved a precision of 0.50 and a recall of 0.67 for the off-task class. This balance reflects the challenge of detecting rare events in imbalanced datasets. The model successfully identified 67% of actual off-task instances while maintaining 50% precision in its positive predictions.</p></li>
<li><p>Class Imbalance Effects: The stark contrast in performance between the majority class (Not OffTask) and minority class (OffTask) highlights the persistent challenge of class imbalance. While the model excelled in identifying not off-task behavior (precision: 0.99, recall: 0.97), its performance on the off-task class was notably lower.</p></li>
<li><p>Confusion Matrix Analysis: The confusion matrix revealed that out of 153 test instances, the model correctly identified 143 not off-task cases and 4 off-task cases. However, it misclassified 4 not off-task instances as off-task (false positives) and missed 2 actual off-task instances (false negatives). This distribution underscores the model’s tendency to err on the side of caution when predicting off-task behavior.</p></li>
<li><p>Cross-Validation Insights: The cross-validation results (mean F1-score: 0.299, standard deviation: 0.201) exposed significant variability in model performance across different data subsets. This instability suggests that the model’s ability to generalize may be limited, particularly when dealing with the minority class in certain data splits.</p></li>
</ol>
</section>
<section id="implications-and-future-directions" class="level3">
<h3 class="anchored" data-anchor-id="implications-and-future-directions">Implications and Future Directions:</h3>
<ol type="1">
<li><p>Threshold Optimization: The study demonstrated the critical role of threshold optimization in balancing precision and recall for imbalanced datasets. Future research could explore dynamic thresholding techniques that adapt to varying class distributions.</p></li>
<li><p>Feature Engineering: Given the model’s inconsistent performance across folds, further feature engineering could help capture more robust indicators of off-task behavior, potentially improving generalization.</p></li>
<li><p>Ensemble Methods: The variability in cross-validation scores suggests that ensemble methods, such as stacking or boosting with different base learners, might yield more stable and accurate predictions.</p></li>
<li><p>Real-time Application: As the model achieves moderate success in identifying off-task behavior, future work could focus on implementing these classifiers in real-time educational settings, providing immediate feedback to educators.</p></li>
<li><p>Ethical Considerations: The use of machine learning for behavior detection raises important ethical questions about privacy and the potential for bias. Future studies should address these concerns and explore ways to ensure fair and transparent application of these technologies in educational environments.</p></li>
</ol>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion:</h3>
<p>This study provides valuable insights into the challenges and potential solutions for detecting off-task behavior in educational settings using machine learning techniques. While the Gradient Boosting model showed promising results, the analysis revealed persistent challenges related to class imbalance and generalization. These findings underscore the need for continued research and development in this field, with a focus on improving model stability, enhancing feature representation, and addressing ethical considerations. As we refine these techniques, the potential for data-driven interventions to support student engagement and learning outcomes becomes increasingly tangible.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Made with <a href="https://quarto.org/" target="_blank"><img src="https://quarto.org/quarto.png" class="img-fluid" width="65" alt="Quarto"></a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/baker-jr-john/Website" target="_blank">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>