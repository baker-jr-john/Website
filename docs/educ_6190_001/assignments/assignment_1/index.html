<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="John Baker">
<meta name="dcterms.date" content="2025-02-11">
<meta name="keywords" content="Intelligent Tutoring Systems, Conversational Agents, Educational Data Analysis">
<meta name="description" content="A Pipeline for Analyzing Conversational Agent Language Style and Its Impact on Written Summaries">

<title>John Baker – Learning Analytics – Penn GSE</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../simplified-shield.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-3d58872d45ebcc22bdba56a0a456e3b8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#background-and-related-work" id="toc-background-and-related-work" class="nav-link" data-scroll-target="#background-and-related-work">Background and Related Work</a>
  <ul class="collapse">
  <li><a href="#importance-of-numerical-data" id="toc-importance-of-numerical-data" class="nav-link" data-scroll-target="#importance-of-numerical-data">Importance of Numerical Data</a></li>
  <li><a href="#outlier-detection" id="toc-outlier-detection" class="nav-link" data-scroll-target="#outlier-detection">Outlier Detection</a></li>
  <li><a href="#data-transformation" id="toc-data-transformation" class="nav-link" data-scroll-target="#data-transformation">Data Transformation</a></li>
  <li><a href="#feature-scaling-and-normalization" id="toc-feature-scaling-and-normalization" class="nav-link" data-scroll-target="#feature-scaling-and-normalization">Feature Scaling and Normalization</a></li>
  <li><a href="#interaction-features" id="toc-interaction-features" class="nav-link" data-scroll-target="#interaction-features">Interaction Features</a></li>
  <li><a href="#feature-selection" id="toc-feature-selection" class="nav-link" data-scroll-target="#feature-selection">Feature Selection</a></li>
  <li><a href="#considerations-and-cautions" id="toc-considerations-and-cautions" class="nav-link" data-scroll-target="#considerations-and-cautions">Considerations and Cautions</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a></li>
  <li><a href="#implementation-details" id="toc-implementation-details" class="nav-link" data-scroll-target="#implementation-details">Implementation Details</a>
  <ul class="collapse">
  <li><a href="#data-preprocessing-handling-multiple-attempts" id="toc-data-preprocessing-handling-multiple-attempts" class="nav-link" data-scroll-target="#data-preprocessing-handling-multiple-attempts">Data Preprocessing: Handling Multiple Attempts</a></li>
  <li><a href="#loading-data" id="toc-loading-data" class="nav-link" data-scroll-target="#loading-data">Loading Data</a></li>
  <li><a href="#applying-the-processing-function-and-creating-a-test-variable" id="toc-applying-the-processing-function-and-creating-a-test-variable" class="nav-link" data-scroll-target="#applying-the-processing-function-and-creating-a-test-variable">Applying the Processing Function and Creating a Test Variable</a></li>
  <li><a href="#renaming-and-visualizing-the-writing-time-variable" id="toc-renaming-and-visualizing-the-writing-time-variable" class="nav-link" data-scroll-target="#renaming-and-visualizing-the-writing-time-variable">Renaming and Visualizing the Writing Time Variable</a></li>
  <li><a href="#outlier-replacement-and-log-transformation" id="toc-outlier-replacement-and-log-transformation" class="nav-link" data-scroll-target="#outlier-replacement-and-log-transformation">Outlier Replacement and Log Transformation</a></li>
  <li><a href="#visual-comparison-of-distribution-transformations" id="toc-visual-comparison-of-distribution-transformations" class="nav-link" data-scroll-target="#visual-comparison-of-distribution-transformations">Visual Comparison of Distribution Transformations</a></li>
  <li><a href="#feature-scaling-min-max-normalization" id="toc-feature-scaling-min-max-normalization" class="nav-link" data-scroll-target="#feature-scaling-min-max-normalization">Feature Scaling: Min-Max Normalization</a></li>
  <li><a href="#data-quality-assurance-and-aggregation" id="toc-data-quality-assurance-and-aggregation" class="nav-link" data-scroll-target="#data-quality-assurance-and-aggregation">Data Quality Assurance and Aggregation</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Enhancing Data Quality in Intelligent Tutoring Systems</h1>
</div>

<div>
  <div class="description">
    A Pipeline for Analyzing Conversational Agent Language Style and Its Impact on Written Summaries
  </div>
</div>

<div class="quarto-title-meta-author column-page-left">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">John Baker <a href="mailto:jbaker1@upenn.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://www.gse.upenn.edu/">
            Penn GSE: University of Pennsylvania Graduate School of Education
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-page-left">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 11, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>This project presents a comprehensive data processing pipeline designed to enhance the quality of raw log data from an Intelligent Tutoring System (ITS) and to evaluate the impact of conversational agent language styles on the quality of written summaries. Using AutoTutor ARC, adult participants engaged in pretest and posttest lessons where the language style of the conversational agents was varied among formal, informal, and mixed modalities. The raw data, characterized by multiple attempts per participant, missing values, and skewed distributions, necessitated a systematic approach to data cleaning and transformation. Our pipeline groups data by unique identifiers, retains the first non-null responses, detects and replaces outliers, applies a logarithmic transformation to reduce skewness, and normalizes key features via min-max scaling. The resulting data not only supports robust statistical analyses but also provides clear insights into how conversational agent language style influences learning outcomes. This work underscores the importance of rigorous data preparation in ITS research and offers a replicable framework for future studies examining the efficacy of adaptive educational technologies.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>Intelligent Tutoring Systems, Conversational Agents, Educational Data Analysis</p>
  </div>
</div>

</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Intelligent Tutoring Systems (ITS) have emerged as powerful tools for enhancing learning outcomes across various domains, including reading comprehension. These systems often employ conversational agents to interact with learners, providing personalized feedback and guidance. However, the effectiveness of these agents may depend on various factors, including their language style. This study investigates the impact of the conversational agents’ language style on the quality of written summaries produced by adult participants using AutoTutor ARC, an ITS designed to improve reading comprehension.</p>
<p>AutoTutor ARC collects extensive log data throughout the learning process, capturing participants’ interactions with the system across multiple lessons. The study design includes pretest assessments (lessons 2 and 3) and posttest assessments (lessons 9 and 10), enabling the comparison of performance before and after the intervention. The conversational agents’ language style is varied between formal, informal, and mixed styles to assess its influence on learning outcomes.</p>
<p>Given the inherent complexity of the raw log data, which is characterized by multiple attempts per participant and a diverse range of data formats, a systematic data processing pipeline is crucial. This pipeline aims to prepare the data for meaningful analysis by addressing common issues such as missing values, outliers, and skewed distributions. Furthermore, feature engineering techniques are employed to better capture the relevant variables for subsequent statistical analysis.</p>
<p>The present assignment focuses on the importance of numerical data in the context of this study, discussing its background, related work, and techniques. Moreover, it provides considerations and cautions when dealing with numerical data in the realm of machine learning and ITS research. By examining the role of data preparation in the AutoTutor ARC study, this assignment contributes to the broader understanding of how data processing techniques can support the evaluation and improvement of ITS interventions.</p>
</section>
<section id="background-and-related-work" class="level2">
<h2 class="anchored" data-anchor-id="background-and-related-work">Background and Related Work</h2>
<section id="importance-of-numerical-data" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-numerical-data">Importance of Numerical Data</h3>
<p>Data mining involves preprocessing and transforming data to generate patterns using analysis tools and algorithms. Outlying variables in recorded data can significantly affect the robustness of a model, making the identification of outliers before data analysis essential <span class="citation" data-cites="awawdeh2019application">(<a href="#ref-awawdeh2019application" role="doc-biblioref">Awawdeh et al. 2019</a>)</span>. Extreme values can cause problems in statistical analysis by increasing error variance, reducing statistical power, and biasing estimates. Therefore, screening data for extreme scores is crucial <span class="citation" data-cites="osborne2012best">(<a href="#ref-osborne2012best" role="doc-biblioref">Osborne 2012</a>)</span>.</p>
<p>Data cleaning, which includes screening for extreme scores, missing data, and normality, is a critical step in quantitative research to ensure the validity of results. However, this step is often overlooked <span class="citation" data-cites="osborne2012best">(<a href="#ref-osborne2012best" role="doc-biblioref">Osborne 2012</a>)</span>. Transformations are often necessary in data analysis to address issues such as non-normal distribution of errors in linear regression. These transformations can change the scale of variables, alter relationships between variables, and modify the error distributions <span class="citation" data-cites="pek2017data">(<a href="#ref-pek2017data" role="doc-biblioref">Pek, Wong, and Wong 2017</a>)</span>.</p>
</section>
<section id="outlier-detection" class="level3">
<h3 class="anchored" data-anchor-id="outlier-detection">Outlier Detection</h3>
<p>Outliers can be detected using various methods, such as re-weighted least squares (Re-WLS). The bisquare weights method can be used to minimize the effect of outliers in least-squares fitting, where points far from the fitted line will get zero weight and be considered outliers. Outliers can be addressed by either deleting or transforming them, depending on the number of outliers present. Deleting outliers is suitable when there are a limited number of outliers, while transformation is used when there are many <span class="citation" data-cites="awawdeh2019application">(<a href="#ref-awawdeh2019application" role="doc-biblioref">Awawdeh et al. 2019</a>)</span>.</p>
<p>Outlier detection methods have been studied and applied in various fields, including intrusion detection, wireless sensor networks, satellite image analysis, motion segmentation, and weather prediction <span class="citation" data-cites="awawdeh2019application">(<a href="#ref-awawdeh2019application" role="doc-biblioref">Awawdeh et al. 2019</a>)</span>.</p>
</section>
<section id="data-transformation" class="level3">
<h3 class="anchored" data-anchor-id="data-transformation">Data Transformation</h3>
<p>Data transformations are used to address non-normality. However, transformations can change the nature of the effect and should be applied carefully when interpreting effect sizes <span class="citation" data-cites="pek2017data">(<a href="#ref-pek2017data" role="doc-biblioref">Pek, Wong, and Wong 2017</a>)</span>. Various transformations include logarithmic, square root, and reciprocal, with logarithmic transformations being particularly useful for compressing heavy-tailed distributions. The Box-Cox transformation is a family of power transforms that includes the log <span class="citation" data-cites="zheng2018feature">(<a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>.</p>
<p>Winsorizing and trimming are techniques used to address data contamination by replacing or removing extreme values. However, these transformations can bias effect size estimates when extreme cases are not outliers. Reverse transformations are not generally recommended because inferential results do not necessarily map back onto the original effect <span class="citation" data-cites="pek2017data">(<a href="#ref-pek2017data" role="doc-biblioref">Pek, Wong, and Wong 2017</a>)</span>.</p>
</section>
<section id="feature-scaling-and-normalization" class="level3">
<h3 class="anchored" data-anchor-id="feature-scaling-and-normalization">Feature Scaling and Normalization</h3>
<p>Feature scaling, or normalization, is used to change the scale of the feature, which may be necessary for models sensitive to the input scale. Common scaling methods include min-max scaling, standardization, and L2 normalization <span class="citation" data-cites="zheng2018feature">(<a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>. Min-max scaling squeezes data to be within a specific range, while standardization results in data with a mean of 0 and a variance of 1 <span class="citation" data-cites="awawdeh2019application zheng2018feature">(<a href="#ref-awawdeh2019application" role="doc-biblioref">Awawdeh et al. 2019</a>; <a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>. Feature scaling does not change the shape of the distribution, only the scale <span class="citation" data-cites="zheng2018feature">(<a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>.</p>
</section>
<section id="interaction-features" class="level3">
<h3 class="anchored" data-anchor-id="interaction-features">Interaction Features</h3>
<p>Interaction features are created by combining pairs of input features, allowing models to capture interactions between features <span class="citation" data-cites="zheng2018feature">(<a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>.</p>
</section>
<section id="feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="feature-selection">Feature Selection</h3>
<p>Feature selection techniques, such as filtering, wrapper, and embedded methods, are used to reduce the computational expense of using many features and to identify the most useful features <span class="citation" data-cites="zheng2018feature">(<a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>.</p>
</section>
<section id="considerations-and-cautions" class="level3">
<h3 class="anchored" data-anchor-id="considerations-and-cautions">Considerations and Cautions</h3>
<p>When dealing with numerical data, it is essential to consider that the magnitude of the data may or may not be important, depending on the situation. The distribution of numerical features matters for some models, and the Central Limit Theorem (CLT) makes the normality of errors less relevant when the sample size is large enough <span class="citation" data-cites="pek2017data zheng2018feature">(<a href="#ref-pek2017data" role="doc-biblioref">Pek, Wong, and Wong 2017</a>; <a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>.</p>
<p>Transformations should be used to improve effect size interpretation and to address non-normality when sample sizes are small <span class="citation" data-cites="pek2017data">(<a href="#ref-pek2017data" role="doc-biblioref">Pek, Wong, and Wong 2017</a>)</span>. Data visualization is critical for understanding data and the effect of transformations <span class="citation" data-cites="zheng2018feature">(<a href="#ref-zheng2018feature" role="doc-biblioref">Zheng and Casari 2018</a>)</span>. The choice of method depends on whether the goal is statistical prediction or statistical inference <span class="citation" data-cites="pek2017data">(<a href="#ref-pek2017data" role="doc-biblioref">Pek, Wong, and Wong 2017</a>)</span>.</p>
</section>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<p>The methodological framework for this project can be summarized in the following steps:</p>
<ol type="1">
<li><p><strong>Data Ingestion and Preliminary Cleaning:</strong><br>
Raw data is imported from an Excel file hosted on Google Drive. Unique identifiers (e.g., student IDs, lesson IDs) are used to group the data, ensuring that, for each participant, only the earliest non-null response is retained when multiple attempts are recorded.</p></li>
<li><p><strong>Feature Engineering and Labeling:</strong><br>
A new variable is introduced to distinguish between pretest and posttest conditions, based on the lesson identifier. In addition, specific columns are renamed for clarity (e.g., renaming <code>Q5Duration</code> to <code>WritingTime</code>).</p></li>
<li><p><strong>Visualization and Descriptive Analysis:</strong><br>
Histograms and summary statistics are generated to examine the distribution of the writing time data, revealing the presence of outliers and a highly skewed distribution.</p></li>
<li><p><strong>Outlier Treatment and Data Transformation:</strong><br>
Outliers are identified using a three-standard-deviation rule and are replaced with lesson-specific means. A logarithmic transformation is then applied to reduce the skewness of the writing time variable, resulting in a distribution more amenable to parametric analysis.</p></li>
<li><p><strong>Feature Scaling:</strong><br>
The writing time variable is normalized using min-max scaling to facilitate further analysis and potential machine learning applications.</p></li>
<li><p><strong>Data Quality Assurance and Aggregation:</strong><br>
Duplicate records and missing values are identified and addressed. Finally, the dataset is aggregated by test condition (pretest vs.&nbsp;posttest) to generate summary statistics that inform subsequent analyses.</p></li>
</ol>
</section>
<section id="implementation-details" class="level2">
<h2 class="anchored" data-anchor-id="implementation-details">Implementation Details</h2>
<section id="data-preprocessing-handling-multiple-attempts" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-handling-multiple-attempts">Data Preprocessing: Handling Multiple Attempts</h3>
<p>The core preprocessing is encapsulated in the <code>process_log_data</code> function. This function takes a raw DataFrame, groups records by unique identifiers (e.g., student and lesson IDs), and then selects the first non-null response for each repeated measure (such as responses to multiple questions or their corresponding durations).</p>
<div id="694a414b" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_log_data(df):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Process log data by extracting first attempts and handling missing values</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">    by looking at subsequent attempts.</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define identifier and repeated columns</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    base_cols <span class="op">=</span> [<span class="st">'RecordID'</span>, <span class="st">'ClassID'</span>, <span class="st">'UserID'</span>, <span class="st">'LessonID'</span>]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    attempt_cols <span class="op">=</span> [<span class="st">'LessonAttempt'</span>, <span class="st">'TotalTime'</span>, <span class="st">'XML'</span>]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    data_cols <span class="op">=</span> [<span class="ss">f'Q</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">Data'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    duration_cols <span class="op">=</span> [<span class="ss">f'Q</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">Duration'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)]</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># List to store processed rows</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    processed_data <span class="op">=</span> []</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Group the data by the base columns (unique combination per record)</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    grouped <span class="op">=</span> df.groupby(base_cols)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, group <span class="kw">in</span> grouped:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Start with the key identifiers</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        row_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(base_cols, name))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For each data and duration column, pick the first non-null attempt</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> col <span class="kw">in</span> data_cols <span class="op">+</span> duration_cols:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            row_dict[col] <span class="op">=</span> group[col].iloc[<span class="dv">0</span>]  <span class="co"># Take the first attempt</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> pd.isna(row_dict[col]):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If missing, search subsequent attempts</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> attempt <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(group)):</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> <span class="kw">not</span> pd.isna(group[col].iloc[attempt]):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>                        row_dict[col] <span class="op">=</span> group[col].iloc[attempt]</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">break</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Also add attempt-specific columns</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        row_dict[<span class="st">'LessonAttempt'</span>] <span class="op">=</span> group[<span class="st">'LessonAttempt'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        row_dict[<span class="st">'TotalTime'</span>] <span class="op">=</span> group[<span class="st">'TotalTime'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        row_dict[<span class="st">'XML'</span>] <span class="op">=</span> group[<span class="st">'XML'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        processed_data.append(row_dict)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the list of dictionaries into a DataFrame with a specified column order</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(processed_data)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    column_order <span class="op">=</span> base_cols <span class="op">+</span> [<span class="st">'LessonAttempt'</span>, <span class="st">'TotalTime'</span>, <span class="st">'XML'</span>] <span class="op">+</span> data_cols <span class="op">+</span> duration_cols</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result_df[column_order]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Key aspects of the function include:</em></p>
<ul>
<li><strong>Grouping:</strong> Data is grouped by <code>RecordID</code>, <code>ClassID</code>, <code>UserID</code>, and <code>LessonID</code> to handle multiple attempts by the same student.</li>
<li><strong>Iteration:</strong> For each group, the function selects the first non-null value for each data and duration column, preserving the earliest response.</li>
<li><strong>Output:</strong> The function returns a cleaned DataFrame with a single row per unique record, with logically ordered columns.</li>
</ul>
</section>
<section id="loading-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-data">Loading Data</h3>
<p>In this segment, the code reads an Excel file containing the log data. This file holds data from multiple lessons that are later used to compare pretest and posttest performance.</p>
<div id="becbead2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>summary_log_data <span class="op">=</span> pd.read_excel(</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'/Users/john/Library/CloudStorage/Box-Box/Website/educ_6190_001/assignments/assignment_1/mnt/data/summary_data_-_lesson_2-3-9-10.xlsx'</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    sheet_name<span class="op">=</span><span class="st">'Sheet1'</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="applying-the-processing-function-and-creating-a-test-variable" class="level3">
<h3 class="anchored" data-anchor-id="applying-the-processing-function-and-creating-a-test-variable">Applying the Processing Function and Creating a Test Variable</h3>
<p>The raw data is processed using our custom function.</p>
<div id="a6a62530" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>processed_df <span class="op">=</span> process_log_data(summary_log_data)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>processed_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">RecordID</th>
<th data-quarto-table-cell-role="th">ClassID</th>
<th data-quarto-table-cell-role="th">UserID</th>
<th data-quarto-table-cell-role="th">LessonID</th>
<th data-quarto-table-cell-role="th">LessonAttempt</th>
<th data-quarto-table-cell-role="th">TotalTime</th>
<th data-quarto-table-cell-role="th">XML</th>
<th data-quarto-table-cell-role="th">Q1Data</th>
<th data-quarto-table-cell-role="th">Q2Data</th>
<th data-quarto-table-cell-role="th">Q3Data</th>
<th data-quarto-table-cell-role="th">Q4Data</th>
<th data-quarto-table-cell-role="th">Q5Data</th>
<th data-quarto-table-cell-role="th">Q6Data</th>
<th data-quarto-table-cell-role="th">Q7Data</th>
<th data-quarto-table-cell-role="th">Q8Data</th>
<th data-quarto-table-cell-role="th">Q9Data</th>
<th data-quarto-table-cell-role="th">Q1Duration</th>
<th data-quarto-table-cell-role="th">Q2Duration</th>
<th data-quarto-table-cell-role="th">Q3Duration</th>
<th data-quarto-table-cell-role="th">Q4Duration</th>
<th data-quarto-table-cell-role="th">Q5Duration</th>
<th data-quarto-table-cell-role="th">Q6Duration</th>
<th data-quarto-table-cell-role="th">Q7Duration</th>
<th data-quarto-table-cell-role="th">Q8Duration</th>
<th data-quarto-table-cell-role="th">Q9Duration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>formal</td>
<td>formal5_02</td>
<td>lesson2</td>
<td>1</td>
<td>379.071</td>
<td>Lesson2-Flood.xml</td>
<td>Next</td>
<td>Arousal8_Pleasant8</td>
<td>2.0</td>
<td>3.0</td>
<td>Floods are one of the most common natural disa...</td>
<td>4.0</td>
<td>6.0</td>
<td>3.0</td>
<td>3.0</td>
<td>72.531</td>
<td>7.484</td>
<td>19.874</td>
<td>8.031</td>
<td>177.328</td>
<td>6.750</td>
<td>23.859</td>
<td>35.843</td>
<td>15.156</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>formal</td>
<td>formal5_02</td>
<td>lesson3</td>
<td>1</td>
<td>358.535</td>
<td>Lesson3-Hurricane.xml</td>
<td>Next</td>
<td>Arousal9_Pleasant5</td>
<td>1.0</td>
<td>1.0</td>
<td>The two most destructive hurricanes to ever hi...</td>
<td>6.0</td>
<td>2.0</td>
<td>1.0</td>
<td>6.0</td>
<td>119.062</td>
<td>4.593</td>
<td>4.999</td>
<td>3.890</td>
<td>119.484</td>
<td>3.000</td>
<td>28.343</td>
<td>20.140</td>
<td>40.203</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>formal</td>
<td>formal5_02</td>
<td>lesson9</td>
<td>1</td>
<td>452.599</td>
<td>Lesson9-Job.xml</td>
<td>Next</td>
<td>Arousal9_Pleasant5</td>
<td>1.0</td>
<td>5.0</td>
<td>The United States job market has deteriorated....</td>
<td>3.0</td>
<td>4.0</td>
<td>5.0</td>
<td>2.0</td>
<td>71.531</td>
<td>6.796</td>
<td>2.687</td>
<td>3.828</td>
<td>202.812</td>
<td>4.609</td>
<td>97.828</td>
<td>25.796</td>
<td>24.296</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>formal</td>
<td>formal5_02</td>
<td>lesson10</td>
<td>1</td>
<td>395.415</td>
<td>Lesson10-Butterfly.xml</td>
<td>Next</td>
<td>Arousal5_Pleasant5</td>
<td>2.0</td>
<td>3.0</td>
<td>The butterfly and the moth have a lot of thing...</td>
<td>3.0</td>
<td>1.0</td>
<td>4.0</td>
<td>6.0</td>
<td>73.031</td>
<td>6.078</td>
<td>4.078</td>
<td>3.890</td>
<td>227.796</td>
<td>3.718</td>
<td>22.093</td>
<td>21.078</td>
<td>21.031</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>formal</td>
<td>formal16_02</td>
<td>lesson2</td>
<td>1</td>
<td>537.568</td>
<td>Lesson2-Flood.xml</td>
<td>Next</td>
<td>Arousal7_Pleasant3</td>
<td>2.0</td>
<td>3.0</td>
<td>Flood is one of the natural disaster that crea...</td>
<td>3.0</td>
<td>4.0</td>
<td>5.0</td>
<td>4.0</td>
<td>27.437</td>
<td>14.343</td>
<td>19.828</td>
<td>6.968</td>
<td>377.781</td>
<td>7.625</td>
<td>6.765</td>
<td>21.375</td>
<td>14.875</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>After processing the raw data with the custom function, a new column (<code>test</code>) is created to distinguish between pretest (lessons 2 and 3) and posttest (lessons 9 and 10) conditions. The mapping is verified by printing the distribution of the test types and a sample of the processed data.</p>
<div id="413dc15a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'test'</span>] <span class="op">=</span> processed_df[<span class="st">'LessonID'</span>].<span class="bu">map</span>({</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lesson2'</span>: <span class="st">'pretest'</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lesson3'</span>: <span class="st">'pretest'</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lesson9'</span>: <span class="st">'posttest'</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lesson10'</span>: <span class="st">'posttest'</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Distribution of test types:"</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'test'</span>].value_counts())</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Sample of processed data with test variable:"</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[[<span class="st">'LessonID'</span>, <span class="st">'test'</span>]].head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Distribution of test types:
test
posttest    386
pretest     381
Name: count, dtype: int64

Sample of processed data with test variable:
   LessonID      test
0   lesson2   pretest
1   lesson3   pretest
2   lesson9  posttest
3  lesson10  posttest
4   lesson2   pretest
5   lesson3   pretest
6   lesson9  posttest
7  lesson10  posttest
8   lesson2   pretest
9   lesson3   pretest</code></pre>
</div>
</div>
</section>
<section id="renaming-and-visualizing-the-writing-time-variable" class="level3">
<h3 class="anchored" data-anchor-id="renaming-and-visualizing-the-writing-time-variable">Renaming and Visualizing the Writing Time Variable</h3>
<p>For clarity, the column <code>Q5Duration</code> is renamed to <code>WritingTime</code>. A histogram is then plotted to visualize the distribution of writing time, with vertical lines indicating the mean and the thresholds defined by three standard deviations.</p>
<div id="814d3fc8" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename for clarity</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>processed_df <span class="op">=</span> processed_df.rename(columns<span class="op">=</span>{<span class="st">'Q5Duration'</span>: <span class="st">'WritingTime'</span>})</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot histogram with mean and ±3 standard deviations</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>plt.hist(processed_df[<span class="st">'WritingTime'</span>], bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>plt.axvline(processed_df[<span class="st">'WritingTime'</span>].mean(), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">'Mean'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(processed_df[<span class="st">'WritingTime'</span>].mean() <span class="op">+</span> <span class="dv">3</span><span class="op">*</span>processed_df[<span class="st">'WritingTime'</span>].std(),</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">'3 SD Above Mean'</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(processed_df[<span class="st">'WritingTime'</span>].mean() <span class="op">-</span> <span class="dv">3</span><span class="op">*</span>processed_df[<span class="st">'WritingTime'</span>].std(),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">'3 SD Below Mean'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Writing Time (seconds)'</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of Writing Time'</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(array([9.57302808e-04, 1.51315605e-03, 8.77012895e-04, 4.01449564e-04,
        2.09989003e-04, 9.88183543e-05, 4.32330300e-05, 3.08807357e-05,
        3.70568829e-05, 4.94091772e-05, 1.85284414e-05, 1.23522943e-05,
        6.17614715e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        6.17614715e-06, 0.00000000e+00, 1.23522943e-05, 0.00000000e+00,
        6.17614715e-06, 0.00000000e+00, 6.17614715e-06, 0.00000000e+00,
        6.17614715e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 6.17614715e-06]),
 array([1.26500000e+00, 2.33898967e+02, 4.66532933e+02, 6.99166900e+02,
        9.31800867e+02, 1.16443483e+03, 1.39706880e+03, 1.62970277e+03,
        1.86233673e+03, 2.09497070e+03, 2.32760467e+03, 2.56023863e+03,
        2.79287260e+03, 3.02550657e+03, 3.25814053e+03, 3.49077450e+03,
        3.72340847e+03, 3.95604243e+03, 4.18867640e+03, 4.42131037e+03,
        4.65394433e+03, 4.88657830e+03, 5.11921227e+03, 5.35184623e+03,
        5.58448020e+03, 5.81711417e+03, 6.04974813e+03, 6.28238210e+03,
        6.51501607e+03, 6.74765003e+03, 6.98028400e+03]),
 &lt;BarContainer object of 30 artists&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Text(0.5, 0, 'Writing Time (seconds)')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Text(0, 0.5, 'Density')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Text(0.5, 1.0, 'Distribution of Writing Time')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-5.png" width="986" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="7a2918ae" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Writing Time Summary Statistics:"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'WritingTime'</span>].describe())</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Skewness: </span><span class="sc">{</span>processed_df[<span class="st">'WritingTime'</span>]<span class="sc">.</span>skew()<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Writing Time Summary Statistics:
count     696.000000
mean      572.174059
std       630.892576
min         1.265000
25%       251.722250
50%       405.382500
75%       644.047000
max      6980.284000
Name: WritingTime, dtype: float64

Skewness: 4.77</code></pre>
</div>
</div>
</section>
<section id="outlier-replacement-and-log-transformation" class="level3">
<h3 class="anchored" data-anchor-id="outlier-replacement-and-log-transformation">Outlier Replacement and Log Transformation</h3>
<p>To address skewness and outliers in the <code>WritingTime</code> variable, the code: - Computes acceptable bounds (mean ± 3 standard deviations). - Replaces values outside these bounds with the lesson-specific mean. - Applies a logarithmic transformation (using <code>np.log(x + 1)</code>) to compress the scale of higher values and stabilize variance.</p>
<p>Descriptive statistics and skewness values are compared across the original, cleaned, and log-transformed data, demonstrating the effectiveness of these preprocessing steps.</p>
<div id="e5db1ca3" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean, standard deviation, and bounds for outlier detection</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> processed_df[<span class="st">'WritingTime'</span>].mean()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> processed_df[<span class="st">'WritingTime'</span>].std()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>lower_bound <span class="op">=</span> mean <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> std</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>upper_bound <span class="op">=</span> mean <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> std</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Preserve the original writing times</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'WritingTime_original'</span>] <span class="op">=</span> processed_df[<span class="st">'WritingTime'</span>]</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace outliers with the mean writing time of the corresponding lesson</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>lesson_means <span class="op">=</span> processed_df.groupby(<span class="st">'LessonID'</span>)[<span class="st">'WritingTime'</span>].transform(<span class="st">'mean'</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> (processed_df[<span class="st">'WritingTime'</span>] <span class="op">&lt;</span> lower_bound) <span class="op">|</span> (processed_df[<span class="st">'WritingTime'</span>] <span class="op">&gt;</span> upper_bound)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>processed_df.loc[mask, <span class="st">'WritingTime'</span>] <span class="op">=</span> lesson_means[mask]</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply a log transformation to the cleaned writing times</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'WritingTime_log'</span>] <span class="op">=</span> np.log(processed_df[<span class="st">'WritingTime'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Display statistics for each transformation stage</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original WritingTime Statistics:"</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'WritingTime_original'</span>].describe())</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Skewness (original):"</span>, processed_df[<span class="st">'WritingTime_original'</span>].skew())</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cleaned WritingTime Statistics:"</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'WritingTime'</span>].describe())</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Skewness (cleaned):"</span>, processed_df[<span class="st">'WritingTime'</span>].skew())</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log-transformed WritingTime Statistics:"</span>)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'WritingTime_log'</span>].describe())</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Skewness (log-transformed):"</span>, processed_df[<span class="st">'WritingTime_log'</span>].skew())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original WritingTime Statistics:
count     696.000000
mean      572.174059
std       630.892576
min         1.265000
25%       251.722250
50%       405.382500
75%       644.047000
max      6980.284000
Name: WritingTime_original, dtype: float64

Skewness (original): 4.774762070142547

Cleaned WritingTime Statistics:
count     696.000000
mean      512.355243
std       391.086600
min         1.265000
25%       251.722250
50%       405.382500
75%       626.499750
max      2375.579000
Name: WritingTime, dtype: float64

Skewness (cleaned): 2.0766269712768888

Log-transformed WritingTime Statistics:
count    696.000000
mean       5.979808
std        0.782562
min        0.817575
25%        5.532290
50%        6.007293
75%        6.441735
max        7.773417
Name: WritingTime_log, dtype: float64

Skewness (log-transformed): -1.0692825002709074</code></pre>
</div>
</div>
</section>
<section id="visual-comparison-of-distribution-transformations" class="level3">
<h3 class="anchored" data-anchor-id="visual-comparison-of-distribution-transformations">Visual Comparison of Distribution Transformations</h3>
<p>A three-panel plot compares the original, cleaned, and log-transformed distributions side by side. This visual comparison highlights: - The strong positive skew in the original data. - The reduction of extreme values in the cleaned data. - The near-symmetric distribution achieved after log transformation.</p>
<div id="89e7777b" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Original data distribution</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">131</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>plt.hist(processed_df[<span class="st">'WritingTime_original'</span>], bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original WritingTime'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Seconds'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Cleaned data distribution (with outliers replaced)</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">132</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>plt.hist(processed_df[<span class="st">'WritingTime'</span>], bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Cleaned WritingTime</span><span class="ch">\n</span><span class="st">(Outliers Replaced)'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Seconds'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-transformed distribution</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">133</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>plt.hist(processed_df[<span class="st">'WritingTime_log'</span>], bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Log-transformed WritingTime'</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Log(Seconds)'</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(array([155., 245., 142.,  65.,  34.,  16.,   7.,   5.,   6.,   8.,   3.,
          2.,   1.,   0.,   0.,   0.,   1.,   0.,   2.,   0.,   1.,   0.,
          1.,   0.,   1.,   0.,   0.,   0.,   0.,   1.]),
 array([1.26500000e+00, 2.33898967e+02, 4.66532933e+02, 6.99166900e+02,
        9.31800867e+02, 1.16443483e+03, 1.39706880e+03, 1.62970277e+03,
        1.86233673e+03, 2.09497070e+03, 2.32760467e+03, 2.56023863e+03,
        2.79287260e+03, 3.02550657e+03, 3.25814053e+03, 3.49077450e+03,
        3.72340847e+03, 3.95604243e+03, 4.18867640e+03, 4.42131037e+03,
        4.65394433e+03, 4.88657830e+03, 5.11921227e+03, 5.35184623e+03,
        5.58448020e+03, 5.81711417e+03, 6.04974813e+03, 6.28238210e+03,
        6.51501607e+03, 6.74765003e+03, 6.98028400e+03]),
 &lt;BarContainer object of 30 artists&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 1.0, 'Original WritingTime')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 0, 'Seconds')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0, 0.5, 'Frequency')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(array([21., 40., 99., 74., 99., 71., 68., 58., 31., 24., 24., 14., 13.,
        10., 11.,  3.,  6.,  3.,  5.,  1.,  3.,  0.,  2.,  3.,  3.,  1.,
         1.,  1.,  5.,  2.]),
 array([1.2650000e+00, 8.0408800e+01, 1.5955260e+02, 2.3869640e+02,
        3.1784020e+02, 3.9698400e+02, 4.7612780e+02, 5.5527160e+02,
        6.3441540e+02, 7.1355920e+02, 7.9270300e+02, 8.7184680e+02,
        9.5099060e+02, 1.0301344e+03, 1.1092782e+03, 1.1884220e+03,
        1.2675658e+03, 1.3467096e+03, 1.4258534e+03, 1.5049972e+03,
        1.5841410e+03, 1.6632848e+03, 1.7424286e+03, 1.8215724e+03,
        1.9007162e+03, 1.9798600e+03, 2.0590038e+03, 2.1381476e+03,
        2.2172914e+03, 2.2964352e+03, 2.3755790e+03]),
 &lt;BarContainer object of 30 artists&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 1.0, 'Cleaned WritingTime\n(Outliers Replaced)')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 0, 'Seconds')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(array([ 1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  2.,  3.,  3.,
         5.,  3.,  1.,  7., 19., 43., 64., 58., 93., 97., 93., 79., 48.,
        33., 19.,  9., 13.]),
 array([0.81757476, 1.04943618, 1.2812976 , 1.51315902, 1.74502044,
        1.97688186, 2.20874327, 2.44060469, 2.67246611, 2.90432753,
        3.13618895, 3.36805037, 3.59991179, 3.83177321, 4.06363463,
        4.29549605, 4.52735747, 4.75921889, 4.99108031, 5.22294173,
        5.45480314, 5.68666456, 5.91852598, 6.1503874 , 6.38224882,
        6.61411024, 6.84597166, 7.07783308, 7.3096945 , 7.54155592,
        7.77341734]),
 &lt;BarContainer object of 30 artists&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 1.0, 'Log-transformed WritingTime')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 0, 'Log(Seconds)')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-9-output-11.png" width="1430" height="471" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="feature-scaling-min-max-normalization" class="level3">
<h3 class="anchored" data-anchor-id="feature-scaling-min-max-normalization">Feature Scaling: Min-Max Normalization</h3>
<p>The cleaned <code>WritingTime</code> variable is scaled to a [0, 1] range using min-max normalization. Although this step does not alter the distribution’s skewness, it standardizes the data for algorithms that require features on a similar scale.</p>
<div id="dbb82c33" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>processed_df[<span class="st">'WritingTime_scale'</span>] <span class="op">=</span> (</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    (processed_df[<span class="st">'WritingTime'</span>] <span class="op">-</span> processed_df[<span class="st">'WritingTime'</span>].<span class="bu">min</span>()) <span class="op">/</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    (processed_df[<span class="st">'WritingTime'</span>].<span class="bu">max</span>() <span class="op">-</span> processed_df[<span class="st">'WritingTime'</span>].<span class="bu">min</span>())</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original WritingTime Statistics:"</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'WritingTime'</span>].describe())</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Skewness (original):"</span>, processed_df[<span class="st">'WritingTime'</span>].skew())</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Min-Max Scaled WritingTime Statistics:"</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[<span class="st">'WritingTime_scale'</span>].describe())</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Skewness (scaled):"</span>, processed_df[<span class="st">'WritingTime_scale'</span>].skew())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original WritingTime Statistics:
count     696.000000
mean      512.355243
std       391.086600
min         1.265000
25%       251.722250
50%       405.382500
75%       626.499750
max      2375.579000
Name: WritingTime, dtype: float64

Skewness (original): 2.0766269712768888

Min-Max Scaled WritingTime Statistics:
count    696.000000
mean       0.215258
std        0.164716
min        0.000000
25%        0.105486
50%        0.170204
75%        0.263333
max        1.000000
Name: WritingTime_scale, dtype: float64

Skewness (scaled): 2.076626971276889</code></pre>
</div>
</div>
<p>A side-by-side histogram confirms that the underlying distribution shape remains unchanged after scaling.</p>
<div id="ed0e5d97" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Original distribution</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>plt.hist(processed_df[<span class="st">'WritingTime'</span>], bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original WritingTime'</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Seconds'</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaled distribution</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>plt.hist(processed_df[<span class="st">'WritingTime_scale'</span>], bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Min-Max Scaled WritingTime'</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Scaled Value (0-1)'</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(array([21., 40., 99., 74., 99., 71., 68., 58., 31., 24., 24., 14., 13.,
        10., 11.,  3.,  6.,  3.,  5.,  1.,  3.,  0.,  2.,  3.,  3.,  1.,
         1.,  1.,  5.,  2.]),
 array([1.2650000e+00, 8.0408800e+01, 1.5955260e+02, 2.3869640e+02,
        3.1784020e+02, 3.9698400e+02, 4.7612780e+02, 5.5527160e+02,
        6.3441540e+02, 7.1355920e+02, 7.9270300e+02, 8.7184680e+02,
        9.5099060e+02, 1.0301344e+03, 1.1092782e+03, 1.1884220e+03,
        1.2675658e+03, 1.3467096e+03, 1.4258534e+03, 1.5049972e+03,
        1.5841410e+03, 1.6632848e+03, 1.7424286e+03, 1.8215724e+03,
        1.9007162e+03, 1.9798600e+03, 2.0590038e+03, 2.1381476e+03,
        2.2172914e+03, 2.2964352e+03, 2.3755790e+03]),
 &lt;BarContainer object of 30 artists&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Text(0.5, 1.0, 'Original WritingTime')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Text(0.5, 0, 'Seconds')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Text(0, 0.5, 'Frequency')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(array([21., 40., 99., 74., 99., 71., 68., 58., 31., 24., 24., 14., 13.,
        10., 11.,  3.,  6.,  3.,  5.,  1.,  3.,  0.,  2.,  3.,  3.,  1.,
         1.,  1.,  5.,  2.]),
 array([0.        , 0.03333333, 0.06666667, 0.1       , 0.13333333,
        0.16666667, 0.2       , 0.23333333, 0.26666667, 0.3       ,
        0.33333333, 0.36666667, 0.4       , 0.43333333, 0.46666667,
        0.5       , 0.53333333, 0.56666667, 0.6       , 0.63333333,
        0.66666667, 0.7       , 0.73333333, 0.76666667, 0.8       ,
        0.83333333, 0.86666667, 0.9       , 0.93333333, 0.96666667,
        1.        ]),
 &lt;BarContainer object of 30 artists&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Text(0.5, 1.0, 'Min-Max Scaled WritingTime')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Text(0.5, 0, 'Scaled Value (0-1)')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Text(0, 0.5, 'Frequency')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-11-output-9.png" width="1142" height="470" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="data-quality-assurance-and-aggregation" class="level3">
<h3 class="anchored" data-anchor-id="data-quality-assurance-and-aggregation">Data Quality Assurance and Aggregation</h3>
<p>Additional steps include: - Checking for and confirming the absence of duplicate records.</p>
<div id="ddf78395" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check duplicates</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of duplicates:"</span>, processed_df.duplicated().<span class="bu">sum</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of duplicates: 0</code></pre>
</div>
</div>
<ul>
<li>Identifying missing values and removing rows with incomplete key columns.</li>
</ul>
<div id="62fab85f" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check missing values</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Missing values in relevant columns:"</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(processed_df[[<span class="st">'WritingTime'</span>, <span class="st">'WritingTime_log'</span>, <span class="st">'WritingTime_scale'</span>, <span class="st">'test'</span>]].isnull().<span class="bu">sum</span>())</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove rows with missing values if any exist</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>processed_df <span class="op">=</span> processed_df.dropna(subset<span class="op">=</span>[<span class="st">'WritingTime'</span>, <span class="st">'WritingTime_log'</span>, <span class="st">'WritingTime_scale'</span>, <span class="st">'test'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Missing values in relevant columns:
WritingTime          71
WritingTime_log      71
WritingTime_scale    71
test                  0
dtype: int64</code></pre>
</div>
</div>
<ul>
<li>Aggregating summary statistics by test condition (pretest vs.&nbsp;posttest).</li>
</ul>
<div id="f1ecc7c8" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>grouped_stats <span class="op">=</span> processed_df.groupby(<span class="st">'test'</span>).agg({</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'WritingTime_log'</span>: [<span class="st">'mean'</span>, <span class="st">'std'</span>],</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'WritingTime_scale'</span>: [<span class="st">'mean'</span>, <span class="st">'std'</span>]</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>}).<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Descriptive Statistics by Test Group:"</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grouped_stats)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Descriptive Statistics by Test Group:
         WritingTime_log        WritingTime_scale       
                    mean    std              mean    std
test                                                    
posttest           6.007  0.786             0.224  0.176
pretest            5.953  0.779             0.207  0.153</code></pre>
</div>
</div>
<ul>
<li>Saving the processed dataset as a CSV file for future analysis.</li>
</ul>
<div id="fe6101ac" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the processed DataFrame for future analysis</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>processed_df.to_csv(<span class="st">'assign1_summary_log.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This project implements a comprehensive data processing pipeline designed to prepare raw log data for statistical analysis and machine learning applications. The key steps include:</p>
<ol type="1">
<li>Importing raw data from an Excel file.</li>
<li>Processing multiple attempts per student by grouping and selecting the first non-null response.</li>
<li>Creating a test label to distinguish between pretest and posttest conditions.</li>
<li>Renaming and visualizing a key performance metric (WritingTime).</li>
<li>Identifying and replacing outliers, followed by a log transformation to reduce skewness.</li>
<li>Normalizing the data using min-max scaling.</li>
<li>Ensuring data quality by checking for duplicates and handling missing values.</li>
<li>Aggregating summary statistics by test type and saving the cleaned dataset.</li>
</ol>
<p>This systematic approach not only cleans and prepares the data but also enhances its suitability for subsequent statistical tests and modeling. Ultimately, the refined data supports more accurate and meaningful conclusions about the effects of conversational agent language style on learning outcomes within ITS environments.</p>



</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-claude3opus2024" class="csl-entry" role="listitem">
Anthropic. 2024a. <span>“Claude 3 Opus.”</span> Large language model. <a href="https://claude.ai/">https://claude.ai/</a>.
</div>
<div id="ref-claude35sonnet" class="csl-entry" role="listitem">
———. 2024b. <span>“Claude 3.5 Sonnet.”</span> Large language model. <a href="https://claude.ai/">https://claude.ai/</a>.
</div>
<div id="ref-awawdeh2019application" class="csl-entry" role="listitem">
Awawdeh, Moath, Tarig Faisal, Anees Bashir, and Amjad Sheikh. 2019. <span>“Application of Outlier Detection Using Re-Weighted Least Squares and r-Squared for IoT Extracted Data.”</span> In <em>2019 Advances in Science and Engineering Technology International Conferences (ASET)</em>, 1–6. IEEE.
</div>
<div id="ref-openai2025-o3-mini-high" class="csl-entry" role="listitem">
OpenAI. 2025. <span>“O3-Mini (High).”</span> Large language model. <a href="https://chatgpt.com/">https://chatgpt.com/</a>.
</div>
<div id="ref-osborne2012best" class="csl-entry" role="listitem">
Osborne, Jason W. 2012. <em>Best Practices in Data Cleaning: A Complete Guide to Everything You Need to Do Before and After Collecting Your Data</em>. Sage publications.
</div>
<div id="ref-pek2017data" class="csl-entry" role="listitem">
Pek, Jolynn, Octavia Wong, and AC Wong. 2017. <span>“Data Transformations for Inference with Linear Regression: Clarifications and Recommendations.”</span> <em>Practical Assessment, Research, and Evaluation</em> 22 (1).
</div>
<div id="ref-zheng2018feature" class="csl-entry" role="listitem">
Zheng, Alice, and Amanda Casari. 2018. <em>Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists</em>. O’Reilly Media, Inc.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/penngse\.johnbaker\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Made with <a href="https://quarto.org/" target="_blank"><img src="https://quarto.org/quarto.png" class="img-fluid" width="65" alt="Quarto"></a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/baker-jr-john/Website" target="_blank">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>