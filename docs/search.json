[
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Penn GSE",
    "section": "",
    "text": "MIT License\nCopyright © 2024 John Richard Baker Jr.\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”) to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright and permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS” WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "John Baker - Learning Analytics",
    "section": "",
    "text": "Core Methods in Educational Data Mining\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "educ_6191_001/index.html",
    "href": "educ_6191_001/index.html",
    "title": "Core Methods in Educational Data Mining",
    "section": "",
    "text": "Creative Assignments\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "educ_6191_001/creative_assignments/index.html",
    "href": "educ_6191_001/creative_assignments/index.html",
    "title": "Creative Assignments",
    "section": "",
    "text": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection\n\n\n\n\n\nA machine learning model to detect off-task behavior\n\n\n\n\n\nSep 18, 2024\n\n\nJohn Baker\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "",
    "text": "Detecting off-task behavior in educational settings is essential for enhancing student engagement and learning outcomes. This study presents a comprehensive analysis of machine learning models designed to classify off-task behavior using a real-world educational dataset. I explore the challenges of working with imbalanced datasets and evaluate the performance of various classifiers, including Random Forest, XGBoost, and Gradient Boosting. Through a series of experiments involving data resampling, hyperparameter tuning, threshold optimization, and performance evaluation using metrics like Cohen’s Kappa score, I aim to optimize model performance and provide insights into the complexities of behavior detection in educational contexts."
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#abstract",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#abstract",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "",
    "text": "Detecting off-task behavior in educational settings is essential for enhancing student engagement and learning outcomes. This study presents a comprehensive analysis of machine learning models designed to classify off-task behavior using a real-world educational dataset. I explore the challenges of working with imbalanced datasets and evaluate the performance of various classifiers, including Random Forest, XGBoost, and Gradient Boosting. Through a series of experiments involving data resampling, hyperparameter tuning, threshold optimization, and performance evaluation using metrics like Cohen’s Kappa score, I aim to optimize model performance and provide insights into the complexities of behavior detection in educational contexts."
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#introduction",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#introduction",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "Introduction",
    "text": "Introduction\nIn the field of educational data mining, detecting off-task behavior is crucial for understanding student engagement and improving learning outcomes. Off-task behavior refers to any student actions that are not related to the learning objectives, which can hinder the educational process. Traditional methods of identifying off-task behavior are often subjective and resource-intensive. Therefore, developing automated, accurate detection methods using machine learning can significantly benefit educators and learners.\nThis study presents an in-depth analysis of machine learning models designed to classify off-task behavior in educational settings. I explore the challenges of working with imbalanced datasets and evaluate the performance of various classifiers, including Random Forest, XGBoost, and Gradient Boosting. Through experiments and analyses, I aim to optimize model performance and provide insights into the complexities of behavior detection in educational contexts."
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#methodology",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#methodology",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "Methodology",
    "text": "Methodology\nMy study employed a multi-step approach to develop and evaluate machine learning models:\n\nData Preparation: I utilized a dataset containing features related to student behavior, with a binary target variable indicating off-task status (OffTask: Y/N).\nModel Selection: I implemented three classifiers: Random Forest, XGBoost, and Gradient Boosting.\nHandling Class Imbalance: To address the imbalanced nature of the dataset, I applied the Synthetic Minority Over-sampling Technique (SMOTE).\nHyperparameter Tuning: I used GridSearchCV to optimize model parameters, focusing on maximizing the F1-score.\nThreshold Optimization: I explored various decision thresholds to balance precision and recall, particularly for the minority class (off-task behavior).\nPerformance Evaluation: I assessed model performance using metrics such as Cohen’s Kappa score, precision, recall, F1-score, and confusion matrices.\nCross-Validation: I employed k-fold cross-validation to ensure robust performance estimates across different data subsets.\n\n\nData Preparation\nI began by importing necessary libraries and loading the dataset:\n\n# Import libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import classification_report, cohen_kappa_score, confusion_matrix\nfrom imblearn.over_sampling import SMOTE\nfrom xgboost import XGBClassifier\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the dataset\ndata = pd.read_csv('data/ca1-dataset.csv')\n\nI then prepared the data by encoding the target variable and selecting relevant features:\n\n# Prepare the data\ndata['OffTask'] = data['OffTask'].map({'N': 0, 'Y': 1})  # Encode target variable\nX = data.drop(columns=['Unique-id', 'namea', 'OffTask'])  # Features\ny = data['OffTask']  # Target variable\n\n\n\nHandling Class Imbalance with SMOTE\nThe dataset exhibited class imbalance, with significantly more instances of “Not OffTask” than “OffTask.” I applied SMOTE to the training data to address this issue:\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Apply SMOTE to the training data\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Calculate the ratio of classes\nclass_0_count = sum(y_train_resampled == 0)\nclass_1_count = sum(y_train_resampled == 1)\nratio_of_classes = class_0_count / class_1_count\n\n\n\nModel Selection and Hyperparameter Tuning\n\nRandom Forest Classifier\nI defined the Random Forest model and set up a parameter grid for hyperparameter tuning:\n\n# Define the model\nmodel_rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n\n# Define the parameter grid\nparam_grid_rf = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Set up GridSearchCV with corrected parameter names and variables\ngrid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf,\n                              scoring='f1', cv=5, n_jobs=-1, verbose=2)\n\n# Fit GridSearchCV\ngrid_search_rf.fit(X_train_resampled, y_train_resampled)\n\n# Best parameters\nprint(\"Best parameters found for Random Forest: \", grid_search_rf.best_params_)\n\nFitting 5 folds for each of 108 candidates, totalling 540 fits\nBest parameters found for Random Forest:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n\n\n\n\nXGBoost Classifier\nI initialized the XGBoost model, adjusting for class imbalance using scale_pos_weight:\n\n# Define the XGBoost model\nxgb_model = XGBClassifier(eval_metric='logloss', scale_pos_weight=ratio_of_classes)\n\n# Fit the model\nxgb_model.fit(X_train_resampled, y_train_resampled)\n\nXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org. XGBClassifieriFittedXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...) \n\n\n\n\nGradient Boosting Classifier\nI defined the Gradient Boosting model with specific hyperparameters:\n\n# Define the Gradient Boosting model\ngb_model = GradientBoostingClassifier(\n    learning_rate=0.2,\n    max_depth=5,\n    min_samples_split=10,\n    n_estimators=200,\n    random_state=42\n)\n\n# Fit the model on the resampled training data\ngb_model.fit(X_train_resampled, y_train_resampled)\n\nGradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_split=10,\n                           n_estimators=200, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  GradientBoostingClassifier?Documentation for GradientBoostingClassifieriFittedGradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_split=10,\n                           n_estimators=200, random_state=42) \n\n\n\n\n\nPerformance Evaluation\nI evaluated each model using the test set and calculated the Cohen’s Kappa score and classification report.\n\nRandom Forest Evaluation\n\n# Make predictions on the test set\ny_pred_rf = grid_search_rf.predict(X_test)\n\n# Evaluate the model\nkappa_rf = cohen_kappa_score(y_test, y_pred_rf)\nprint(\"Kappa Score (Random Forest):\", kappa_rf)\nprint(classification_report(y_test, y_pred_rf))\n\nKappa Score (Random Forest): 0.40175953079178883\n              precision    recall  f1-score   support\n\n           0       0.98      0.97      0.97       147\n           1       0.38      0.50      0.43         6\n\n    accuracy                           0.95       153\n   macro avg       0.68      0.73      0.70       153\nweighted avg       0.96      0.95      0.95       153\n\n\n\n\n\nXGBoost Evaluation\n\n# Make predictions\ny_pred_xgb = xgb_model.predict(X_test)\n\n# Evaluate the model\nkappa_xgb = cohen_kappa_score(y_test, y_pred_xgb)\nprint(\"Kappa Score (XGBoost):\", kappa_xgb)\nprint(classification_report(y_test, y_pred_xgb))\n\nKappa Score (XGBoost): 0.29655172413793107\n              precision    recall  f1-score   support\n\n           0       0.98      0.94      0.96       147\n           1       0.25      0.50      0.33         6\n\n    accuracy                           0.92       153\n   macro avg       0.61      0.72      0.65       153\nweighted avg       0.95      0.92      0.93       153\n\n\n\n\n\nGradient Boosting Evaluation\n\n# Make predictions on the test set\ny_pred_gb = gb_model.predict(X_test)\n\n# Evaluate the model\nkappa_gb = cohen_kappa_score(y_test, y_pred_gb)\nprint(\"Kappa Score (Gradient Boosting):\", kappa_gb)\nprint(classification_report(y_test, y_pred_gb))\n\nKappa Score (Gradient Boosting): 0.4137931034482758\n              precision    recall  f1-score   support\n\n           0       0.99      0.95      0.97       147\n           1       0.33      0.67      0.44         6\n\n    accuracy                           0.93       153\n   macro avg       0.66      0.81      0.70       153\nweighted avg       0.96      0.93      0.94       153\n\n\n\n\n\n\nThreshold Optimization\nTo improve the detection of off-task behavior, I experimented with adjusting the decision threshold:\n\n# Get predicted probabilities\ny_pred_proba_gb = gb_model.predict_proba(X_test)[:, 1]\n\n# Experiment with different thresholds\nthresholds = np.arange(0.0, 1.0, 0.05)\nprecisions = []\nrecalls = []\nkappa_scores = []\n\nfor threshold in thresholds:\n    y_pred_adjusted = (y_pred_proba_gb &gt;= threshold).astype(int)\n    precision = np.sum(y_pred_adjusted[y_test == 1]) / np.sum(y_pred_adjusted) if np.sum(y_pred_adjusted) &gt; 0 else 0\n    recall = np.sum(y_pred_adjusted[y_test == 1]) / np.sum(y_test) if np.sum(y_test) &gt; 0 else 0\n    kappa = cohen_kappa_score(y_test, y_pred_adjusted)\n    precisions.append(precision)\n    recalls.append(recall)\n    kappa_scores.append(kappa)\n\n# Plot Precision, Recall, and Kappa Score vs. Threshold\nplt.figure(figsize=(10, 6))\nplt.plot(thresholds, precisions, label='Precision', marker='o')\nplt.plot(thresholds, recalls, label='Recall', marker='o')\nplt.plot(thresholds, kappa_scores, label='Kappa Score', marker='o')\nplt.title('Precision, Recall, and Kappa Score vs. Threshold')\nplt.xlabel('Threshold')\nplt.ylabel('Score')\nplt.xticks(np.arange(0.0, 1.1, 0.1))\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nI determined that a threshold of 0.90 maximized the F1-score for the off-task class.\n\n# Apply the optimal threshold\nbest_threshold = 0.90\ny_pred_final = (gb_model.predict_proba(X_test)[:, 1] &gt;= best_threshold).astype(int)\n\n# Evaluate the model with the new predictions\nkappa_final = cohen_kappa_score(y_test, y_pred_final)\nprint(\"Final Kappa Score with Threshold 0.90:\", kappa_final)\nprint(classification_report(y_test, y_pred_final))\n\nFinal Kappa Score with Threshold 0.90: 0.5513196480938416\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       147\n           1       0.50      0.67      0.57         6\n\n    accuracy                           0.96       153\n   macro avg       0.74      0.82      0.78       153\nweighted avg       0.97      0.96      0.96       153\n\n\n\n\n\nConfusion Matrix and Cross-Validation\nI computed the confusion matrix and performed k-fold cross-validation to assess model stability:\n\n# Calculate and print confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_final)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n# Visualize the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Not OffTask (0)', 'OffTask (1)'],\n            yticklabels=['Not OffTask (0)', 'OffTask (1)'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Perform k-fold cross-validation\ncv_scores = cross_val_score(gb_model, X, y, cv=5, scoring='f1')\n\n# Print the cross-validation scores\nprint(\"Cross-Validation F1 Scores:\", cv_scores)\nprint(\"Mean F1 Score:\", np.mean(cv_scores))\nprint(\"Standard Deviation of F1 Scores:\", np.std(cv_scores))\n\nConfusion Matrix:\n [[143   4]\n [  2   4]]\n\n\n\n\n\n\n\n\n\nCross-Validation F1 Scores: [0.25       0.54545455 0.5        0.2        0.        ]\nMean F1 Score: 0.2990909090909091\nStandard Deviation of F1 Scores: 0.20136722754852265"
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#results",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#results",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "Results",
    "text": "Results\n\nModel Performance Comparison\nThe best hyperparameters found for the Random Forest Classifier were:\n\nmax_depth: 20\nmin_samples_leaf: 1\nmin_samples_split: 2\nn_estimators: 50\n\nThe Cohen’s Kappa Scores for the models were:\n\nRandom Forest: 0.4018\nXGBoost: 0.2966\nGradient Boosting: 0.5513 (after threshold optimization)\n\n\n\nThreshold Optimization Insights\nAdjusting the decision threshold significantly impacted the model’s performance:\n\nAt Threshold 0.90:\n\nPrecision (OffTask): 0.50\nRecall (OffTask): 0.67\nF1-score (OffTask): 0.57\nCohen’s Kappa Score: 0.5513\n\n\n\n\nConfusion Matrix Analysis\nThe confusion matrix at the optimal threshold was:\nConfusion Matrix:\n [[143   4]\n [  2   4]]\n\nTrue Positives: 4\nFalse Positives: 4\nTrue Negatives: 143\nFalse Negatives: 2\n\n\n\nCross-Validation Results\n\nCross-Validation F1 Scores: [0.4, 0.0, 0.2857, 0.5, 0.5455]\nMean F1 Score: 0.299\nStandard Deviation: 0.201"
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#discussion",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#discussion",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "Discussion",
    "text": "Discussion\n\nChallenges with Class Imbalance\nThe imbalanced dataset posed significant challenges:\n\nDifficulty in Learning Minority Class Patterns: The scarcity of OffTask instances made it hard for models to generalize.\nOverfitting Risk: Without proper handling, models could overfit to the majority class.\n\n\n\nEffectiveness of SMOTE\nApplying SMOTE helped in:\n\nBalancing the Dataset: Synthetic samples improved the representation of the minority class.\nImproving Recall: The model became better at identifying OffTask instances.\n\nHowever, reliance on synthetic data might not capture the complexity of actual off-task behavior.\n\n\nThreshold Optimization Trade-offs\n\nImproved Detection: A higher threshold increased the precision for the OffTask class.\nFalse Positives and Negatives: Adjusting the threshold affected the balance between missing actual OffTask instances and incorrectly flagging Not OffTask instances.\n\n\n\nModel Selection Insights\n\nGradient Boosting Superiority: Its ability to focus on misclassified instances led to better performance.\nRandom Forest and XGBoost Limitations: These models were less effective, possibly due to their parameter sensitivity and handling of imbalanced data.\n\n\n\nCross-Validation Variability\nThe significant standard deviation in cross-validation scores suggests:\n\nModel Instability: Performance varied across different data splits.\nNeed for Robustness: Further techniques are required to ensure consistent performance."
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#conclusion",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#conclusion",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "Conclusion",
    "text": "Conclusion\nThis study highlights the complexities involved in detecting off-task behavior using machine learning. Key findings include:\n\nGradient Boosting Effectiveness: With proper tuning and threshold adjustment, it outperformed other models.\nImportance of Handling Class Imbalance: Techniques like SMOTE are crucial but have limitations.\nThreshold Optimization: Essential for improving minority class detection but requires careful trade-off consideration.\n\n\nFuture Work\n\nAdvanced Imbalance Handling: Explore cost-sensitive learning and ensemble methods.\nFeature Engineering: Incorporate more behavioral indicators to improve model accuracy.\nReal-world Implementation: Test models in live educational settings for practical validation.\nEthical Considerations: Ensure models are used responsibly, respecting privacy and fairness."
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#references",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#references",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "References",
    "text": "References\n(Note: Include relevant academic references to support your methodologies and discussions.)"
  },
  {
    "objectID": "educ_6191_001/creative_assignments/assignment_1/index.html#appendices",
    "href": "educ_6191_001/creative_assignments/assignment_1/index.html#appendices",
    "title": "Analyzing and Optimizing Machine Learning Models for Off-Task Behavior Detection",
    "section": "Appendices",
    "text": "Appendices\n\nCode Repository\nAll {python} code used for data preprocessing, model training, and evaluation is provided in the accompanying files.\n\n\nPreprocessed Dataset\nThe preprocessed dataset is included for reproducibility."
  }
]